const data = {
  nodes: [
    {
      FIELD1: 1,
      id: "7C7CAEED",
      name: "On rank correlation in information retrieval evaluation",
      url: "https://dl.acm.org/doi/abs/10.1145/1273221.1273223",
      abstract:
        "Some methods for rank correlation in evaluation are examined and their relative advantages and disadvantages are discussed. In particular, it is suggested that different test statistics should be used for providing additional information about the experiments other that the one provided by statistical significance testing. Kendall's τ is often used for testing-rank correlation, yet it is little appropriate if the objective of the test is different from what τ was designed for. In particular, attention should be paid to the null hypothesis. Other measures for rank correlation are described. If one test statistic suggests to reject a hypothesis, other test statistics should be used to support or to revise the decision. The paper then focuses on rank correlation between webpage lists ordered by PageRank for applying the general reflections on these test statistics. An interpretation of PageRank behaviour is provided on the basis of the discussion of the test statistics for rank correlation.",
      citations:
        ' ""10.1109/ICPR48806.2021.9411963/,  ""10.1109/AICAI.2019.8701391/,  ""10.1007/978-3-030-11018-5_40/,  ""10.1109/CVPR.2017.125/,  ""10.1109/DSAA.2016.43/,  ""10.1108/AJIM-12-2014-0171/,  ""10.4018/978-1-4666-2854-0.ch010/,  ""10.1007/s10115-011-0391-7/,  ""10.1214/10-EJS577/,  ""10.1007/978-3-642-02469-6_43/,  ""10.1007/s13735-019-00178-7/,  ""10.1088/1742-5468/2015/07/P07002/',
      group:
        "SIGIR '02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2002  Pages   199–206https://doi.org/10.1145/564376.564412",
      year: "",
      authors: "Massimo Melucci",
      doi: "10.1145/1273221.1273223",
    },
    {
      FIELD1: 2,
      id: "7AEE29E3",
      name: "The Voting Model for People Search",
      url: "https://theses.gla.ac.uk/609/",
      abstract: "",
      citations: "",
      group:
        "SIGIR '02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2002  Pages   199–206https://doi.org/10.1145/564376.564412",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 3,
      id: "7D68490B",
      name: "Document clustering with committees",
      url: "https://dl.acm.org/doi/abs/10.1145/564376.564412",
      abstract:
        "\nDocument clustering is useful in many information retrieval tasks: document browsing, organization and viewing of retrieval results, generation of Yahoo-like hierarchies of documents, etc. The general goal of clustering is to group data elements such that the intra-group similarities are high and the inter-group similarities are low. We present a clustering algorithm called CBC (Clustering By Committee) that is shown to produce higher quality clusters in document clustering tasks as compared to several well known clustering algorithms. It initially discovers a set of tight clusters (high intra-group similarity), called committees, that are well scattered in the similarity space (low inter-group similarity). The union of the committees is but a subset of all elements. The algorithm proceeds by assigning elements to their most similar committee. Evaluating cluster quality has always been a difficult task. We present a new evaluation methodology that is based on the editing distance between output clusters and manually constructed classes (the answer key). This evaluation measure is more intuitive and easier to interpret than previous evaluation measures.\n",
      citations:
        ' ""10.1109/ACIT53391.2021.9677217/,  ""10.4018/978-1-5225-5191-1.ch003/,  ""10.1109/ICRIIS.2017.8002466/,  ""10.4018/978-1-5225-0536-5.ch013/,  ""10.1007/978-3-319-59226-8_22/,  ""10.1147/JRD.2017.2742706/,  ""10.1109/ICECDS.2017.8390037/,  ""10.1007/978-3-319-23207-2_44/,  ""10.1007/978-3-319-20895-4_18/,  ""10.1007/978-3-662-43908-1_40/,  ""10.1109/AICCSA.2013.6616455/,  ""10.1109/ICISA.2012.6220980/,  ""10.1016/j.protcy.2012.10.052/,  ""10.1109/ICISA.2012.6220951/,  ""10.1007/978-3-642-27207-3_22/,  ""10.1109/FSKD.2011.6019857/,  ""10.1109/TIE.2010.2045315/,  ""10.4018/978-1-60960-537-7.ch013/,  ""10.1108/02635571111115182/,  ""10.1007/s11192-009-0097-8/,  ""10.1007/978-3-642-15251-1_32/,  ""10.1007/978-3-642-00958-7_61/,  ""10.1002/asi.21145/,  ""10.4018/jdwm.2009080703/,  ""10.1007/978-3-540-68125-0_80/,  ""10.1007/s10115-008-0135-5/,  ""10.1007/978-3-540-71701-0_47/,  ""10.1109/ICMLC.2007.4370588/,  ""10.1007/BF03037400/,  ""10.1109/ICMLC.2006.258855/,  ""10.1016/j.ipm.2005.06.008/,  ""10.1007/978-3-540-24752-4_13/,  ""10.1109/CIT.2004.1357351/,  ""10.1108/VJIKMS-08-2018-0068/',
      group:
        "SIGIR '02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2002  Pages   199–206https://doi.org/10.1145/564376.564412",
      year: "",
      authors: "Patrick Pantel",
      doi: "10.1145/564376.564412",
    },
    {
      FIELD1: 4,
      id: "7A488256",
      name: "A comparison of indexing techniques for Japanese text retrieval",
      url: "https://dl.acm.org/doi/abs/10.1145/160688.160728",
      abstract:
        "\nA series of Japanese full-text retrieval experiments were conducted using an inference network document retrieval model. The retrieval performance of two major indexing methods, character-based and word-based, were evaluated. Using structured queries, the character-based indexing performed retrieval as well as, or slightly better, than the word-based system. This result has practical significance since the character-based indexing speed is considerably faster than the traditional word-based indexing. All the queries in this experiment were automatically formulated from natural language input.\n",
      citations:
        ' ""10.1109/SNLP.2009.5340946/,  ""10.1007/s10590-009-9064-7/,  ""10.1007/978-3-540-76719-0_22/,  ""10.1007/s10209-004-0098-6/,  ""10.1109/DLRP.2000.942204/,  ""10.1002/(SICI)1097-4571(1999)50:8&lt;709::AID-ASI8&gt;3.0.CO;2-V/,  ""10.1109/HICSS.1996.495303/,  ""10.1007/BFb0034715/',
      group:
        "SIGIR '93: Proceedings of the 16th annual international ACM SIGIR conference on Research and development in information retrievalJuly 1993  Pages   237–246https://doi.org/10.1145/160688.160728",
      year: "",
      authors: "Hideo Fujii",
      doi: "10.1145/160688.160728",
    },
    {
      FIELD1: 5,
      id: "7D5CD2DF",
      name: "Feature selection for ranking",
      url: "https://dl.acm.org/doi/abs/10.1145/1277741.1277811",
      abstract:
        "\nRanking is a very important topic in information retrieval. While algorithms for learning ranking models have been intensively studied, this is not the case for feature selection, despite of its importance. The reality is that many feature selection methods used in classification are directly applied to ranking. We argue that because of the striking differences between ranking and classification, it is better to develop different feature selection methods for ranking. To this end, we propose a new feature selection method in this paper. Specifically, for each feature we use its value to rank the training instances, and define the ranking accuracy in terms of a performance measure or a loss function as the importance of the feature. We also define the correlation between the ranking results of two features as the similarity between them. Based on the definitions, we formulate the feature selection issue as an optimization problem, for which it is to find the features with maximum total importance scores and minimum total similarity scores. We also demonstrate how to solve the optimization problem in an efficient way. We have tested the effectiveness of our feature selection method on two information retrieval datasets and with two ranking models. Experimental results show that our method can outperform traditional feature selection methods for the ranking task.\n",
      citations:
        ' ""10.1007/978-3-030-95391-1_29/,  ""10.1007/978-3-030-99142-5_5/,  ""10.1109/ICICCS53718.2022.9788340/,  ""10.2298/CSIS201220042Y/,  ""10.1007/978-981-15-5619-7_1/,  ""10.1587/transcom.2020EBP3175/,  ""10.1109/JSEN.2021.3079835/,  ""10.1016/j.arcontrol.2021.04.001/,  ""10.1109/JBHI.2020.2966178/,  ""10.1007/s42979-020-00377-8/,  ""10.1109/ACCESS.2020.3043459/,  ""10.1109/ITT51279.2020.9320778/,  ""10.1109/ACCESS.2019.2902640/,  ""10.1109/ACCESS.2019.2918555/,  ""10.1142/S021819401930001X/,  ""10.1109/IJCNN.2018.8489646/,  ""10.1007/s10791-018-9330-5/,  ""10.1007/978-3-319-93417-4_9/,  ""10.1016/j.jocs.2017.10.012/,  ""10.1109/CIBCB.2018.8404965/,  ""10.1109/TNNLS.2016.2562670/,  ""10.1109/KST.2017.7886119/,  ""10.1109/ISM.2017.42/,  ""10.1109/BigData.2016.7840658/,  ""10.1007/s13748-015-0080-y/,  ""10.1109/ICACCAF.2016.7748991/,  ""10.1007/978-3-319-46843-3_3/,  ""10.1109/CIBEC.2016.7836087/,  ""10.1007/978-3-319-41754-7_51/,  ""10.1109/IJCNN.2015.7280529/,  ""10.1002ra2.2015.1450520100119/,  ""10.1109/TCYB.2014.2347372/,  ""10.1109/FSKD.2015.7382026/,  ""10.1109/PERCOM.2015.7146512/,  ""10.1109/RIOS.2015.7270735/,  ""10.1109/ICEEI.2015.7352467/,  ""10.1109/TCSVT.2014.2305511/,  ""10.1007/978-3-319-06028-6_41/,  ""10.3156/jsoft.26.809/,  ""10.1007/978-3-319-04702-7_19/,  ""10.2200/S00607ED2V01Y201410HLT026/,  ""10.1109/TNNLS.2013.2286696/,  ""10.1109/ICMU.2014.6799049/,  ""10.1109/ICoCS.2014.7060911/,  ""10.1007/978-3-642-37450-0_27/,  ""10.1016/j.measurement.2012.05.031/,  ""10.1109/TNNLS.2013.2247628/,  ""10.1002/asi.22789/,  ""10.1002/9781118562796.ch2/,  ""10.1007/s13278-011-0045-5/,  ""10.1109/TGRS.2010.2054832/,  ""10.1109/IEEM.2011.6118112/,  ""10.2200/S00348ED1V01Y201104HLT012/,  ""10.1007/978-3-642-14267-3_13/,  ""10.1109/CSCWD.2011.5960053/,  ""10.1109/ISDA.2011.6121702/,  ""10.1109/IEMBS.2010.5627132/,  ""10.1109/IJCNN.2010.5596936/,  ""10.1109/HIBIT.2010.5478911/,  ""10.1007/978-3-642-01891-6_7/,  ""10.1109/ISCIS.2009.5291904/,  ""10.1109/AFGR.2008.4813401/,  ""10.1007/978-3-540-68636-1_68/,  ""10.1109/ICMLC.2008.4620685/,  ""10.1007/978-3-540-87479-9_33/,  ""10.17706/jsw.11.2.148-161/,  ""10.1007/s12652-018-0976-z/,  ""10.52547/jipm.36.4.1081/',
      group:
        "SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2007  Pages   407–414https://doi.org/10.1145/1277741.1277811",
      year: "",
      authors: "Xiubo Geng",
      doi: "10.1145/1277741.1277811",
    },
    {
      FIELD1: 6,
      id: "7646C4F7",
      name: "Learning to advertise",
      url: "https://dl.acm.org/doi/abs/10.1145/1148170.1148265",
      abstract:
        "\nContent-targeted advertising, the task of automatically associating ads to a Web page, constitutes a key Web monetization strategy nowadays. Further, it introduces new challenging technical problems and raises interesting questions. For instance, how to design ranking functions able to satisfy conflicting goals such as selecting advertisements (ads) that are relevant to the users and suitable and profitable to the publishers and advertisers? In this paper we propose a new framework for associating ads with web pages based on Genetic Programming (GP). Our GP method aims at learning functions that select the most appropriate ads, given the contents of a Web page. These ranking functions are designed to optimize overall precision and minimize the number of misplacements. By using a real ad collection and web pages from a newspaper, we obtained a gain over a state-of-the-art baseline method of 61.7% in average precision. Further, by evolving individuals to provide good ranking estimations, GP was able to discover ranking functions that are very effective in placing ads in web pages while avoiding irrelevant ones.\n",
      citations:
        ' ""10.1007/s11042-022-12248-w/,  ""10.1007/978-3-030-34515-0_29/,  ""10.1109/ICDE48307.2020.00146/,  ""10.29333/jisem/8483/,  ""10.1109/ICDMW51313.2020.00066/,  ""10.1109/COMPSAC.2018.00081/,  ""10.4018/978-1-5225-5191-1.ch038/,  ""10.1007/978-1-4614-8265-9_455/,  ""10.1007/978-3-319-98812-2_34/,  ""10.4018/978-1-5225-2058-0.ch009/,  ""10.1007/978-1-4899-7687-1_826/,  ""10.1109/CEC.2016.7743803/,  ""10.1007/978-1-4899-7993-3_455-2/,  ""10.1007/978-3-319-29659-3_13/,  ""10.4018/978-1-4666-5019-0.ch008/,  ""10.4018/ijtd.2014010105/,  ""10.1109/ACC.2013.6580778/,  ""10.4018/978-1-4666-2542-6.ch006/,  ""10.1007/978-3-642-31546-6_3/,  ""10.1007/978-3-642-39878-0_14/,  ""10.4018/ijirr.2013100101/,  ""10.1109/ICEEI.2011.6021592/,  ""10.4018/978-1-60960-189-8.ch004/,  ""10.4018/978-1-60960-189-8.ch013/,  ""10.4018/978-1-60960-189-8.ch005/,  ""10.4018/978-1-60960-189-8.ch003/,  ""10.4018/978-1-60960-189-8.ch011/,  ""10.1109/JPROC.2009.2039841/,  ""10.1007/s10115-009-0222-2/,  ""10.1007/978-3-642-15208-5_13/,  ""10.1109/CVPRW.2009.5204162/,  ""10.1007/978-0-387-39940-9_455/,  ""10.1007/s10462-021-10039-7/',
      group:
        "SIGIR '06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2006  Pages   549–556https://doi.org/10.1145/1148170.1148265",
      year: "",
      authors: "Anísio Lacerda",
      doi: "10.1145/1148170.1148265",
    },
    {
      FIELD1: 7,
      id: "7CF9B0DC",
      name: "Personalized tag recommendation using graph-based ranking on multi-type interrelated objects",
      url: "https://dl.acm.org/doi/abs/10.1145/1571941.1572034",
      abstract:
        '\nSocial tagging is becoming increasingly popular in many Web 2.0 applications where users can annotate resources (e.g. Web pages) with arbitrary keywords (i.e. tags). A tag recommendation module can assist users in tagging process by suggesting relevant tags to them. It can also be directly used to expand the set of tags annotating a resource. The benefits are twofold: improving user experience and enriching the index of resources. However, the former one is not emphasized in previous studies, though a lot of work has reported that different users may describe the same concept in different ways. We address the problem of personalized tag recommendation for text documents. In particular, we model personalized tag recommendation as a "query and ranking" problem and propose a novel graph-based ranking algorithm for interrelated multi-type objects. When a user issues a tagging request, both the document and the user are treated as a part of the query. Tags are then ranked by our graph-based ranking algorithm which takes into consideration both relevance to the document and preference of the user. Finally, the top ranked tags are presented to the user as suggestions. Experiments on a large-scale tagging data set collected from Del.icio.us have demonstrated that our proposed algorithm significantly outperforms algorithms which fail to consider the diversity of different users\' interests.\n',
      citations:
        ' ""10.1155/2022/7610124/,  ""10.1109/TMM.2020.2992941/,  ""10.1109/ICWS53863.2021.00036/,  ""10.1007/s11432-020-3219-6/,  ""10.1007/978-3-030-37548-5_13/,  ""10.1007/978-3-030-10997-4_12/,  ""10.1109/EITCE47263.2019.9095150/,  ""10.1007/978-981-13-1936-5_4/,  ""10.1007/978-3-319-50901-3_25/,  ""10.1109/ICWS.2016.63/,  ""10.1007/s13278-015-0309-6/,  ""10.4236/jcc.2015.39002/,  ""10.1016/j.neucom.2014.07.011/,  ""10.1109/TKDE.2013.70/,  ""10.1109/ISPA.2015.7306024/,  ""10.1109/IISA.2015.7388124/,  ""10.1109/ICDE.2014.6816706/,  ""10.1109/ICASSP.2014.6854936/,  ""10.1109/ISCCSP.2014.6877953/,  ""10.1109/ASONAM.2014.6921586/,  ""10.1109/ICIP.2014.7025607/,  ""10.1109/ICME.2014.6890126/,  ""10.1109/ICME.2014.6890162/,  ""10.4018/978-1-4666-2806-9.ch014/,  ""10.4018/978-1-4666-2806-9.ch003/,  ""10.4018/978-1-4666-4213-3.ch007/,  ""10.1007/978-3-642-35725-1_21/,  ""10.1007/978-3-642-41644-6_17/,  ""10.1007/s13278-012-0054-z/,  ""10.1007/s11390-012-1241-0/,  ""10.1057/dddmp.2012.25/,  ""10.1007/978-3-642-24434-6_12/,  ""10.1007/978-3-642-20244-5_32/,  ""10.1007/978-3-642-20149-3_6/,  ""10.1587/transinf.E94.D.542/,  ""10.1007/978-3-642-23863-5_52/,  ""10.1007/s10115-019-01343-4/,  ""10.1111/itor.12569/,  ""10.1007/s10115-020-01515-7/,  ""10.1007/s11280-021-00967-3/',
      group:
        "SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrievalJuly 2009  Pages   540–547https://doi.org/10.1145/1571941.1572034",
      year: "",
      authors: "Ziyu Guan",
      doi: "10.1145/1571941.1572034",
    },
    {
      FIELD1: 8,
      id: "78D3F0A3",
      name: "Term relevance feedback and query expansion: relation to design",
      url: "https://link.springer.com/chapter/10.1007/978-1-4471-2099-5_9",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 9,
      id: "7C55ADC9",
      name: "A sequential algorithm for training text classifiers",
      url: "https://dl.acm.org/doi/pdf/10.1145/219587.219592",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 10,
      id: "7F9C2FCD",
      name: "Document clustering via adaptive subspace iteration",
      url: "https://dl.acm.org/doi/abs/10.1145/1008992.1009031",
      abstract:
        "\nDocument clustering has long been an important problem in information retrieval. In this paper, we present a new clustering algorithm ASI1 , which uses explicitly modeling of the subspace structure associated with each cluster. ASI simultaneously performs data reduction and subspace identification via an iterative alternating optimization procedure. Motivated from the optimization procedure, we then provide a novel method to determine the number of clusters. We also discuss the connections of ASI with various existential clustering approaches. Finally, extensive experimental results on real data sets show the effectiveness of ASI algorithm.\n",
      citations:
        ' ""10.1109/TNNLS.2020.3027539/,  ""10.1007/978-981-19-2719-5_12/,  ""10.2478/dim-2020-0003/,  ""10.1007/978-3-030-38961-1_19/,  ""10.1109/TNNLS.2018.2861209/,  ""10.2478/amcs-2019-0006/,  ""10.4018/978-1-5225-5191-1.ch003/,  ""10.1109/TKDE.2017.2781721/,  ""10.1109/BigData.2017.8258107/,  ""10.4018/978-1-5225-0536-5.ch013/,  ""10.1007/978-1-4899-7687-1_676/,  ""10.26634/jcom.4.3.8289/,  ""10.1109/TNNLS.2014.2337335/,  ""10.1007/978-3-319-09259-1_11/,  ""10.1186/s40537-015-0027-y/,  ""10.1007/978-94-007-6516-0_28/,  ""10.1109/ICoSP.2012.6491702/,  ""10.1007/978-1-4614-3223-4_4/,  ""10.1587/transinf.E94.D.1227/,  ""10.3745/KIPSTB.2010.17B.2.177/,  ""10.1007/978-3-642-12035-0_17/,  ""10.1109/ICADIWT.2009.5273918/,  ""10.1007/978-3-642-04174-7_33/,  ""10.4018/978-1-60566-010-3.ch043/,  ""10.1007/s00500-007-0246-z/,  ""10.1007/s10115-007-0116-0/,  ""10.1109/IJCNN.2006.247253/,  ""10.1109/IS.2006.348532/,  ""10.1109/IJCNN.2006.247254/,  ""10.1007/11564126_41/',
      group:
        "SIGIR '04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2004  Pages   218–225https://doi.org/10.1145/1008992.1009031",
      year: "",
      authors: "Tao Li",
      doi: "10.1145/1008992.1009031",
    },
    {
      FIELD1: 11,
      id: "7B1F8566",
      name: "Personalized active learning for collaborative filtering",
      url: "https://dl.acm.org/doi/abs/10.1145/1390334.1390352",
      abstract:
        "\nCollaborative Filtering (CF) requires user-rated training examples for statistical inference about the preferences of new users. Active learning strategies identify the most informative set of training examples through minimum interactions with the users. Current active learning approaches in CF make an implicit and unrealistic assumption that a user can provide rating for any queried item. This paper introduces a new approach to the problem which does not make such an assumption. We personalize active learning for the user, and query for only those items which the user can provide rating for. We propose an extended form of Bayesian active learning and use the Aspect Model for CF to illustrate and examine the idea. A comparative evaluation of the new method and a well-established baseline method on benchmark datasets shows statistically significant improvements with our method over the performance of the baseline method that is representative for existing approaches which do not take personalization into account.\n",
      citations:
        ' ""10.1109/TKDE.2019.2953721/,  ""10.1109/TKDE.2019.2891530/,  ""10.1109/ACCESS.2020.3022796/,  ""10.1007/978-3-030-64580-9_12/,  ""10.1109/ACCESS.2020.2967792/,  ""10.1007/978-1-4939-7131-2_88/,  ""10.1109/ACCESS.2017.2772226/,  ""10.1109/ACCESS.2017.2767058/,  ""10.1109/ICME.2017.8019472/,  ""10.1007/978-1-4614-7163-9_88-1/,  ""10.2200/S00718ED1V01Y201605ICR049/,  ""10.1109/IJCNN.2016.7727731/,  ""10.1007/978-3-319-07485-6_11/,  ""10.1109/ICME.2014.6890218/,  ""10.1007/s13218-014-0323-2/,  ""10.1109/IRI.2013.6642453/,  ""10.1109/ICDM.2013.69/,  ""10.1109/ICMLC.2013.6890370/,  ""10.1007/978-1-4614-1894-8_2/,  ""10.1007/s11704-012-2871-7/,  ""10.1007/978-3-642-23014-1_14/,  ""10.1109/ICSMC.2011.6083868/,  ""10.1109/IRI.2011.6009563/,  ""10.1109/CIDM.2011.5949431/,  ""10.1016/j.procs.2011.04.187/,  ""10.1109/ICCSE.2010.5593606/,  ""10.1109/IJCNN.2009.5178967/,  ""10.1007/s10994-019-05817-y/,  ""10.1371/journal.pone.0217408/',
      group:
        "SIGIR '08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrievalJuly 2008  Pages   91–98https://doi.org/10.1145/1390334.1390352",
      year: "",
      authors: "Abhay S. Harpale",
      doi: "10.1145/1390334.1390352",
    },
    {
      FIELD1: 12,
      id: "75365F6D",
      name: "Iterative translation disambiguation for cross-language information retrieval",
      url: "https://dl.acm.org/doi/abs/10.1145/1076034.1076123",
      abstract:
        "\nFinding a proper distribution of translation probabilities is one of the most important factors impacting the effectiveness of a cross-language information retrieval system. In this paper we present a new approach that computes translation probabilities for a given query by using only a bilingual dictionary and a monolingual corpus in the target language. The algorithm combines term association measures with an iterative machine learning approach based on expectation maximization. Our approach considers only pairs of translation candidates and is therefore less sensitive to data-sparseness issues than approaches using higher n-grams. The learned translation probabilities are used as query term weights and integrated into a vector-space retrieval system. Results for English-German cross-lingual retrieval show substantial improvements over a baseline using dictionary lookup without term weighting.\n",
      citations:
        ' ""10.1007/978-3-031-05936-0_36/,  ""10.1007/978-3-319-56608-5_39/,  ""10.1007/978-3-319-44564-9_16/,  ""10.1109/ICSESS.2015.7339147/,  ""10.1109/ICACSIS.2014.7065896/,  ""10.1017/S1351324912000265/,  ""10.1007/978-3-642-32790-2_46/,  ""10.1007/978-1-84800-330-9_16/,  ""10.1007/978-3-642-15754-7_31/,  ""10.1007/978-81-8489-203-1_30/,  ""10.1109/ICALT.2006.1652523/,  ""10.1007/s10462-019-09796-3/,  ""10.1007/s11042-021-11074-w/',
      group:
        "SIGIR '05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2005  Pages   520–527https://doi.org/10.1145/1076034.1076123",
      year: "",
      authors: "Christof Monz",
      doi: "10.1145/1076034.1076123",
    },
    {
      FIELD1: 13,
      id: "7B15399A",
      name: "On-line new event detection and tracking",
      url: "https://dl.acm.org/doi/pdf/10.1145/290941.290954",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 14,
      id: "7A3CEE9A",
      name: "Query-sensitive mutual reinforcement chain and its application in query-oriented multi-document summarization",
      url: "https://dl.acm.org/doi/abs/10.1145/1390334.1390384",
      abstract:
        "\nSentence ranking is the issue of most concern in document summarization. Early researchers have presented the mutual reinforcement principle (MR) between sentence and term for simultaneous key phrase and salient sentence extraction in generic single-document summarization. In this work, we extend the MR to the mutual reinforcement chain (MRC) of three different text granularities, i.e., document, sentence and terms. The aim is to provide a general reinforcement framework and a formal mathematical modeling for the MRC. Going one step further, we incorporate the query influence into the MRC to cope with the need for query-oriented multi-document summarization. While the previous summarization approaches often calculate the similarity regardless of the query, we develop a query-sensitive similarity to measure the affinity between the pair of texts. When evaluated on the DUC 2005 dataset, the experimental results suggest that the proposed query-sensitive MRC (Qs-MRC) is a promising approach for summarization.\n",
      citations:
        ' ""10.1109/ICIVC50857.2020.9177457/,  ""10.1109/ICCCNT.2017.8204049/,  ""10.1016/j.visinf.2017.01.006/,  ""10.1109/WIW.2016.041/,  ""10.1109/TVCG.2015.2467554/,  ""10.1007/978-3-319-19581-0_24/,  ""10.1109/TSMCC.2013.2258335/,  ""10.1109/IRI.2014.7051942/,  ""10.1007/978-3-319-13647-9_14/,  ""10.1016/j.ins.2014.04.028/,  ""10.1111/j.1467-8640.2012.00435.x/,  ""10.1109/ICMLC.2011.6016951/,  ""10.1007/978-3-642-19551-8_24/,  ""10.1016/j.ins.2011.04.052/,  ""10.1002/asi.21593/,  ""10.1002/asi.21296/,  ""10.1111/j.1467-8640.2010.00365.x/,  ""10.1007/s13369-018-3619-y/',
      group:
        "SIGIR '08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrievalJuly 2008  Pages   283–290https://doi.org/10.1145/1390334.1390384",
      year: "",
      authors: "Furu Wei",
      doi: "10.1145/1390334.1390384",
    },
    {
      FIELD1: 15,
      id: "7B35DF6E",
      name: "Robust temporal and spectral modeling for query By melody",
      url: "https://dl.acm.org/doi/abs/10.1145/564376.564435",
      abstract:
        "\nQuery by melody is the problem of retrieving musical performances from melodies. Retrieval of real performances is complicated due to the large number of variations in performing a melody and the presence of colored accompaniment noise. We describe a simple yet effective probabilistic model for this task. We describe a generative model that is rich enough to capture the spectral and temporal variations of musical performances and allows for tractable melody retrieval. While most of previous studies on music retrieval from melodies were performed with either symbolic (e.g. MIDI) data or with monophonic (single instrument) performances, we performed experiments in retrieving live and studio recordings of operas that contain a leading vocalist and rich instrumental accompaniment. Our results show that the probabilistic approach we propose is effective and can be scaled to massive datasets.\n",
      citations: ' ""10.1109/TASL.2010.2041384/,  ""10.1109/TMM.2008.2007293/',
      group:
        "SIGIR '02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2002  Pages   331–338https://doi.org/10.1145/564376.564435",
      year: "",
      authors: "Shai Shalev-Shwartz",
      doi: "10.1145/564376.564435",
    },
    {
      FIELD1: 16,
      id: "7D322466",
      name: "A study of methods for negative relevance feedback",
      url: "https://dl.acm.org/doi/abs/10.1145/1390334.1390374",
      abstract:
        "\nNegative relevance feedback is a special case of relevance feedback where we do not have any positive example; this often happens when the topic is difficult and the search results are poor. Although in principle any standard relevance feedback technique can be applied to negative relevance feedback, it may not perform well due to the lack of positive examples. In this paper, we conduct a systematic study of methods for negative relevance feedback. We compare a set of representative negative feedback methods, covering vector-space models and language models, as well as several special heuristics for negative feedback. Evaluating negative feedback methods requires a test set with sufficient difficult topics, but there are not many naturally difficult topics in the existing test collections. We use two sampling strategies to adapt a test collection with easy topics to evaluate negative feedback. Experiment results on several TREC collections show that language model based negative feedback methods are generally more effective than those based on vector-space models, and using multiple negative models is an effective heuristic for negative feedback. Our results also show that it is feasible to adapt test collections with easy topics for evaluating negative feedback methods through sampling.\n",
      citations:
        ' ""10.1007/s12046-021-01763-5/,  ""10.1007/978-3-030-49461-2_22/,  ""10.1109/ICSECC51444.2020.9557550/,  ""10.1142/S021819401950030X/,  ""10.1007/978-1-4614-8265-9_462/,  ""10.1007/978-3-319-94301-5_1/,  ""10.1109/ICPCSI.2017.8392032/,  ""10.1007/978-3-319-56608-5_63/,  ""10.1007/978-1-4899-7993-3_462-2/,  ""10.1007/978-981-10-0515-2_14/,  ""10.1109/RCIS.2014.6861073/,  ""10.1109/ICASSP.2014.6854376/,  ""10.1007/s13369-014-1463-2/,  ""10.1109/RCIS.2014.6861049/,  ""10.1109/ICASSP.2013.6639326/,  ""10.1007/978-3-642-37453-1_44/,  ""10.1109/ICSMC.2012.6378148/,  ""10.1007/978-3-642-23318-0_26/,  ""10.1109/ASRU.2011.6163963/,  ""10.1002/cae.20311/,  ""10.1007/978-3-642-23535-1_38/,  ""10.1109/ICISE.2010.5688547/,  ""10.1109/ICICISYS.2010.5658362/,  ""10.1007/978-0-387-39940-9_462/,  ""10.1371/journal.pone.0104707/',
      group:
        "SIGIR '08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrievalJuly 2008  Pages   219–226https://doi.org/10.1145/1390334.1390374",
      year: "",
      authors: "Xuanhui Wang",
      doi: "10.1145/1390334.1390374",
    },
    {
      FIELD1: 17,
      id: "7F4D016F",
      name: "Global ranking by exploiting user clicks",
      url: "https://dl.acm.org/doi/abs/10.1145/1571941.1571950",
      abstract:
        "\nIt is now widely recognized that user interactions with search results can provide substantial relevance information on the documents displayed in the search results. In this paper, we focus on extracting relevance information from one source of user interactions, i.e., user click data, which records the sequence of documents being clicked and not clicked in the result set during a user search session. We formulate the problem as a global ranking problem, emphasizing the importance of the sequential nature of user clicks, with the goal to predict the relevance labels of all the documents in a search session. This is distinct from conventional learning to rank methods that usually design a ranking model defined on a single document; in contrast, in our model the relational information among the documents as manifested by an aggregation of user clicks is exploited to rank all the documents jointly. In particular, we adapt several sequential supervised learning algorithms, including the conditional random field (CRF), the sliding window method and the recurrent sliding window method, to the global ranking problem. Experiments on the click data collected from a commercial search engine demonstrate that our methods can outperform the baseline models for search results re-ranking.\n",
      citations:
        ' ""10.1109/TIP.2017.2699623/,  ""10.1108/IJWIS-12-2015-0046/,  ""10.1109/TASLP.2016.2560527/,  ""10.2200/S00607ED2V01Y201410HLT026/,  ""10.1109/ICCNC.2012.6167463/,  ""10.1007/s13735-012-0002-8/,  ""10.2200/S00348ED1V01Y201104HLT012/',
      group:
        "SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrievalJuly 2009  Pages   35–42https://doi.org/10.1145/1571941.1571950",
      year: "",
      authors: "Shihao Ji",
      doi: "10.1145/1571941.1571950",
    },
    {
      FIELD1: 18,
      id: "78240F38",
      name: "Using statistical testing in the evaluation of retrieval experiments",
      url: "https://dl.acm.org/doi/abs/10.1145/160688.160758",
      abstract:
        "\nThe standard strategies for evaluation based on precision and recall are examined and their relative advantages and disadvantages are discussed. In particular, it is suggested that relevance feedback be evaluated from the perspective of the user. A number of different statistical tests are described for determining if differences in performance between retrieval methods are significant. These tests have often been ignored in the past because most are based on an assumption of normality which is not strictly valid for the standard performance measures. However, one can test this assumption using simple diagnostic plots, and if it is a poor approximation, there are a number of non-parametric alternatives.\n",
      citations:
        ' ""10.1016/j.ipm.2020.102481/,  ""10.1007/978-3-030-72240-1_3/,  ""10.1016/j.knosys.2021.107114/,  ""10.1109/TITS.2020.2983647/,  ""10.1016/j.elerap.2021.101083/,  ""10.1109/TGCN.2021.3077854/,  ""10.1109/ACCESS.2021.3116857/,  ""10.1016/j.knosys.2021.107623/,  ""10.1007/978-3-030-42835-8_1/,  ""10.1109/TLT.2020.2990724/,  ""10.1051/epjconf/202024506038/,  ""10.1109/TKDE.2020.3001025/,  ""10.1007/978-3-030-15712-8_33/,  ""10.1016/j.jbi.2019.103210/,  ""10.1007/978-3-030-22948-1_1/,  ""10.1109/MDM.2019.00-54/,  ""10.1109/TITS.2019.2912075/,  ""10.1109/ACCESS.2018.2808340/,  ""10.1007/978-1-4614-8265-9_235/,  ""10.1007/978-1-4614-8265-9_478/,  ""10.1007/978-981-13-1199-4_2/,  ""10.1007/978-981-13-1199-4_5/,  ""10.1109/TPAMI.2017.2677439/,  ""10.1007/978-3-319-59569-6_45/,  ""10.1186/s13173-017-0053-z/,  ""10.1007/978-1-4899-7993-3_478-2/,  ""10.1007/978-1-4899-7993-3_235-2/,  ""10.1007/978-3-319-44564-9_5/,  ""10.1108/AJIM-12-2014-0171/,  ""10.1109/SSCI.2015.193/,  ""10.1016/j.ijpe.2014.12.038/,  ""10.1007/978-3-642-54798-0_6/,  ""10.5715/jnlp.21.921/,  ""10.1109/ICCSS.2014.6961829/,  ""10.1016/j.elerap.2014.01.001/,  ""10.1007/978-3-319-11749-2_25/,  ""10.1007/978-3-319-12844-3_25/,  ""10.1108/PROG-07-2012-0037/,  ""10.1007/978-3-642-37456-2_18/,  ""10.1002/asi.22910/,  ""10.1007/s10115-012-0504-y/,  ""10.1007/978-3-642-23008-0_5/,  ""10.1007/s10115-011-0391-7/,  ""10.1002/meet.14504901202/,  ""10.1007/s00354-012-0104-0/,  ""10.4018/978-1-4666-0185-7.ch007/,  ""10.5715/jnlp.19.121/,  ""10.1007/978-3-642-16098-1_3/,  ""10.1007/s10791-011-9169-5/,  ""10.1002/meet.2011.14504801071/,  ""10.4258/hir.2011.17.2.120/,  ""10.4018/978-1-60960-593-3.ch014/,  ""10.1007/s00799-011-0070-z/,  ""10.1007/s10579-009-9101-4/,  ""10.1007/978-3-642-15181-1_5/,  ""10.1007/978-3-642-15464-5_34/,  ""10.1007/978-3-642-15754-7_71/,  ""10.1007/978-3-642-15754-7_48/,  ""10.4018/jswis.2010100101/,  ""10.1007/978-3-642-04447-2_109/,  ""10.1109/IRI.2009.5211574/,  ""10.1081/E-ELIS3-120044772/,  ""10.1002/asi.21255/,  ""10.1109/WICOM.2009.5304847/,  ""10.1007/978-0-387-39940-9_235/,  ""10.1007/978-0-387-39940-9_478/,  ""10.4018/jswis.2009100103/,  ""10.1007/978-3-540-75134-2_9/,  ""10.1007/978-3-540-75134-2_7/,  ""10.1108/00220410810899754/,  ""10.1007/978-3-540-74999-8_109/,  ""10.1007/978-3-540-73111-5_108/,  ""10.1007/978-3-540-74999-8_2/,  ""10.1007/978-3-540-71496-5_48/,  ""10.1007/978-3-540-77088-6_15/,  ""10.1007/978-3-540-71496-5_57/,  ""10.1007/978-3-540-72895-5_13/,  ""10.1007/978-3-540-74999-8_3/,  ""10.1108/00012530710817573/,  ""10.1002/asi.20273/,  ""10.1016/j.ipm.2004.08.012/,  ""10.1016/j.ipm.2005.01.004/,  ""10.1007/s00450-004-0174-4/,  ""10.1002/meet.14504201106/,  ""10.1007/978-3-540-30222-3_5/,  ""10.1007/978-3-540-24642-8_17/,  ""10.1007/978-3-540-24642-8_15/,  ""10.1007/978-3-540-27814-6_30/,  ""10.1007/978-3-540-30125-7_103/,  ""10.1007/978-3-540-25966-4_31/,  ""10.1007/978-3-540-24840-8_49/,  ""10.1109/WI.2003.1241200/,  ""10.1007/978-3-540-45237-9_2/,  ""10.1007/3-540-36618-0_13/,  ""10.1002/asi.10300/,  ""10.1007/3-540-45691-0_2/,  ""10.1007/3-540-45869-7_42/,  ""10.1007/0-306-47019-5_6/,  ""10.1007/3-540-45650-3_16/,  ""10.1007/3-540-39965-8_2/,  ""10.1007/978-4-431-65950-1_54/,  ""10.1002/(SICI)1097-4571(199601)47:1&lt;70::AID-ASI7&gt;3.0.CO;2-#/,  ""10.1002/asi.24203/,  ""10.1007/s00521-021-06158-5/,  ""10.1007/s10758-021-09568-5/,  ""10.1007/s10844-018-0526-3/,  ""10.1371/journal.pone.0268212/,  ""10.1287/isre.2019.0911/,  ""10.2196/34583/',
      group:
        "SIGIR '93: Proceedings of the 16th annual international ACM SIGIR conference on Research and development in information retrievalJuly 1993  Pages   329–338https://doi.org/10.1145/160688.160758",
      year: "",
      authors: "David Hull",
      doi: "10.1145/160688.160758",
    },
    {
      FIELD1: 19,
      id: "7B6CCC91",
      name: "Self-taught hashing for fast similarity search",
      url: "https://dl.acm.org/doi/abs/10.1145/1835449.1835455",
      abstract:
        "\nThe ability of fast similarity search at large scale is of great importance to many Information Retrieval (IR) applications. A promising way to accelerate similarity search is semantic hashing which designs compact binary codes for a large number of documents so that semantically similar documents are mapped to similar codes (within a short Hamming distance). Although some recently proposed techniques are able to generate high-quality codes for documents known in advance, obtaining the codes for previously unseen documents remains to be a very challenging problem. In this paper, we emphasise this issue and propose a novel Self-Taught Hashing (STH) approach to semantic hashing: we first find the optimal l-bit binary codes for all documents in the given corpus via unsupervised learning, and then train l classifiers via supervised learning to predict the l-bit code for any query document unseen before. Our experiments on three real-world text datasets show that the proposed approach using binarised Laplacian Eigenmap (LapEig) and linear Support Vector Machine (SVM) outperforms state-of-the-art techniques significantly.\n",
      citations:
        ' ""10.1109/TMM.2021.3053766/,  ""10.1109/TKDE.2020.2995195/,  ""10.1109/TIP.2022.3158092/,  ""10.1007/s13042-021-01466-7/,  ""10.1109/TBDATA.2020.3027379/,  ""10.1109/IVMSP54334.2022.9816233/,  ""10.1109/TASLP.2022.3196877/,  ""10.1109/ACCESS.2021.3052605/,  ""10.1007/s11280-020-00859-y/,  ""10.1109/TKDE.2019.2953897/,  ""10.1016/j.neucom.2020.08.084/,  ""10.1109/ACCESS.2021.3092150/,  ""10.1109/ICIP42928.2021.9506441/,  ""10.23919/CCC52363.2021.9549732/,  ""10.1109/TIP.2020.3040536/,  ""10.1007/978-3-030-93420-0_25/,  ""10.1109/TIP.2020.2963952/,  ""10.1109/ICASSP40776.2020.9053129/,  ""10.1109/ACCESS.2020.2994783/,  ""10.1109/ICME46284.2020.9102819/,  ""10.1109/TIP.2020.3014727/,  ""10.1109/TMM.2020.2991513/,  ""10.1109/LNET.2020.3031961/,  ""10.1109/TIP.2018.2890144/,  ""10.1109/TPAMI.2019.2914897/,  ""10.1016/j.cviu.2019.102852/,  ""10.1109/BRACIS.2019.00152/,  ""10.1109/ICBK.2019.00044/,  ""10.1109/DSAA.2019.00020/,  ""10.1109/ICCV.2019.00538/,  ""10.1109/DASC/PiCom/CBDCom/CyberSciTech.2019.00138/,  ""10.1109/ICSIDP47821.2019.9173008/,  ""10.1007/978-3-030-34113-8_5/,  ""10.1109/TIP.2018.2882155/,  ""10.1109/JBHI.2018.2827703/,  ""10.1109/TIP.2019.2892703/,  ""10.1109/TNNLS.2016.2615085/,  ""10.1109/TIP.2017.2749147/,  ""10.1109/TCYB.2018.2822781/,  ""10.1007/978-981-13-2203-7_57/,  ""10.1007/978-3-030-01228-1_21/,  ""10.1007/978-3-030-01216-8_27/,  ""10.1109/TIP.2017.2759250/,  ""10.1109/TPAMI.2017.2699960/,  ""10.1109/SANER.2018.8330243/,  ""10.1109/TNNLS.2018.2797248/,  ""10.1109/TIP.2017.2737329/,  ""10.1109/TCYB.2016.2608906/,  ""10.1109/TCYB.2016.2591068/,  ""10.3233/IDT-170286/,  ""10.1109/TIP.2017.2695099/,  ""10.1007/978-3-319-69923-3_28/,  ""10.1109/ICIP.2017.8296972/,  ""10.1109/ICIP.2017.8296308/,  ""10.1109/INDICON.2017.8487755/,  ""10.1007/978-981-10-1627-1_35/,  ""10.1007/s40745-016-0091-y/,  ""10.1109/TCYB.2015.2457618/,  ""10.1109/TNNLS.2015.2495345/,  ""10.1007/s12021-016-9300-2/,  ""10.1109/ICPR.2016.7900200/,  ""10.1109/JPROC.2015.2487976/,  ""10.1007/978-981-10-3005-5_10/,  ""10.1109/ICIP.2016.7532650/,  ""10.1109/AINA.2016.37/,  ""10.1109/ICDM.2016.0155/,  ""10.1007/978-3-319-46454-1_23/,  ""10.1080/00450618.2015.1128966/,  ""10.1016/j.neucom.2015.06.036/,  ""10.1109/ICIP.2015.7351274/,  ""10.1007/978-3-319-24571-3_17/,  ""10.1007/978-3-319-25255-1_24/,  ""10.1007/s11042-014-2035-x/,  ""10.1109/CVPR.2015.7298598/,  ""10.1109/CVPR.2015.7298654/,  ""10.1109/TCYB.2014.2366109/,  ""10.1109/TIP.2015.2390975/,  ""10.1007/978-3-319-16354-3_15/,  ""10.1007/978-3-319-18111-0_33/,  ""10.1007/978-3-319-18032-8_39/,  ""10.1016/j.neucom.2014.09.033/,  ""10.1587/transinf.2015EDL8060/,  ""10.1016/j.neucom.2014.10.042/,  ""10.1007/978-3-319-14445-0_23/,  ""10.1109/TMM.2015.2425651/,  ""10.1109/IJCNN.2015.7280707/,  ""10.1109/TIP.2015.2405340/,  ""10.1109/CVPR.2015.7299011/,  ""10.1109/ISDA.2015.7489162/,  ""10.1109/TIP.2014.2337759/,  ""10.1109/TIP.2014.2352458/,  ""10.1109/ChinaSIP.2014.6889279/,  ""10.1016/j.cviu.2014.04.001/,  ""10.1109/TCYB.2013.2289351/,  ""10.1109/TCYB.2013.2283497/,  ""10.1007/978-3-319-12640-1_36/,  ""10.1007/978-3-319-12640-1_48/,  ""10.1587/essfr.7.256/,  ""10.1016/j.cviu.2014.01.011/,  ""10.1007/978-3-319-10578-9_25/,  ""10.1109/TIP.2014.2332764/,  ""10.1109/ICME.2014.6890264/,  ""10.1109/APSIPA.2014.7041566/,  ""10.1109/ChinaSIP.2014.6889281/,  ""10.1109/APSIPA.2014.7041557/,  ""10.1109/ICICIP.2014.7010268/,  ""10.1109/ICME.2014.6890219/,  ""10.1109/TMM.2013.2291214/,  ""10.1016/j.neucom.2012.07.053/,  ""10.1007/978-3-642-23535-1_44/,  ""10.1007/s11042-020-08772-2/,  ""10.1007/s11042-019-7157-8/,  ""10.1007/s10586-017-1013-2/,  ""10.1007/s11280-020-00779-x/,  ""10.1002/9781118445112.stat07973/,  ""10.1007/s10489-022-03546-9/',
      group:
        "SIGIR '10: Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrievalJuly 2010  Pages   18–25https://doi.org/10.1145/1835449.1835455",
      year: "",
      authors: "Dell Zhang",
      doi: "10.1145/1835449.1835455",
    },
    {
      FIELD1: 20,
      id: "7ED831FE",
      name: "Large scale semi-supervised linear SVMs",
      url: "https://dl.acm.org/doi/abs/10.1145/1148170.1148253",
      abstract:
        "\nLarge scale learning is often realistic only in a semi-supervised setting where a small set of labeled examples is available together with a large collection of unlabeled data. In many information retrieval and data mining applications, linear classifiers are strongly preferred because of their ease of implementation, interpretability and empirical performance. In this work, we present a family of semi-supervised linear support vector classifiers that are designed to handle partially-labeled sparse datasets with possibly very large number of examples and features. At their core, our algorithms employ recently developed modified finite Newton techniques. Our contributions in this paper are as follows: (a) We provide an implementation of Transductive SVM (TSVM) that is significantly more efficient and scalable than currently used dual techniques, for linear classification problems involving large, sparse datasets. (b) We propose a variant of TSVM that involves multiple switching of labels. Experimental results show that this variant provides an order of magnitude further improvement in training efficiency. (c) We present a new algorithm for semi-supervised learning based on a Deterministic Annealing (DA) approach. This algorithm alleviates the problem of local minimum in the TSVM optimization procedure while also being computationally attractive. We conduct an empirical study on several document classification tasks which confirms the value of our methods in large scale semi-supervised settings.\n",
      citations:
        ' ""10.23919/INDIACom54597.2022.9763302/,  ""10.1109/TDSC.2020.3032073/,  ""10.1109/TVT.2019.2933916/,  ""10.1002/tee.22825/,  ""10.1109/ACCESS.2019.2958064/,  ""10.1109/CVPRW.2019.00321/,  ""10.1109/JSYST.2015.2478800/,  ""10.1007/978-3-319-61609-4_6/,  ""10.1007/978-3-030-03338-5_47/,  ""10.1109/TCYB.2017.2765665/,  ""10.1109/TNNLS.2018.2809623/,  ""10.1109/ICPR.2018.8546169/,  ""10.1109/CVPRW.2018.00079/,  ""10.1109/TSMC.2017.2694321/,  ""10.1007/978-3-319-56414-2_8/,  ""10.1109/IJCNN.2017.7966207/,  ""10.1016/j.patcog.2016.09.009/,  ""10.1016/j.neucom.2017.01.012/,  ""10.1016/j.ifacol.2016.07.014/,  ""10.1109/TIFS.2015.2505680/,  ""10.1109/BESC.2016.7804484/,  ""10.1109/SSCI.2016.7849934/,  ""10.1109/BESC.2016.7804487/,  ""10.1109/BESC.2016.7804488/,  ""10.1109/ICCCNT.2015.7395179/,  ""10.1109/TKDE.2015.2399298/,  ""10.1109/ICRoM.2015.7367857/,  ""10.1109/CBMI.2015.7153607/,  ""10.1016/j.neucom.2014.11.051/,  ""10.1109/IJCNN.2014.6889824/,  ""10.1109/ITAIC.2014.7065005/,  ""10.1109/LGRS.2014.2310202/,  ""10.1093an/mpt030/,  ""10.1007/978-3-662-44848-9_37/,  ""10.1007/978-3-319-10849-0_16/,  ""10.1016/j.patrec.2014.02.003/,  ""10.1109/SOCPAR.2013.7054133/,  ""10.1088/0967-3334/34/4/465/,  ""10.1007/978-3-642-37574-3_5/,  ""10.1007/978-3-319-12568-8_85/,  ""10.1016/B978-0-444-53859-8.00008-4/,  ""10.1002/sam.11204/,  ""10.1109/TNNLS.2012.2198240/,  ""10.1109/ICIP.2012.6467559/,  ""10.4018/978-1-60960-818-7.ch308/,  ""10.4018/978-1-60960-818-7.ch314/,  ""10.1007/978-3-642-35136-5_46/,  ""10.4018/978-1-61692-859-9.ch009/,  ""10.1080/03081079.2010.544866/,  ""10.1527/tjsai.26.621/,  ""10.1017/CBO9781139042918.016/,  ""10.1109/BIBM.2010.5706610/,  ""10.1109/IJCNN.2010.5596668/,  ""10.1109/IJCNN.2010.5596506/,  ""10.1007/s10115-009-0209-z/,  ""10.1007/978-1-60327-241-4_13/,  ""10.1007/978-3-642-14770-8_44/,  ""10.1007/978-3-642-14770-8_43/,  ""10.1109/ICNIDC.2009.5360803/,  ""10.1109/CVPR.2009.5206715/,  ""10.3310gfar05040/,  ""10.1093/bfgp/elaa013/,  ""10.1007/s42044-020-00061-3/,  ""10.1007/s11590-020-01616-w/,  ""10.1021/acs.jproteome.0c00711/',
      group:
        "SIGIR '06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2006  Pages   477–484https://doi.org/10.1145/1148170.1148253",
      year: "",
      authors: "Vikas Sindhwani",
      doi: "10.1145/1148170.1148253",
    },
    {
      FIELD1: 21,
      id: "7D693F66",
      name: "Selecting good expansion terms for pseudo-relevance feedback",
      url: "https://dl.acm.org/doi/abs/10.1145/1390334.1390377",
      abstract:
        "\nPseudo-relevance feedback assumes that most frequent terms in the pseudo-feedback documents are useful for the retrieval. In this study, we re-examine this assumption and show that it does not hold in reality - many expansion terms identified in traditional approaches are indeed unrelated to the query and harmful to the retrieval. We also show that good expansion terms cannot be distinguished from bad ones merely on their distributions in the feedback documents and in the whole collection. We then propose to integrate a term classification process to predict the usefulness of expansion terms. Multiple additional features can be integrated in this process. Our experiments on three TREC collections show that retrieval effectiveness can be much improved when term classification is used. In addition, we also demonstrate that good terms should be identified directly according to their possible impact on the retrieval effectiveness, i.e. using supervised learning, instead of unsupervised learning.\n",
      citations:
        ' ""10.1109/ACCESS.2022.3149929/,  ""10.1007/978-3-030-99736-6_28/,  ""10.1007/s10791-022-09405-y/,  ""10.1007/978-3-030-72113-8_31/,  ""10.1007/978-3-030-72240-1_25/,  ""10.1109/TFUZZ.2020.2993702/,  ""10.1109/ACCESS.2021.3118600/,  ""10.1109/BIBM52615.2021.9669713/,  ""10.1109/TRIBES52498.2021.9751671/,  ""10.1109/LA-CCI48322.2021.9769853/,  ""10.1007/s42979-020-0069-x/,  ""10.1109/TSC.2017.2696531/,  ""10.1007/978-3-030-51310-8_5/,  ""10.1145/3366423.3380005/,  ""10.1109/ICBK50248.2020.00044/,  ""10.1109/ICSECC51444.2020.9557550/,  ""10.1007/978-3-030-15719-7_26/,  ""10.1007/978-3-030-15712-8_33/,  ""10.1007/978-3-030-15712-8_19/,  ""10.1007/978-3-030-28730-6_7/,  ""10.1186/s12859-019-3080-2/,  ""10.2197/ipsjjip.27.61/,  ""10.1109/TKDE.2019.2945764/,  ""10.1109/ICOSC.2019.8665516/,  ""10.1007/978-3-319-59463-7_25/,  ""10.1007/978-3-319-76941-7_32/,  ""10.4018/978-1-5225-5191-1.ch072/,  ""10.1007/978-3-319-93935-3_8/,  ""10.4018/978-1-5225-5191-1.ch022/,  ""10.1007/978-3-319-75420-8_38/,  ""10.1016/j.procs.2018.08.011/,  ""10.1109/BIBM.2018.8621577/,  ""10.1109/ICIEV.2018.8641004/,  ""10.1109/ACCESS.2018.2876425/,  ""10.1109/ACCESS.2017.2698142/,  ""10.1016/j.procs.2017.08.317/,  ""10.17485/ijst/2017/v10i18/114051/,  ""10.1007/s13278-017-0476-8/,  ""10.1109/MLDS.2017.8/,  ""10.1007/978-981-10-3274-5_7/,  ""10.1109/TSMC.2015.2421484/,  ""10.2200/S00718ED1V01Y201605ICR049/,  ""10.1007/978-3-319-41754-7_24/,  ""10.1108/EL-12-2014-0211/,  ""10.1007/978-3-319-30671-1_38/,  ""10.1109/ICDE.2016.7498308/,  ""10.1109/CESYS.2016.7889833/,  ""10.1108/AJIM-06-2015-0091/,  ""10.1002/asi.23476/,  ""10.1109/ISSCS.2015.7204027/,  ""10.1109/WCI.2015.7495539/,  ""10.1007/978-3-319-28940-3_4/,  ""10.1007/978-3-319-28940-3_21/,  ""10.1109/ICSECS.2015.7333094/,  ""10.1007/978-3-319-27030-2_8/,  ""10.1109/CBMI.2015.7153613/,  ""10.1007/978-81-322-2012-1_6/,  ""10.1007/978-3-319-12640-1_25/,  ""10.1007/s10791-013-9237-0/,  ""10.1007/s13369-014-1463-2/,  ""10.1002/asi.23143/,  ""10.1186/1471-2105-15-S12-S1/,  ""10.1007/978-3-642-37453-1_44/,  ""10.1007/978-3-642-40511-2_6/,  ""10.1007/978-3-642-45068-6_11/,  ""10.1007/978-3-642-37186-8_8/,  ""10.1109/FSKD.2013.6816262/,  ""10.1109/MSR.2013.6624044/,  ""10.1002/meet.14505001046/,  ""10.1007/978-3-642-34752-8_39/,  ""10.1109/ICMLC.2012.6359677/,  ""10.1109/ICCSNT.2012.6526019/,  ""10.1002/cae.20311/,  ""10.1109/ASRU.2011.6163962/,  ""10.1109/ISDA.2011.6121718/,  ""10.1007/978-3-642-12101-2_45/,  ""10.1007/978-3-642-15470-6_27/,  ""10.1007/978-3-642-15431-7_18/,  ""10.1007/978-3-642-16515-3_48/,  ""10.1007/978-3-642-17187-1_20/,  ""10.1007/978-3-642-13025-0_1/,  ""10.1109/NLPKE.2010.5587826/,  ""10.1109/KAM.2010.5646239/,  ""10.1109/NLPKE.2010.5587859/,  ""10.1109/CEC.2010.5586351/,  ""10.1109/ICCAE.2010.5451899/,  ""10.1109/GRC.2009.5255110/,  ""10.1109/ICME.2009.5202566/,  ""10.1007/s11280-018-0584-z/,  ""10.1007/s10462-019-09773-w/,  ""10.1007/s10115-019-01429-z/,  ""10.4028/www.scientific.net/AMR.255-260.2028/,  ""10.1007/s10115-018-1322-7/,  ""10.1007/s12525-020-00420-9/,  ""10.1007/s00521-020-05534-x/',
      group:
        "SIGIR '08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrievalJuly 2008  Pages   243–250https://doi.org/10.1145/1390334.1390377",
      year: "",
      authors: "Guihong Cao",
      doi: "10.1145/1390334.1390377",
    },
    {
      FIELD1: 22,
      id: "762040FD",
      name: "Novelty and redundancy detection in adaptive filtering",
      url: "https://dl.acm.org/doi/abs/10.1145/564376.564393",
      abstract:
        "\nThis paper addresses the problem of extending an adaptive information filtering system to make decisions about the novelty and redundancy of relevant documents. It argues that relevance and redundance should each be modelled explicitly and separately. A set of five redundancy measures are proposed and evaluated in experiments with and without redundancy thresholds. The experimental results demonstrate that the cosine similarity metric and a redundancy measure based on a mixture of language models are both effective for identifying redundant documents.\n",
      citations:
        ' ""10.1162/coli_a_00429/,  ""10.1007/s12525-021-00488-x/,  ""10.1109/TKDE.2020.3027950/,  ""10.1162/qss_a_00170/,  ""10.1007/978-981-33-4087-9_35/,  ""10.1109/INCET51464.2021.9456301/,  ""10.1007/978-3-030-86797-3_33/,  ""10.2174/1872212114666200403091053/,  ""10.1007/978-3-030-77198-0_4/,  ""10.1007/978-3-030-77198-0_6/,  ""10.1088/1742-6596/1897/1/012024/,  ""10.4018/978-1-7998-0951-7.ch031/,  ""10.1007/s11704-019-8324-9/,  ""10.1007/s42452-020-2082-z/,  ""10.4018/978-1-5225-9373-7.ch009/,  ""10.5772/intechopen.92548/,  ""10.1109/IWCMC48107.2020.9148105/,  ""10.1109/IJCNN48605.2020.9206788/,  ""10.1109/HPCC-SmartCity-DSS50907.2020.00095/,  ""10.1007/978-981-13-2354-6_14/,  ""10.1007/978-981-13-0550-4_3/,  ""10.1109/TVCG.2018.2834341/,  ""10.1007/978-3-030-22815-6_25/,  ""10.4018/978-1-5225-8437-7.ch006/,  ""10.1109/IJCNN.2019.8851857/,  ""10.1109/GC46384.2019.00010/,  ""10.1109/AICCSA47632.2019.9035339/,  ""10.1007/978-981-10-3932-4_17/,  ""10.1007/978-981-10-6626-9_2/,  ""10.1109/TKDE.2018.2874246/,  ""10.1109/ICACCCN.2018.8748683/,  ""10.1109/ACCESS.2017.2669243/,  ""10.1007/978-3-319-39292-9_5/,  ""10.1108/JOCM-10-2016-0226/,  ""10.1140/epjds/s13688-017-0123-7/,  ""10.1007/978-3-319-42553-5_16/,  ""10.1109/AICCSA.2016.7945792/,  ""10.1007/978-3-662-49390-8_8/,  ""10.1016/j.wasman.2016.01.046/,  ""10.1109/SKG.2016.024/,  ""10.20965/jaciii.2016.p0467/,  ""10.4018/IJKSR.2016070107/,  ""10.1007/978-3-319-39958-4_14/,  ""10.2200/S00718ED1V01Y201605ICR049/,  ""10.1109/ICDE.2016.7498326/,  ""10.1109/CIT/IUCC/DASC/PICOM.2015.69/,  ""10.1109/TKDE.2014.2345378/,  ""10.1108/LHT-06-2015-0063/,  ""10.4018/978-1-4666-5019-0.ch009/,  ""10.1017/S026988891400006X/,  ""10.1109/ACCESS.2014.2332453/,  ""10.1109/MLSP.2014.6958911/,  ""10.1109/ITMC.2013.7352707/,  ""10.4018/978-1-4666-2940-0.ch009/,  ""10.1007/978-3-642-38288-8_43/,  ""10.1007/978-3-642-40477-1_21/,  ""10.1007/978-3-642-41230-1_5/,  ""10.1007/978-3-642-41230-1_18/,  ""10.1002/meet.14505001042/,  ""10.1109/TNNLS.2012.2199765/,  ""10.1109/WI-IAT.2012.128/,  ""10.1002/asi.21697/,  ""10.1109/CITS.2012.6220389/,  ""10.1109/FSKD.2012.6234068/,  ""10.1002/cae.20373/,  ""10.1109/ICRA.2011.5980404/,  ""10.1007/978-0-387-85820-3_3/,  ""10.1007/978-0-387-85820-3_4/,  ""10.1007/978-3-642-18308-9_12/,  ""10.2200/S00368ED1V01Y201105ICR019/,  ""10.1108/17410391111148567/,  ""10.4018/jmdem.2011040102/,  ""10.1109/BIBM.2010.5706654/,  ""10.1007/978-3-642-13287-2_4/,  ""10.1007/978-3-642-14400-4_20/,  ""10.1002/9780470689646.ch7/,  ""10.1108/09696471011082358/,  ""10.1109/ICICS.2009.5397541/,  ""10.1111/j.1467-8640.2009.00341.x/,  ""10.2139/ssrn.3199443/,  ""10.1109/NAFIPS.2008.4531235/,  ""10.1109/IJCNN.2008.4634359/,  ""10.1002/asi.20709/,  ""10.1109/ICSSSM.2007.4280214/,  ""10.1109/WI-IATW.2007.29/,  ""10.1109/ICME.2007.4284696/,  ""10.1109/ICDIM.2007.369232/,  ""10.1007/978-3-540-75867-9_29/,  ""10.1007/978-3-540-73435-2_3/,  ""10.1109/MSP.2006.1621449/,  ""10.1109/AERO.2006.1656136/,  ""10.1109/TSA.2005.852087/,  ""10.2964/jsik_KJ00003803602/,  ""10.1109/WI.2004.10053/,  ""10.1007/978-3-540-30112-7_24/,  ""10.1109/ICDE.2003.1260777/,  ""10.1007/s00500-019-04143-8/,  ""10.1017/S1351324920000194/,  ""10.3390/s21072508/,  ""10.1007/s00778-021-00674-5/',
      group:
        "SIGIR '02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2002  Pages   81–88https://doi.org/10.1145/564376.564393",
      year: "",
      authors: "Yi Zhang",
      doi: "10.1145/564376.564393",
    },
    {
      FIELD1: 23,
      id: "7518DA52",
      name: "A similarity-based probability model for latent semantic indexing",
      url: "https://dl.acm.org/doi/pdf/10.1145/312624.312652",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 24,
      id: "7AD389CE",
      name: "On feature distributional clustering for text categorization",
      url: "https://dl.acm.org/doi/abs/10.1145/383952.383976",
      abstract:
        "\nWe describe a text categorization approach that is based on a combination of feature distributional clusters with a support vector machine (SVM) classifier. Our feature selection approach employs distributional clustering of words via the recently introducedinformation bottleneck method, which generates a more efficientword-clusterrepresentation of documents. Combined with the classification power of an SVM, this method yields high performance text categorization that can outperform other recent methods in terms of categorization accuracy and representation efficiency. Comparing the accuracy of our method with other techniques, we observe significant dependency of the results on the data set. We discuss the potential reasons for this dependency.\n",
      citations:
        ' ""10.4018/978-1-6684-6303-1.ch037/,  ""10.1007/978-3-030-64949-4_10/,  ""10.4018/978-1-7998-4240-8.ch012/,  ""10.1061/(ASCE)CP.1943-5487.0000967/,  ""10.1109/TIT.2019.2958705/,  ""10.1142/S0219622020500248/,  ""10.1109/ACCESS.2020.3032840/,  ""10.1016/j.elerap.2019.100892/,  ""10.4018/IJIIT.2019070104/,  ""10.1007/978-3-319-67056-0_15/,  ""10.2139/ssrn.3128678/,  ""10.4018/IJRSDA.2017010103/,  ""10.1007/978-3-319-47650-6_32/,  ""10.1007/978-3-319-28917-5_3/,  ""10.1109/IJCNN.2015.7280654/,  ""10.1109/SMC.2015.297/,  ""10.4018/ijeis.2015010104/,  ""10.1007/978-3-319-10377-8_10/,  ""10.1016/j.ins.2014.02.033/,  ""10.1109/COMPSYM.2010.5685442/,  ""10.1109/ITIME.2009.5236431/,  ""10.1007/978-1-84882-171-2_18/,  ""10.1109/ICCIS.2008.4670801/,  ""10.1007/978-3-540-74171-8_71/,  ""10.1007/s10115-004-0177-2/,  ""10.1007/978-3-540-24752-4_13/,  ""10.1007/978-3-540-24655-8_64/,  ""10.1007/978-3-540-24752-4_14/,  ""10.1109/NNSP.2003.1317999/,  ""10.1162/153244303322753661/,  ""10.4028/www.scientific.net/AMR.532-533.1191/,  ""10.4028/www.scientific.net/AMM.268-270.1844/,  ""10.35940/ijeat.D3417.0411422/',
      group:
        "SIGIR '01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrievalSeptember 2001  Pages   146–153https://doi.org/10.1145/383952.383976",
      year: "",
      authors: "Ron Bekkerman",
      doi: "10.1145/383952.383976",
    },
    {
      FIELD1: 25,
      id: "7A6D1235",
      name: "Short text classification in twitter to improve information filtering",
      url: "https://dl.acm.org/doi/abs/10.1145/1835449.1835643",
      abstract:
        '\nIn microblogging services such as Twitter, the users may become overwhelmed by the raw data. One solution to this problem is the classification of short text messages. As short texts do not provide sufficient word occurrences, traditional classification methods such as "Bag-Of-Words" have limitations. To address this problem, we propose to use a small set of domain-specific features extracted from the author\'s profile and text. The proposed approach effectively classifies the text to a predefined set of generic classes such as News, Events, Opinions, Deals, and Private Messages.\n',
      citations:
        ' ""10.1007/978-981-16-3071-2_59/,  ""10.1109/TKDE.2020.2992485/,  ""10.1007/978-981-19-2266-4_3/,  ""10.4018/978-1-6684-6291-1.ch004/,  ""10.1109/IWCMC55113.2022.9825000/,  ""10.1109/TCYB.2021.3133106/,  ""10.1109/ICDE53745.2022.00308/,  ""10.3233/SW-212838/,  ""10.1109/ACCESS.2020.3047831/,  ""10.1109/TVCG.2020.3030387/,  ""10.1007/978-3-030-66501-2_1/,  ""10.4218/etrij.2019-0443/,  ""10.1007/978-3-030-73280-6_27/,  ""10.1007/978-3-030-73050-5_40/,  ""10.1109/ICAIBD51990.2021.9459035/,  ""10.1038/s41598-021-93262-0/,  ""10.1007/978-3-030-79203-9_12/,  ""10.1007/978-3-030-79150-6_52/,  ""10.1109/ICCCN52240.2021.9522209/,  ""10.1109/ACCESS.2021.3107812/,  ""10.1007/978-3-030-86993-9_24/,  ""10.1109/ACCESS.2021.3111790/,  ""10.1109/ACCESS.2021.3125768/,  ""10.1016/j.asoc.2021.107861/,  ""10.1007/978-3-030-92270-2_56/,  ""10.1109/ICAC54203.2021.9671169/,  ""10.1109/ACCESS.2021.3071009/,  ""10.4018/IJAEIS.289429/,  ""10.1007/978-3-030-14347-3_29/,  ""10.1007/978-981-13-7403-6_61/,  ""10.1007/978-981-15-0222-4_5/,  ""10.1007/978-981-15-1216-2_2/,  ""10.1109/ACCESS.2020.2973207/,  ""10.1007/s13278-020-0629-z/,  ""10.1016/B978-0-12-819445-4.00016-3/,  ""10.1109/ic-ETITE47903.2020.211/,  ""10.1016/j.wpi.2020.101968/,  ""10.3233/IDA-194669/,  ""10.1109/ACCESS.2020.2994450/,  ""10.1016/j.eswa.2020.113691/,  ""10.1109/ICCES48766.2020.9137924/,  ""10.1007/978-3-030-52485-2_11/,  ""10.1007/978-981-15-8101-4_43/,  ""10.1109/ICAIIS49377.2020.9194885/,  ""10.1007/978-3-030-60450-9_55/,  ""10.1007/978-3-030-60975-7_18/,  ""10.1155/2020/3915036/,  ""10.1016/j.knosys.2020.106487/,  ""10.12720/jait.11.2.71-77/,  ""10.1109/SCCC51225.2020.9281189/,  ""10.1109/CyberC49757.2020.00036/,  ""10.1166/jctn.2020.9442/,  ""10.1109/NICS51282.2020.9335865/,  ""10.4018/IJIRR.2020010101/,  ""10.1007/978-3-030-01520-6_25/,  ""10.4018/978-1-5225-7338-8.ch008/,  ""10.1007/978-981-13-1056-0_41/,  ""10.1007/978-3-030-03146-6_47/,  ""10.1007/978-981-13-1708-8_26/,  ""10.4018/978-1-5225-8362-2.ch049/,  ""10.1007/978-3-030-15712-8_56/,  ""10.1007/978-3-030-02985-2_2/,  ""10.2197/ipsjjip.27.404/,  ""10.1007/978-3-030-16272-6_11/,  ""10.1109/EuroSPW.2019.00031/,  ""10.1109/ACCESS.2019.2925819/,  ""10.1016/j.cie.2019.106063/,  ""10.1007/978-3-319-91815-0_5/,  ""10.1007/978-981-15-0758-8_14/,  ""10.1007/978-981-13-1927-3_15/,  ""10.1109/ACCESS.2019.2953918/,  ""10.1109/BRACIS.2019.00144/,  ""10.1109/SNPD.2019.8935711/,  ""10.1109/ASYU48272.2019.8946379/,  ""10.36535/0548-0027-2019-12-4/,  ""10.1109/CIC48465.2019.00029/,  ""10.3103/S0005105519060062/,  ""10.1007/978-3-030-29894-4_19/,  ""10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00232/,  ""10.1109/STC-CSIT.2019.8929819/,  ""10.1109/SP.2019.00012/,  ""10.1109/ACCESS.2018.2885698/,  ""10.2478opets-2019-0059/,  ""10.1007/s41109-019-0125-4/,  ""10.1007/978-981-10-6319-0_5/,  ""10.1007/978-3-319-76941-7_38/,  ""10.1061/9780784481288.050/,  ""10.1016/j.procs.2018.08.199/,  ""10.1016/j.procs.2018.07.267/,  ""10.1007/978-3-319-76941-7_69/,  ""10.1016/j.procs.2018.05.028/,  ""10.4018/978-1-5225-2805-0.ch009/,  ""10.1007/978-3-319-93818-9_32/,  ""10.1007/978-3-319-98812-2_46/,  ""10.1007/s11573-018-0897-5/,  ""10.1007/978-3-319-90092-6_14/,  ""10.1007/978-3-319-98812-2_13/,  ""10.1007/978-3-319-95522-3_10/,  ""10.1016/j.ijdrr.2018.02.003/,  ""10.1007/978-3-319-92901-9_3/,  ""10.1108/IJPCC-D-18-00008/,  ""10.1016/j.procs.2018.07.210/,  ""10.1007/978-981-10-8198-9_34/,  ""10.1007/978-3-030-03056-8_10/,  ""10.1109/FSKD.2018.8687274/,  ""10.1109/iSAI-NLP.2018.8692858/,  ""10.1109/SIET.2018.8693213/,  ""10.1109/ICCAIRO.2018.00016/,  ""10.1109/ICCUBEA.2018.8697765/,  ""10.1109/ICACCAF.2018.8776683/,  ""10.1111/coin.12117/,  ""10.1007/978-3-319-77116-8_29/,  ""10.1109/CSCI46756.2018.00060/,  ""10.1109/ICACI.2018.8377555/,  ""10.1109/DSC.2018.00015/,  ""10.1109/SNPD.2018.8441072/,  ""10.1109/ICMLC.2018.8527039/,  ""10.1109/ASONAM.2018.8508285/,  ""10.1109/BigData.2018.8622556/,  ""10.1109/IISA.2017.8316358/,  ""10.1109/TCSS.2017.2720632/,  ""10.1109/ITSC.2017.8317650/,  ""10.1109/TII.2017.2695371/,  ""10.1109/ICCCBDA.2017.7951886/,  ""10.1007/978-981-10-7359-5_9/,  ""10.1109/RE.2017.14/,  ""10.1007/s41870-017-0015-x/,  ""10.1109/ACCESS.2017.2679227/,  ""10.1007/978-3-319-70139-4_21/,  ""10.1007/978-3-319-64930-6_13/,  ""10.3233/IDA-160048/,  ""10.1115/1.4037478/,  ""10.1109/ICSC.2017.36/,  ""10.1109/ICCONS.2017.8250665/,  ""10.1109/ICBDA.2017.8078799/,  ""10.1007/978-3-319-60240-0_29/,  ""10.1007/s12572-017-0197-2/,  ""10.1007/978-3-319-63315-2_27/,  ""10.1109/JCDL.2017.7991567/,  ""10.1109/ITOEC.2017.8122444/,  ""10.1109/ACCESS.2017.2740982/,  ""10.1109/ICBDA.2017.8078815/,  ""10.1109/ICIS.2017.7960039/,  ""10.1109/ICTS.2017.8265681/,  ""10.1109/ICCONS.2017.8250749/,  ""10.1109/BigData.2017.8258136/,  ""10.1109/ICCONS.2017.8250536/,  ""10.1007/s00354-017-0015-1/,  ""10.4018/978-1-5225-0648-5.ch005/,  ""10.1109/TDSC.2017.2681672/,  ""10.1007/978-3-319-68456-7_7/,  ""10.1109/CSCI.2017.152/,  ""10.1109/UIC-ATC.2017.8397567/,  ""10.1007/978-3-319-59536-8_9/,  ""10.1109/ICICTM.2016.7890783/,  ""10.1109/WI.2016.0022/,  ""10.1109/FSKD.2016.7603402/,  ""10.1109/BigData.2016.7841060/,  ""10.1007/s13278-016-0329-x/,  ""10.1109/GET.2016.7916853/,  ""10.1109/ICC.2016.7511392/,  ""10.1109/ICCIA.2016.15/,  ""10.1109/ACCESS.2016.2594194/,  ""10.1109/RADIOELEK.2016.7477388/,  ""10.1587/transinf.2016SLL0006/,  ""10.1109/RoboMech.2016.7813140/,  ""10.1109/ICITEED.2016.7863313/,  ""10.1007/978-3-319-41111-8_2/,  ""10.1587/transinf.2015EDP7474/,  ""10.1186/s40649-016-0028-9/,  ""10.1007/978-3-319-48740-3_8/,  ""10.1109/ITNEC.2016.7560479/,  ""10.1007/978-81-322-2523-2_73/,  ""10.1007/s13278-015-0275-z/,  ""10.1007/s13278-015-0282-0/,  ""10.1177/0002764215580618/,  ""10.1007/978-3-319-25591-0_44/,  ""10.1016/j.eswa.2015.02.025/,  ""10.1109/DSAA.2015.7344830/,  ""10.1109/FSKD.2015.7382029/,  ""10.1016/j.procs.2015.04.016/,  ""10.1109/ICIST.2015.7289041/,  ""10.1007/978-3-319-14998-1_3/,  ""10.1109/SITA.2015.7358413/,  ""10.1007/978-3-319-20807-7_38/,  ""10.1109/TBDATA.2015.2506159/,  ""10.1109/Agro-Geoinformatics.2015.7248109/,  ""10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.115/,  ""10.1109/ICMLA.2015.142/,  ""10.1109/SmartCity.2015.94/,  ""10.1007/978-3-319-18117-2_1/,  ""10.1007/978-3-319-27237-5_11/,  ""10.1109/DSAA.2015.7344832/,  ""10.1108/EL-05-2014-0084/,  ""10.4018/ijiit.2015010103/,  ""10.1109/ICCSE.2014.6926435/,  ""10.1109/EALS.2014.7009503/,  ""10.1109/IJCNN.2014.6889589/,  ""10.1109/ICRTIT.2014.6996189/,  ""10.1007/s11069-014-1217-1/,  ""10.1109/TEMU.2014.6917760/,  ""10.1109/ICDE.2014.6816706/,  ""10.1109/TLT.2013.2296520/,  ""10.1109/FSKD.2014.6980904/,  ""10.4236/jcc.2014.214006/,  ""10.1109/JPROC.2014.2366052/,  ""10.1007/978-3-319-01778-5_24/,  ""10.2139/ssrn.2473544/,  ""10.1007/978-3-319-07443-6_8/,  ""10.1007/978-3-319-05579-4_14/,  ""10.1007/978-3-319-08010-9_54/,  ""10.1007/978-3-319-09761-9_19/,  ""10.1007/978-3-319-12027-0_10/,  ""10.1007/978-3-662-45924-9_8/,  ""10.1587/transinf.E97.D.1557/,  ""10.1527/tjsai.29.483/,  ""10.1109/ICNC.2013.6818095/,  ""10.1109/ICET.2013.6743524/,  ""10.4018/978-1-4666-4213-3.ch007/,  ""10.1109/ICME.2013.6607607/,  ""10.1109/BMEI.2013.6747026/,  ""10.1109/Geoinformatics.2013.6626207/,  ""10.1109/ICIS.2013.6607883/,  ""10.1007/978-3-642-34531-9_13/,  ""10.1007/978-3-642-39787-5_41/,  ""10.1109/Geoinformatics.2013.6626128/,  ""10.1007/978-1-4471-4739-8_22/,  ""10.1007/978-94-007-5070-8_6/,  ""10.1007/978-3-642-35341-3_14/,  ""10.1007/978-3-642-35142-6_1/,  ""10.1109/PASSAT/SocialCom.2011.213/,  ""10.1109/ICoAC.2011.6165203/,  ""10.7763/IJKE.2015.V1.19/,  ""10.4028/www.scientific.net/AMM.573.560/,  ""10.1007/s13042-017-0750-0/,  ""10.1007/s10586-017-1517-9/,  ""10.4304/jmm.9.5.635-643/,  ""10.21605/cukurovaummfd.310341/,  ""10.1007/s00291-019-00559-8/,  ""10.1371/journal.pone.0210689/,  ""10.3389/fdata.2019.00018/,  ""10.2140/involve.2019.12.1035/,  ""10.2196/jmir.4305/,  ""10.2196/medinform.9170/,  ""10.3389/fams.2018.00041/,  ""10.1371/journal.pone.0223317/,  ""10.22430/22565337.1454/,  ""10.1007/s10844-020-00605-w/,  ""10.1080/23311983.2020.1724593/,  ""10.29130/dubited.748366/,  ""10.1007/s00799-020-00293-5/,  ""10.1080/0952813X.2020.1785019/,  ""10.1002/cpe.6673/,  ""10.1080/01616846.2020.1827618/,  ""10.21923/jesd.906211/,  ""10.1007/s10489-022-03241-9/,  ""10.1007/s00500-022-07267-6/,  ""10.1007/s12065-021-00598-7/',
      group:
        "SIGIR '10: Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrievalJuly 2010  Pages   841–842https://doi.org/10.1145/1835449.1835643",
      year: "",
      authors: "Bharath Sriram",
      doi: "10.1145/1835449.1835643",
    },
    {
      FIELD1: 26,
      id: "7D17A093",
      name: "Named entity recognition in query",
      url: "https://dl.acm.org/doi/abs/10.1145/1571941.1571989",
      abstract:
        "\nThis paper addresses the problem of Named Entity Recognition in Query (NERQ), which involves detection of the named entity in a given query and classification of the named entity into predefined classes. NERQ is potentially useful in many applications in web search. The paper proposes taking a probabilistic approach to the task using query log data and Latent Dirichlet Allocation. We consider contexts of a named entity (i.e., the remainders of the named entity in queries) as words of a document, and classes of the named entity as topics. The topic model is constructed by a novel and general learning method referred to as WS-LDA (Weakly Supervised Latent Dirichlet Allocation), which employs weakly supervised learning (rather than unsupervised learning) using partially labeled seed entities. Experimental results show that the proposed method based on WS-LDA can accurately perform NERQ, and outperform the baseline methods.\n",
      citations:
        ' ""10.1007/978-981-16-6482-3_44/,  ""10.1109/IMCOM53663.2022.9721722/,  ""10.1109/ICBATS54253.2022.9759051/,  ""10.1109/TKDE.2020.3038670/,  ""10.1109/ICAIT56197.2022.9862628/,  ""10.1109/ICCOINS49721.2021.9497155/,  ""10.1109/ACCESS.2021.3107939/,  ""10.1109/ICSCC51209.2021.9528127/,  ""10.1007/978-3-030-88304-1_28/,  ""10.1109/BigData52589.2021.9671697/,  ""10.1007/978-3-030-45439-5_6/,  ""10.1007/978-3-658-29550-9_15/,  ""10.1109/ICDS50568.2020.9268762/,  ""10.1109/TKDE.2020.2981314/,  ""10.1017/S1351324918000281/,  ""10.1007/978-3-030-20948-3_12/,  ""10.1007/978-3-030-21348-0_11/,  ""10.1109/MC.2018.2888763/,  ""10.12677/CSA.2019.98167/,  ""10.1007/978-3-030-27615-7_31/,  ""10.1109/BIBM47256.2019.8983247/,  ""10.1109/AICCSA47632.2019.9035212/,  ""10.1007/978-3-319-93935-3_7/,  ""10.1587/transinf.2017EDP7372/,  ""10.1108/JD-09-2017-0133/,  ""10.2200/S00881ED1V01Y201810DTM053/,  ""10.1007/978-3-319-93935-3_1/,  ""10.1109/ICWR.2017.7959301/,  ""10.1016/j.datak.2017.02.001/,  ""10.3233/WEB-170362/,  ""10.1007/978-3-319-47650-6_9/,  ""10.1007/978-3-319-43997-6_38/,  ""10.1007/978-3-319-44564-9_17/,  ""10.2200/S00714ED1V01Y201603ICR048/,  ""10.1109/COMPSAC.2016.109/,  ""10.1109/TKDE.2014.2327028/,  ""10.1007/s11280-013-0267-8/,  ""10.1109/CIT/IUCC/DASC/PICOM.2015.124/,  ""10.1016/j.procs.2015.09.236/,  ""10.2139/ssrn.3199173/,  ""10.2139/ssrn.3199174/,  ""10.1108/IJWIS-06-2014-0022/,  ""10.1109/TKDE.2014.2313872/,  ""10.1002/tee.21937/,  ""10.1109/HiPC.2013.6799137/,  ""10.4018/978-1-4666-4054-2.ch005/,  ""10.1109/ICDIM.2013.6694007/,  ""10.1007/978-3-642-37401-2_51/,  ""10.1007/978-3-642-37996-3_11/,  ""10.1007/978-3-642-38824-8_40/,  ""10.1007/978-3-642-40501-3_17/,  ""10.1007/978-3-642-41154-0_13/,  ""10.1108/17427371211283038/,  ""10.1109/CCIS.2011.6045022/,  ""10.1007/978-3-642-20847-8_7/,  ""10.2139/ssrn.3199534/,  ""10.1109/IRI.2010.5558955/,  ""10.1007/978-3-642-15464-5_28/,  ""10.1007/978-3-642-15431-7_13/,  ""10.1002/asi.24071/,  ""10.1002/asi.24220/,  ""10.1002/asi.24282/,  ""10.1007/s13369-020-05022-3/,  ""10.1007/s10462-021-09983-1/,  ""10.1017/S1351324922000110/',
      group:
        "SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrievalJuly 2009  Pages   267–274https://doi.org/10.1145/1571941.1571989",
      year: "",
      authors: "Jiafeng Guo",
      doi: "10.1145/1571941.1571989",
    },
    {
      FIELD1: 27,
      id: "76FDA1E2",
      name: "The automatic construction of large-scale corpora for summarization research",
      url: "https://dl.acm.org/doi/pdf/10.1145/312624.312668",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 28,
      id: "7B4696F8",
      name: "Ranking community answers by modeling question-answer relationships via analogical reasoning",
      url: "https://dl.acm.org/doi/abs/10.1145/1571941.1571974",
      abstract:
        "\nThe method of finding high-quality answers has significant impact on user satisfaction in community question answering systems. However, due to the lexical gap between questions and answers as well as spam typically existing in user-generated content, filtering and ranking answers is very challenging. Previous solutions mainly focus on generating redundant features, or finding textual clues using machine learning techniques; none of them ever consider questions and their answers as relational data but instead model them as independent information. Moreover, they only consider the answers of the current question, and ignore any previous knowledge that would be helpful to bridge the lexical and semantic gap. We assume that answers are connected to their questions with various types of latent links, i.e. positive indicating high-quality answers, negative links indicating incorrect answers or user-generated spam, and propose an analogical reasoning-based approach which measures the analogy between the new question-answer linkages and those of relevant knowledge which contains only positive links; the candidate answer which has the most analogous link is assumed to be the best answer. We conducted experiments based on 29.8 million Yahoo!Answer question-answer threads and showed the effectiveness of our approach.\n",
      citations:
        ' ""10.1007/s42979-019-0048-2/,  ""10.1016/j.asoc.2020.106125/,  ""10.1109/CSII.2019.00011/,  ""10.5057/ijae.IJAE-D-19-00007/,  ""10.5057/ijae.IJAE-D-18-00023/,  ""10.1109/CSII.2018.00036/,  ""10.1109/SNPD.2018.8441035/,  ""10.1109/TSMC.2016.2580606/,  ""10.5057/ijae.IJAE-D-16-00023/,  ""10.1007/978-3-319-70139-4_71/,  ""10.1109/TSC.2015.2446991/,  ""10.1007/978-3-319-55705-2_30/,  ""10.1109/ICIS.2016.7550847/,  ""10.2139/ssrn.2736568/,  ""10.1007/978-3-319-30146-4_4/,  ""10.1007/978-3-319-40415-8_12/,  ""10.5057/ijae.IJAE-D-15-00031/,  ""10.1109/SNPD.2015.7176254/,  ""10.1007/978-3-319-25816-4_25/,  ""10.1109/SNPD.2014.6888719/,  ""10.1016/j.ins.2013.10.030/,  ""10.5057/jjske.12.15/,  ""10.4018/ijsi.2013100102/,  ""10.4018/ijsi.2013040105/,  ""10.1007/978-3-642-28670-4_1/,  ""10.1109/IJCNN.2012.6252435/,  ""10.2964/jsik.21-041/,  ""10.1214/09-AOAS321/,  ""10.1109/FSKD.2010.5569521/,  ""10.1007/978-3-642-14246-8_59/,  ""10.1371/journal.pone.0173610/,  ""10.1007/s11063-020-10284-x/,  ""10.1371/journal.pone.0085236/,  ""10.3389/fncom.2016.00064/',
      group:
        "SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrievalJuly 2009  Pages   179–186https://doi.org/10.1145/1571941.1571974",
      year: "",
      authors: "Xin-Jing Wang",
      doi: "10.1145/1571941.1571974",
    },
    {
      FIELD1: 29,
      id: "79E8F68A",
      name: "Development of a modern OPAC: from REVTOLC to MARIAN",
      url: "https://dl.acm.org/doi/abs/10.1145/160688.160730",
      abstract:
        "\nSince 1986 we have investigated the problems and possibilities of applying modern information retrieval methods to large online public access library catalogs (OPACs). In the Retrieval Experiment—Virginia Tech OnLine Catalog (REVTOLC) study we carried out a large pilot test in 1987 and a larger, controlled investigation in 1990, with 216 users and roughly 500,000 MARC records. Results indicated that a forms-based interface coupled with vector and relevance feedback retrieval methods would be well received. Recent efforts developing the Multiple Access and Retrieval of Information with Annotations (MARIAN) system have involved used of a specially developed object-oriented DBMS, construction of a client running under NeXTSTEP, programming of a distributed server with a thread  assigned to each user session to increase concurrency on a small network of NeXTs, refinement of algorithms to use objects and stopping rules for greater efficiency, usability testing and iterative interface refinement.\n",
      citations:
        ' ""10.2200/S00474ED1V01Y201301ICR026/,  ""10.1109/INFVIS.2002.1173146/,  ""10.1007/3-540-45735-6_18/,  ""10.1007/3-540-45490-X_47/,  ""10.1007/3-540-44796-2_16/',
      group:
        "SIGIR '93: Proceedings of the 16th annual international ACM SIGIR conference on Research and development in information retrievalJuly 1993  Pages   248–259https://doi.org/10.1145/160688.160730",
      year: "",
      authors: "Edward A. Fox",
      doi: "10.1145/160688.160730",
    },
    {
      FIELD1: 30,
      id: "7B3F25FB",
      name: "Comparing interactive information retrieval systems across sites: the TREC-6 interactive track matrix experiment",
      url: "https://dl.acm.org/doi/pdf/10.1145/290941.290986",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 31,
      id: "7D613389",
      name: "An effective approach to document retrieval via utilizing WordNet and recognizing phrases",
      url: "https://dl.acm.org/doi/abs/10.1145/1008992.1009039",
      abstract:
        "\nNoun phrases in queries are identified and classified into four types: proper names, dictionary phrases, simple phrases and complex phrases. A document has a phrase if all content words in the phrase are within a window of a certain size. The window sizes for different types of phrases are different and are determined using a decision tree. Phrases are more important than individual terms. Consequently, documents in response to a query are ranked with matching phrases given a higher priority. We utilize WordNet to disambiguate word senses of query terms. Whenever the sense of a query term is determined, its synonyms, hyponyms, words from its definition and its compound words are considered for possible additions to the query. Experimental results show that our approach yields between 23% and 31% improvements over the best-known results on the TREC 9, 10 and 12 collections for short (title only) queries, without using Web data.\n",
      citations:
        ' ""10.1007/978-3-030-71187-0_130/,  ""10.1007/978-3-030-06170-8_5/,  ""10.1109/ICSIDEMPC49020.2020.9299579/,  ""10.1007/s12046-018-1022-8/,  ""10.1109/ACCESS.2019.2894679/,  ""10.4018/978-1-5225-5191-1.ch100/,  ""10.23919/ELMAR.2018.8534677/,  ""10.1109/COMPSAC.2017.35/,  ""10.1007/978-981-10-6805-8_18/,  ""10.4018/IJIRR.2017070101/,  ""10.1007/978-3-319-41754-7_26/,  ""10.1109/ICACT.2016.7423528/,  ""10.1007/s11390-016-1657-z/,  ""10.1016/j.ipm.2015.04.002/,  ""10.1017/S0269888913000167/,  ""10.1007/978-3-319-16354-3_30/,  ""10.1177/0165551514562704/,  ""10.1007/s10115-012-0493-x/,  ""10.1007/978-1-4471-4555-4_7/,  ""10.1007/s11257-012-9127-y/,  ""10.4018/978-1-60960-593-3.ch002/,  ""10.1109/ICEEI.2011.6021532/,  ""10.1007/978-3-642-13025-0_1/,  ""10.1007/978-3-642-15754-7_20/,  ""10.1007/978-3-0348-0031-0_18/,  ""10.1108/17427371011033299/,  ""10.1007/978-3-642-04447-2_14/,  ""10.1007/978-3-642-10242-4_17/,  ""10.1007/978-3-540-68083-3_43/,  ""10.1007/978-3-540-68636-1_21/,  ""10.1007/978-3-540-89376-9_13/,  ""10.2139/ssrn.3199399/,  ""10.2139/ssrn.3199367/,  ""10.1109/WIRI.2005.12/,  ""10.1108/17440080580000082/,  ""10.1007/s10586-018-2054-x/,  ""10.1007/s10115-018-1267-x/,  ""10.1007/s10115-018-1322-7/,  ""10.1007/s10115-020-01451-6/',
      group:
        "SIGIR '04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2004  Pages   266–272https://doi.org/10.1145/1008992.1009039",
      year: "",
      authors: "Shuang Liu",
      doi: "10.1145/1008992.1009039",
    },
    {
      FIELD1: 32,
      id: "79E0597E",
      name: "A belief network model for IR",
      url: "https://dl.acm.org/doi/pdf/10.1145/243199.243272",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 33,
      id: "80BA211F",
      name: "An interactive algorithm for asking and incorporating feature feedback into support vector machines",
      url: "https://dl.acm.org/doi/abs/10.1145/1277741.1277758",
      abstract:
        '\nStandard machine learning techniques typically require ample training data in the form of labeled instances. In many situations it may be too tedious or costly to obtain sufficient labeled data for adequate classifier performance. However, in text classification, humans can easily guess the relevance of features, that is, words that are indicative of a topic, thereby enabling the classifier to focus its feature weights more appropriately in the absence of sufficient labeled data. We will describe an algorithm for tandem learning that begins with a couple of labeled instances, and then at each iteration recommends features and instances for a human to label. Tandem learning using an "oracle" results in much better performance than learning on only features or only instances. We find that humans can emulate the oracle to an extent that results in performance (accuracy) comparable to that of the oracle. Our unique experimental design helps factor out system error from human error, leading to a better understanding of when and why interactive feature selection works.\n',
      citations:
        ' ""10.1109/BigData52589.2021.9671909/,  ""10.1109/TVCG.2018.2834341/,  ""10.1109/IJCNN.2019.8851706/,  ""10.1007/s10994-017-5671-3/,  ""10.1007/s10618-016-0469-7/,  ""10.1109/BigData.2014.7004356/,  ""10.1007/978-3-319-07983-7_18/,  ""10.1109/ICITCS.2013.6717784/,  ""10.1109/CISP.2010.5646961/,  ""10.1109/ICNIDC.2009.5360803/',
      group:
        "SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2007  Pages   79–86https://doi.org/10.1145/1277741.1277758",
      year: "",
      authors: "Hema Raghavan",
      doi: "10.1145/1277741.1277758",
    },
    {
      FIELD1: 34,
      id: "7BDBE804",
      name: "Cross-document summarization by concept classification",
      url: "https://dl.acm.org/doi/abs/10.1145/564376.564399",
      abstract:
        "\nIn this paper we describe a Cross Document Summarizer XDoX designed specifically to summarize large document sets (50-500 documents and more). Such sets of documents are typically obtained from routing or filtering systems run against a continuous stream of data, such as a newswire. XDoX works by identifying the most salient themes within the set (at the granularity level that is regulated by the user) and composing an extraction summary, which reflects these main themes. In the current version, XDoX is not optimized to produce a summary based on a few unrelated documents; indeed, such summaries are best obtained simply by concatenating summaries of individual documents. We show examples of summaries obtained in our tests as well as from our participation in the first Document Understanding Conference (DUC).\n",
      citations:
        ' ""10.1007/978-3-658-29550-9_15/,  ""10.1007/978-3-030-60887-3_26/,  ""10.1007/978-3-319-68783-4_10/,  ""10.1016/B978-0-12-803455-2.00030-5/,  ""10.1109/ReTIS.2015.7232905/,  ""10.1111/j.1467-8640.2012.00435.x/,  ""10.4018/978-1-4666-0318-9.ch002/,  ""10.1007/978-1-4471-4739-8_3/,  ""10.1109/ICCCNET.2008.4787677/,  ""10.1007/978-3-540-74851-9_25/,  ""10.1002/asi.20618/,  ""10.1007/11880592_46/,  ""10.1007/11880592_24/',
      group:
        "SIGIR '02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2002  Pages   121–128https://doi.org/10.1145/564376.564399",
      year: "",
      authors: "Hilda Hardy",
      doi: "10.1145/564376.564399",
    },
    {
      FIELD1: 35,
      id: "7C9725E8",
      name: "Predicting category accesses for a user in a structured information space",
      url: "https://dl.acm.org/doi/abs/10.1145/564376.564390",
      abstract:
        "\nIn a categorized information space, predicting users' information needs at the category level can facilitate personalization, caching and other topic-oriented services. This paper presents a two-phase model to predict the category of a user's next access based on previous accesses. Phase 1 generates a snapshot of a user's preferences among categories based on a temporal and frequency analysis of the user's access history. Phase 2 uses the computed preferences to make predictions at different category granularities. Several alternatives for each phase are evaluated, using the rating behaviors of on-line raters as the form of access considered. The results show that a method based on re-access pattern and frequency analysis of a user's whole history has the best prediction quality, even over a path-based method (Markov model) that uses the combined history of all users.\n",
      citations:
        ' ""10.1016/j.ipm.2015.06.009/,  ""10.4018/978-1-4666-2542-6.ch009/,  ""10.1108/00251741311326590/,  ""10.1002/asi.21071/,  ""10.1108/10662240510615182/,  ""10.1007/978-3-540-45228-7_15/',
      group:
        "SIGIR '02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2002  Pages   65–72https://doi.org/10.1145/564376.564390",
      year: "",
      authors: "Mao Chen",
      doi: "10.1145/564376.564390",
    },
    {
      FIELD1: 36,
      id: "7B0F0125",
      name: "Distributional clustering of words for text classification",
      url: "https://dl.acm.org/doi/pdf/10.1145/290941.290970",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 37,
      id: "7B50FC31",
      name: "Document language models, query models, and risk minimization for information retrieval",
      url: "https://dl.acm.org/doi/abs/10.1145/383952.383970",
      abstract:
        "\nWe present a framework for information retrieval that combines document models and query models using a probabilistic ranking function based on Bayesian decision theory. The framework suggests an operational retrieval model that extends recent developments in the language modeling approach to information retrieval.  A language model for each document is estimated, as well as a language model for each query, and the retrieval problem is cast in terms of risk minimization. The query language model can be exploited to model user preferences, the context of a query, synonomy and word senses. While recent work has incorporated word translation models for this purpose, we introduce a new method using Markov chains defined on a set of documents to estimate the query models.  The Markov chain method has connections to algorithms from link analysis and social networks.  The new approach is evaluated on TREC collections and compared to the basic language modeling approach and vector space models together with query expansion using Rocchio.  Significant improvements are obtained over standard query expansion methods for strong baseline TF-IDF systems, with the greatest improvements attained for short queries on Web data.\n",
      citations:
        ' ""10.1002/asi.24619/,  ""10.5772/intechopen.104784/,  ""10.1007/978-3-031-14054-9_20/,  ""10.1007/978-3-030-72240-1_49/,  ""10.1007/978-3-030-72113-8_10/,  ""10.1142/S0219649220400031/,  ""10.1109/CCCI49893.2020.9256673/,  ""10.1007/978-3-030-66527-2_26/,  ""10.1109/TKDE.2018.2879863/,  ""10.1109/ACCESS.2019.2894809/,  ""10.1631/FITEE.1700105/,  ""10.1142/S021819401950030X/,  ""10.1109/IRC.2019.00075/,  ""10.1007/978-3-319-59463-7_25/,  ""10.1007/978-3-319-73706-5_22/,  ""10.1007/978-3-319-94809-6_1/,  ""10.4018/978-1-5225-5191-1.ch100/,  ""10.1109/CSIEC.2018.8405418/,  ""10.1186/s40537-017-0089-0/,  ""10.1109/CCDC.2017.7978797/,  ""10.1007/978-3-319-70145-5_15/,  ""10.1109/COMPSAC.2017.265/,  ""10.4018/IJIRR.2017070101/,  ""10.1007/978-3-319-39937-9_36/,  ""10.1587/transinf.2016EDP7190/,  ""10.1109/ICSEC.2016.7859913/,  ""10.1007/978-981-10-0515-2_14/,  ""10.1007/978-3-319-30671-1_65/,  ""10.1016/j.is.2015.10.011/,  ""10.1007/s12046-015-0413-3/,  ""10.2139/ssrn.3199176/,  ""10.1007/978-3-319-28940-3_4/,  ""10.1007/978-3-319-28940-3_37/,  ""10.1007/s11280-013-0267-8/,  ""10.1109/CIST.2014.7016631/,  ""10.1007/978-3-642-54798-0_4/,  ""10.1109/TMM.2014.2326836/,  ""10.1007/s10791-013-9237-0/,  ""10.1007/s11390-014-1438-5/,  ""10.5715/jnlp.21.921/,  ""10.1108/IJPCC-03-2014-0020/,  ""10.1177/0165551513507415/,  ""10.1007/s10115-012-0590-x/,  ""10.1109/WCRE.2013.6671281/,  ""10.1002/asi.22916/,  ""10.1109/ICACCS.2013.6938717/,  ""10.1109/ICASSP.2013.6639326/,  ""10.1007/s13735-013-0039-3/,  ""10.1109/NGNS.2012.6656099/,  ""10.1080/18756891.2012.718108/,  ""10.1109/ICASSP.2012.6289080/,  ""10.1109/ICMLC.2012.6359677/,  ""10.5715/jnlp.19.121/,  ""10.1007/978-3-642-32498-7_19/,  ""10.1007/978-3-642-33506-8_82/,  ""10.1007/978-3-642-35341-3_2/,  ""10.1002/9781118562796.ch5/,  ""10.1109/ICEEE.2011.6106659/,  ""10.1007/978-3-642-24396-7_13/,  ""10.1007/978-3-642-14267-3_1/,  ""10.1007/978-3-642-23017-2_1/,  ""10.1007/978-1-4419-8462-3_3/,  ""10.1007/978-3-642-17829-0_10/,  ""10.1007/978-3-642-19437-5_21/,  ""10.1007/978-3-642-24396-7_17/,  ""10.4018/978-1-60960-537-7.ch013/,  ""10.1109/NLPKE.2011.6138167/,  ""10.1109/NWeSP.2011.6088192/,  ""10.1109/ICEMMS.2011.6015771/,  ""10.1007/978-3-642-15470-6_27/,  ""10.1109/ICICISYS.2010.5658362/,  ""10.1109/ICNC.2010.5584041/,  ""10.1007/978-3-642-14556-8_27/,  ""10.1109/NLPKE.2010.5587826/,  ""10.1109/FSKD.2010.5569354/,  ""10.1007/978-3-642-17187-1_49/,  ""10.1109/ICMWI.2010.5647831/,  ""10.1007/978-3-642-15998-5_5/,  ""10.2200/S00235ED1V01Y201004ICR015/,  ""10.1002/asi.21315/,  ""10.1016/j.ipm.2009.09.005/,  ""10.1109/WIAMIS.2009.5031421/,  ""10.1109/ICMLC.2009.5212408/,  ""10.1007/978-3-642-04447-2_26/,  ""10.1007/978-3-642-04180-8_30/,  ""10.1109/CSIE.2009.1090/,  ""10.4018/jdwm.2009080703/,  ""10.1007/978-3-540-78646-7_73/,  ""10.1109/ICMLC.2008.4620852/,  ""10.1109/GRC.2008.4664789/,  ""10.1007/978-3-540-78646-7_44/,  ""10.1007/978-1-4020-4746-6_7/,  ""10.1007/978-3-540-78646-7_31/,  ""10.1007/978-3-540-71496-5_24/,  ""10.1007/978-3-540-77018-3_48/,  ""10.1007/978-3-540-73888-6_18/,  ""10.1631/jzus.2007.A0871/,  ""10.1007/s10791-006-9019-z/,  ""10.1016/j.ipm.2004.11.003/,  ""10.1007/s11767-006-0044-2/,  ""10.1007/0-387-29295-0_78/,  ""10.1109/TSA.2005.851875/,  ""10.1007/978-3-642-17103-1_51/,  ""10.1201/9781420030884.ch19/,  ""10.1007/1-4020-8090-5_19/,  ""10.1201/9780203507223.pt2/,  ""10.1109/ICDE.2003.1260777/,  ""10.1002/asi.10300/,  ""10.1007/3-540-44886-1_19/,  ""10.1007/978-94-017-0171-6_3/,  ""10.1007/3-540-45886-7_14/,  ""10.4028/www.scientific.net/AMM.303-306.1420/,  ""10.1371/journal.pone.0050112/,  ""10.4028/www.scientific.net/JERA.16.110/,  ""10.1371/journal.pone.0104707/,  ""10.1007/s11042-020-10305-w/,  ""10.1007/s00521-020-05534-x/,  ""10.2196/30161/',
      group:
        "SIGIR '01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrievalSeptember 2001  Pages   111–119https://doi.org/10.1145/383952.383970",
      year: "",
      authors: "John Lafferty",
      doi: "10.1145/383952.383970",
    },
    {
      FIELD1: 38,
      id: "7ECC05A5",
      name: "An automatic weighting scheme for collaborative filtering",
      url: "https://dl.acm.org/doi/abs/10.1145/1008992.1009051",
      abstract:
        "\nCollaborative filtering identifies information interest of a particular user based on the information provided by other similar users. The memory-based approaches for collaborative filtering (e.g., Pearson correlation coefficient approach) identify the similarity between two users by comparing their ratings on a set of items. In these approaches, different items are weighted either equally or by some predefined functions. The impact of rating discrepancies among different users has not been taken into consideration. For example, an item that is highly favored by most users should have a smaller impact on the user-similarity than an item for which different types of users tend to give different ratings. Even though simple weighting methods such as variance weighting try to address this problem, empirical studies have shown that they are ineffective in improving the performance of collaborative filtering. In this paper, we present an optimization algorithm to automatically compute the weights for different items based on their ratings from training users. More specifically, the new weighting scheme will create a clustered distribution for user vectors in the item space by bringing users of similar interests closer and separating users of different interests more distant. Empirical studies over two datasets have shown that our new weighting scheme substantially improves the performance of the Pearson correlation coefficient method for collaborative filtering.\n",
      citations:
        ' ""10.1007/s00521-022-06966-3/,  ""10.1007/978-981-16-0666-3_20/,  ""10.1016/j.matpr.2021.04.411/,  ""10.1007/978-3-030-86486-6_22/,  ""10.1007/978-3-030-47426-3_10/,  ""10.1007/978-3-030-61534-5_13/,  ""10.1016/j.procs.2020.03.372/,  ""10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00099/,  ""10.1109/ICDMW51313.2020.00041/,  ""10.1109/TCYB.2019.2939390/,  ""10.1016/j.knosys.2020.106434/,  ""10.1109/ACCESS.2019.2937508/,  ""10.1007/s42452-019-1142-8/,  ""10.1109/ACCESS.2019.2897760/,  ""10.1007/s00500-016-2407-4/,  ""10.1007/978-3-319-63645-0_14/,  ""10.1007/s11042-018-5992-7/,  ""10.1109/SPAC46244.2018.8965431/,  ""10.1007/978-1-4939-7131-2_110165/,  ""10.1007/978-1-4939-7131-2_189/,  ""10.1109/TCSS.2018.2879044/,  ""10.1109/TSC.2016.2589244/,  ""10.1007/978-3-319-55705-2_5/,  ""10.1109/SERVICES.2017.22/,  ""10.1007/978-1-4614-7163-9_110165-1/,  ""10.1109/ICEDEG.2017.7962553/,  ""10.1007/978-1-4614-7163-9_189-1/,  ""10.1109/TSC.2017.2782793/,  ""10.1201/9781315374017-8/,  ""10.1109/ICWS.2016.12/,  ""10.1007/978-3-319-48051-0_14/,  ""10.1109/ICWS.2016.46/,  ""10.1109/TSC.2015.2433251/,  ""10.1186/s40064-016-1841-1/,  ""10.1109/CompComm.2016.7924909/,  ""10.1007/978-3-319-29659-3_2/,  ""10.1007/978-3-319-32025-0_18/,  ""10.1109/CIT/IUCC/DASC/PICOM.2015.282/,  ""10.1109/TSC.2014.2381611/,  ""10.1007/s11390-015-1580-8/,  ""10.1007/978-1-4899-7637-6_2/,  ""10.1587/transinf.2014EDP7174/,  ""10.1109/ISDA.2014.7066284/,  ""10.1109/ICWS.2014.47/,  ""10.1109/CBD.2014.47/,  ""10.1109/MFI.2014.6997657/,  ""10.1007/978-1-4614-7518-7_22/,  ""10.1007/978-3-642-54924-3_64/,  ""10.1007/s13278-014-0234-0/,  ""10.1109/ICME.2013.6607584/,  ""10.1109/TSMCA.2012.2210409/,  ""10.1007/978-3-642-34207-3_2/,  ""10.1007/978-3-642-37688-7_3/,  ""10.1007/978-3-642-40173-2_35/,  ""10.1007/978-3-642-34207-3_4/,  ""10.1177/0165551513480100/,  ""10.4018/jwsr.2013010103/,  ""10.1007/s11390-012-1301-5/,  ""10.1016/S1876-6102(14)00454-8/,  ""10.1007/978-3-642-37804-1_11/,  ""10.1007/978-1-4419-6287-4_4/,  ""10.1007/978-3-642-17537-4_49/,  ""10.1109/NAFIPS.2009.5156454/,  ""10.1109/CISE.2009.5366069/,  ""10.1109/IJCNN.2009.5178967/,  ""10.1007/s11135-007-9111-5/,  ""10.1007/978-3-540-87479-9_30/,  ""10.1109/INDIN.2007.4384846/,  ""10.1007/978-3-540-77226-2_67/,  ""10.4028/www.scientific.net/AMM.347-350.2365/,  ""10.1007/s12652-018-0928-7/,  ""10.1371/journal.pone.0154848/,  ""10.1007/s10489-019-01495-4/,  ""10.21541/apjess.1060744/,  ""10.1007/s11042-022-11980-7/,  ""10.1007/s10791-022-09412-z/',
      group:
        "SIGIR '04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2004  Pages   337–344https://doi.org/10.1145/1008992.1009051",
      year: "",
      authors: "Rong Jin",
      doi: "10.1145/1008992.1009051",
    },
    {
      FIELD1: 39,
      id: "7B9EE6D7",
      name: "Bead: explorations in information visualization",
      url: "https://dl.acm.org/doi/abs/10.1145/133160.133215",
      abstract:
        "\nWe describe work on the visualization of bibliographic data and, to aid in this task, the application of numerical techniques for multidimensional scaling.\nMany areas of scientific research involve complex multivariate data. One example of this is Information Retrieval. Document comparisons may be done using a large number of variables. Such conditions do not favour the more well-known methods of visualization and graphical analysis, as it is rarely feasible to map each variable onto one aspect of even a three-dimensional, coloured and textured space.\nBead is a prototype system for the graphically-based exploration of information. In this system, articles in a bibliography are represented by particles in 3-space. By using physically-based modelling techniques to  take advantage of fast methods for the approximation of potential fields, we represent the relationships between articles by their relative spatial positions. Inter-particle forces tend to make similar articles move closer to one another and dissimilar ones move apart. The result is a 3D scene which can be used to visualize patterns in the high-D information space.\n",
      citations:
        ' ""10.1007/978-1-4899-7502-7_837-1/,  ""10.1007/978-3-642-19160-2_7/,  ""10.4018/978-1-4666-0285-4.ch003/,  ""10.1016/j.ssci.2012.04.006/,  ""10.1108/20408021211223543/,  ""10.1007/978-3-642-10687-3_15/,  ""10.1007/978-3-642-15390-7_4/,  ""10.1080/01449291003767938/,  ""10.4018/jcicg.2010010104/,  ""10.2200/S00174ED1V01Y200901ICR003/,  ""10.1002/bse.661/,  ""10.1108/14684520910969934/,  ""10.1057algrave.rm.8250030/,  ""10.1057algrave.ivs.9500156/,  ""10.3758/BF03192778/,  ""10.1007/3-540-26948-7_5/,  ""10.1002/asi.20175/,  ""10.1109/HICSS.2004.1265110/,  ""10.1007/978-3-642-18638-7_13/,  ""10.1109/IV.2003.1218018/,  ""10.1007/3-540-45747-X_33/,  ""10.1007/978-3-642-55991-4_25/,  ""10.1109/INFVIS.2002.1173146/,  ""10.1109/HAPTIC.2002.998969/,  ""10.1016/S1071-5819(02)91015-3/,  ""10.1109/ENABL.2001.953424/,  ""10.1109/AUIC.2001.906274/,  ""10.1109/VR.2001.913803/,  ""10.1109/SAINT.2001.905184/,  ""10.1007/10722620_11/,  ""10.1007/3-540-44594-3_7/,  ""10.1109/ICME.2000.871068/,  ""10.1109/VL.2000.874348/,  ""10.1109/ICSMC.2000.884963/,  ""10.1109/INFVIS.2000.885099/,  ""10.1007/3-540-48155-9_9/,  ""10.1007/3-540-48155-9_21/,  ""10.1002/(SICI)1097-4571(1999)50:13&lt;1224::AID-ASI8&gt;3.0.CO;2-4/,  ""10.1109/IV.1999.781533/,  ""10.1109/VL.1999.795901/,  ""10.1007/3-540-49795-1_4/,  ""10.1109/ICMAS.1998.699294/,  ""10.1007/3-540-49653-X_32/,  ""10.1109/INFVIS.1998.729569/,  ""10.1109/SPIRE.1998.712979/,  ""10.1109/IV.1997.626486/,  ""10.1109/HICSS.1997.667430/,  ""10.1109/VL.1997.626566/,  ""10.1109/ICSMC.1997.638252/,  ""10.1007/3-540-61442-7_14/,  ""10.1109/VRAIS.1996.490532/,  ""10.1109/VISUAL.1996.567787/,  ""10.1007/3-540-57433-6_46/,  ""10.1007/3-540-57207-4_25/,  ""10.1109/VL.1993.269592/,  ""10.1109/VISUAL.1993.398863/',
      group:
        "SIGIR '92: Proceedings of the 15th annual international ACM SIGIR conference on Research and development in information retrievalJune 1992  Pages   330–337https://doi.org/10.1145/133160.133215",
      year: "",
      authors: "Matthew Chalmers",
      doi: "10.1145/133160.133215",
    },
    {
      FIELD1: 40,
      id: "7DD09999",
      name: "Query dependent ranking using K-nearest neighbor",
      url: "https://dl.acm.org/doi/abs/10.1145/1390334.1390356",
      abstract:
        "\nMany ranking models have been proposed in information retrieval, and recently machine learning techniques have also been applied to ranking model construction. Most of the existing methods do not take into consideration the fact that significant differences exist between queries, and only resort to a single function in ranking of documents. In this paper, we argue that it is necessary to employ different ranking models for different queries and onduct what we call query-dependent ranking. As the first such attempt, we propose a K-Nearest Neighbor (KNN) method for query-dependent ranking. We first consider an online method which creates a ranking model for a given query by using the labeled neighbors of the query in the query feature space and then rank the documents with respect to the query using the created model. Next, we give two offline approximations of the method, which create the ranking models in advance to enhance the efficiency of ranking. And we prove a theory which indicates that the approximations are accurate in terms of difference in loss of prediction, if the learning algorithm used is stable with respect to minor changes in training examples. Our experimental results show that the proposed online and offline methods both outperform the baseline method of using a single ranking function.\n",
      citations:
        ' ""10.1109/ACCESS.2022.3168302/,  ""10.1109/TLT.2021.3075196/,  ""10.32628/IJSRSET2183131/,  ""10.1016/j.agwat.2021.107102/,  ""10.1007/978-3-030-61534-5_12/,  ""10.1109/SMAP49528.2020.9248437/,  ""10.1016/j.procir.2020.02.207/,  ""10.5515/KJKIEES.2019.30.11.885/,  ""10.1214/19-EJS1531/,  ""10.1515/comp-2019-0011/,  ""10.1007/978-3-319-50077-5_6/,  ""10.1109/CESYS.2016.7889833/,  ""10.1109/ISCC.2016.7543917/,  ""10.1109/ICACCI.2015.7275598/,  ""10.1109/TBDATA.2015.2497710/,  ""10.1109/TKDE.2014.2373357/,  ""10.2200/S00607ED2V01Y201410HLT026/,  ""10.1007/978-3-319-11116-2_62/,  ""10.1109/ICCIC.2013.6724149/,  ""10.1007/978-3-642-38634-3_24/,  ""10.1109/ICCIC.2013.6724131/,  ""10.1007/978-3-642-27443-5_47/,  ""10.1587/transinf.E95.D.2327/,  ""10.1002/int.20455/,  ""10.1109/CIDM.2011.5949420/,  ""10.1007/978-3-642-14267-3_7/,  ""10.1007/978-3-642-14125-6_1/,  ""10.2200/S00348ED1V01Y201104HLT012/,  ""10.1109/ICMLC.2010.5580775/,  ""10.1109/JCPC.2009.5420161/,  ""10.1371/journal.pone.0050112/,  ""10.1007/s10791-018-9347-9/,  ""10.1089/big.2018.0175/,  ""10.1002/cpe.4464/,  ""10.1007/s11227-021-03975-2/',
      group:
        "SIGIR '08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrievalJuly 2008  Pages   115–122https://doi.org/10.1145/1390334.1390356",
      year: "",
      authors: "Xiubo Geng",
      doi: "10.1145/1390334.1390356",
    },
    {
      FIELD1: 41,
      id: "7F3D3128",
      name: "EigenRank: a ranking-oriented approach to collaborative filtering",
      url: "https://dl.acm.org/doi/abs/10.1145/1390334.1390351",
      abstract:
        "\nA recommender system must be able to suggest items that are likely to be preferred by the user. In most systems, the degree of preference is represented by a rating score. Given a database of users' past ratings on a set of items, traditional collaborative filtering algorithms are based on predicting the potential ratings that a user would assign to the unrated items so that they can be ranked by the predicted ratings to produce a list of recommended items. In this paper, we propose a collaborative filtering approach that addresses the item ranking problem directly by modeling user preferences derived from the ratings. We measure the similarity between users based on the correlation between their rankings of the items rather than the rating values and propose new collaborative filtering algorithms for ranking items based on the preferences of similar users. Experimental results on real world movie rating data sets show that the proposed approach outperforms traditional collaborative filtering algorithms significantly on the NDCG measure for evaluating ranked results.\n",
      citations:
        ' ""10.1109/TETCI.2020.3023155/,  ""10.1007/s12559-022-10001-x/,  ""10.1016/j.knosys.2022.108946/,  ""10.1016/j.eswa.2021.115482/,  ""10.1109/Cluster48925.2021.00051/,  ""10.1007/s11704-019-8123-3/,  ""10.1007/978-3-030-42835-8_5/,  ""10.1109/Confluence47617.2020.9058016/,  ""10.1007/978-3-030-50371-0_41/,  ""10.1587/transcom.2019EBP3230/,  ""10.1109/TCYB.2019.2896766/,  ""10.1109/TBDATA.2019.2892478/,  ""10.1109/DASC-PICom-CBDCom-CyberSciTech49142.2020.00066/,  ""10.1109/TKDE.2020.3016732/,  ""10.1007/978-3-319-92028-3_3/,  ""10.1007/978-3-030-15712-8_21/,  ""10.3233/WEB-190420/,  ""10.3156/jsoft.31.1_501/,  ""10.1007/s13735-018-0154-2/,  ""10.1007/978-3-319-92013-9_13/,  ""10.1007/978-1-4939-7131-2_189/,  ""10.1109/ICASSP.2018.8461395/,  ""10.1109/ECAI.2018.8679027/,  ""10.1109/CSCloud/EdgeCom.2018.00021/,  ""10.1109/MILCOM.2018.8599804/,  ""10.1007/978-1-4614-7163-9_189-1/,  ""10.1109/ICEDEG.2017.7962553/,  ""10.1109/JSYST.2014.2342375/,  ""10.1109/CompComm.2017.8322919/,  ""10.1109/ICIS.2016.7550761/,  ""10.1109/SMC.2016.7844691/,  ""10.1007/978-3-319-48051-0_14/,  ""10.1109/WISA.2016.21/,  ""10.1109/ISCC.2016.7543856/,  ""10.1007/978-3-319-49586-6_27/,  ""10.1007/978-3-319-29659-3_13/,  ""10.1049/iet-com.2016.0112/,  ""10.1109/CSCESM.2015.7331895/,  ""10.1109/ALLERTON.2015.7447183/,  ""10.1007/s11390-015-1570-x/,  ""10.1109/ISCID.2015.154/,  ""10.1007/978-3-319-14178-7_6/,  ""10.3233/AIC-140628/,  ""10.4018/978-1-4666-4695-7.ch010/,  ""10.1109/THMS.2014.2325837/,  ""10.1109/CISP.2014.7003752/,  ""10.1109/ISDA.2014.7066284/,  ""10.1109/ICDMW.2014.95/,  ""10.1007/978-3-319-05810-8_30/,  ""10.1007/978-3-319-07692-8_35/,  ""10.1155/2013/691042/,  ""10.4018/978-1-4666-2854-0.ch010/,  ""10.1007/978-3-642-37401-2_74/,  ""10.4018/978-1-4666-4695-7.chcrf/,  ""10.1007/978-3-642-34207-3_6/,  ""10.1109/ICDMW.2013.77/,  ""10.1109/WI-IAT.2012.135/,  ""10.1109/IJCNN.2012.6252670/,  ""10.1007/s11390-012-1241-0/,  ""10.1007/s11390-012-1242-z/,  ""10.1007/s11390-012-1244-x/,  ""10.1007/s11390-012-1245-9/,  ""10.1007/s11390-012-1248-6/,  ""10.1007/s11390-012-1247-7/,  ""10.1007/s11390-012-1301-5/,  ""10.1007/s11390-012-1302-4/,  ""10.1007/978-3-642-25694-3_8/,  ""10.1109/SMDCM.2011.5949273/,  ""10.1109/NLPKE.2011.6138181/,  ""10.1007/978-3-642-23014-1_14/,  ""10.1109/IJCNN.2009.5178967/,  ""10.1007/s11227-018-2477-4/,  ""10.1007/s13369-019-04180-3/,  ""10.1007/s12351-017-0325-6/',
      group:
        "SIGIR '08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrievalJuly 2008  Pages   83–90https://doi.org/10.1145/1390334.1390351",
      year: "",
      authors: "Nathan N. Liu",
      doi: "10.1145/1390334.1390351",
    },
    {
      FIELD1: 42,
      id: "7A66FCCB",
      name: "Topic segmentation with an aspect hidden Markov model",
      url: "https://dl.acm.org/doi/abs/10.1145/383952.384021",
      abstract:
        "\nWe present a novel probabilistic method for topic segmentation on unstructured text.  One previous approach to this problem utilizes the hidden Markov model (HMM) method for probabilistically modeling sequence data [7].  The HMM treats a document as mutually independent sets of words generated by a latent topic variable in a time series.  We extend this idea by embedding Hofmann's aspect model for text [5] into the segmenting HMM to form an aspect HMM (AHMM).  In doing so, we provide an intuitive topical dependency between words and a cohesive segmentation model.  We apply this method to segment unbroken streams of New York Times articles as well as noisy transcripts of radio programs on SpeechBot, an online audio archive indexed by an automatic speech recognition engine. We provide experimental comparisons which show that the AHMM outperforms the HMM for this task.\n",
      citations:
        ' ""10.1109/TKDE.2020.2983360/,  ""10.1007/978-3-030-96623-2_16/,  ""10.1007/978-981-16-7136-4_22/,  ""10.1109/ICEIEC54567.2022.9835041/,  ""10.1016/j.matpr.2021.02.183/,  ""10.1007/978-3-030-47426-3_37/,  ""10.1109/ICACCS.2019.8728440/,  ""10.2197/ipsjjip.26.562/,  ""10.1007/978-3-319-73531-3_14/,  ""10.1016/j.cognition.2017.09.018/,  ""10.1007/s12652-017-0501-9/,  ""10.1587/transinf.2017EDP7043/,  ""10.1109/ASRU.2017.8268979/,  ""10.1007/978-3-319-49304-6_42/,  ""10.1007/978-3-319-41920-6_33/,  ""10.1109/ICODSE.2014.7062668/,  ""10.1201/b17080-21/,  ""10.1007/978-3-319-12823-8_26/,  ""10.1007/978-3-319-13186-3_46/,  ""10.1109/ICASSP.2013.6639315/,  ""10.1007/978-3-642-45068-6_12/,  ""10.1109/MLSP.2012.6349772/,  ""10.1002/9781119992691.ch11/,  ""10.1007/978-3-642-13033-5_32/,  ""10.1007/978-3-642-11819-7_12/,  ""10.1109/ISCSLP.2010.5684896/,  ""10.1109/SLT.2010.5700891/,  ""10.1007/s11704-009-0062-y/,  ""10.1109/TFUZZ.2006.889911/,  ""10.1007/978-3-540-73351-5_8/,  ""10.2200/S00048ED1V01Y200609SAP003/,  ""10.1109/ICME.2006.262614/,  ""10.1109/SLT.2006.326826/,  ""10.1109/ICASSP.2005.1416475/,  ""10.1109/NLPKE.2005.1598814/,  ""10.1109/MSP.2005.1511823/,  ""10.1109/ISSPIT.2005.1577174/,  ""10.1109/MLSP.2005.1532908/,  ""10.1109/ICME.2004.1394265/,  ""10.1007/978-3-540-24598-8_26/,  ""10.1109/ICME.2004.1394538/,  ""10.1109/HICSS.2004.1265045/,  ""10.1007/s10515-019-00265-3/',
      group:
        "SIGIR '01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrievalSeptember 2001  Pages   343–348https://doi.org/10.1145/383952.384021",
      year: "",
      authors: "David M. Blei",
      doi: "10.1145/383952.384021",
    },
    {
      FIELD1: 43,
      id: "7C0872C0",
      name: "Automatic metadata generation & evaluation",
      url: "https://dl.acm.org/doi/abs/10.1145/564376.564464",
      abstract:
        "\nThe poster reports on a project in which we are investigating methods for breaking the human metadata-generation bottleneck that plagues Digital Libraries. The research question is whether metadata elements and values can be automatically generated from the content of educational resources, and correctly assigned to mathematics and science educational materials. Natural Language Processing and Machine Learning techniques were implemented to automatically assign values of the GEMgenerate metadata element set tofor learning resources provided by the Gateway for Education (GEM), a service that offers web access to a wide range of educational materials. In a user study, education professionals evaluated the metadata assigned to learning resources by either automatic tagging or manual assignment. Results show minimal difference in the eyes of the evaluators between automatically generated metadata and manually assigned metadata.\n",
      citations:
        ' ""10.1109/JCDL52503.2021.00015/,  ""10.4018/978-1-4666-1791-9.ch008/,  ""10.1002/asi.21706/,  ""10.2139/ssrn.3198936/,  ""10.1007/978-3-642-20227-8_6/,  ""10.1108/00330331111182094/,  ""10.1007/978-3-642-16552-8_19/,  ""10.4018/jmdem.2010111202/,  ""10.1007/978-3-642-04590-5_8/,  ""10.1007/978-0-387-77745-0_15/,  ""10.1109/DEST.2009.5276729/,  ""10.1002/asi.20276/,  ""10.1109/HICSS.2004.1265359/,  ""10.1007/978-3-540-24674-9_5/',
      group:
        "SIGIR '02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2002  Pages   401–402https://doi.org/10.1145/564376.564464",
      year: "",
      authors: "Elizabeth D. Liddy",
      doi: "10.1145/564376.564464",
    },
    {
      FIELD1: 44,
      id: "79C56783",
      name: "LDA-based document models for ad-hoc retrieval",
      url: "https://dl.acm.org/doi/abs/10.1145/1148170.1148204",
      abstract:
        "\nSearch algorithms incorporating some form of topic model have a long history in information retrieval. For example, cluster-based retrieval has been studied since the 60s and has recently produced good results in the language model framework. An approach to building topic models based on a formal generative model of documents, Latent Dirichlet Allocation (LDA), is heavily cited in the machine learning literature, but its feasibility and effectiveness in information retrieval is mostly unknown. In this paper, we study how to efficiently use LDA to improve ad-hoc retrieval. We propose an LDA-based document model within the language modeling framework, and evaluate it on several TREC collections. Gibbs sampling is employed to conduct approximate inference in LDA and the computational complexity is analyzed. We show that improvements over retrieval using cluster-based models can be obtained with reasonable efficiency.\n",
      citations:
        ' ""10.1186/s40537-021-00552-5/,  ""10.1186/s12911-022-01747-3/,  ""10.1007/978-3-030-84669-5_2/,  ""10.1007/978-3-030-96623-2_3/,  ""10.1007/978-981-16-8016-8_2/,  ""10.1007/s12652-021-03153-5/,  ""10.1109/ICSP54964.2022.9778317/,  ""10.1007/s11192-021-04247-9/,  ""10.1016/j.engappai.2022.105213/,  ""10.1109/BDAI56143.2022.9862704/,  ""10.1007/s10489-021-03100-z/,  ""10.1007/978-981-15-5329-5_26/,  ""10.1016/j.envsoft.2021.105044/,  ""10.1007/978-981-16-2540-4_47/,  ""10.1016/j.aiopen.2021.07.002/,  ""10.1007/978-3-030-85896-4_19/,  ""10.1109/ACCESS.2021.3109425/,  ""10.1007/978-3-030-87571-8_51/,  ""10.1007/s10664-021-10026-0/,  ""10.1007/978-3-030-77198-0_6/,  ""10.1109/BigData52589.2021.9671854/,  ""10.1109/TEM.2019.2903115/,  ""10.1016/j.procs.2021.08.114/,  ""10.1016/j.bspc.2019.101667/,  ""10.22581/muet1982.2001.20/,  ""10.1007/978-3-030-45439-5_10/,  ""10.1007/978-3-030-45439-5_30/,  ""10.1109/ICASSP40776.2020.9054066/,  ""10.1007/978-3-030-50146-4_28/,  ""10.1016/B978-0-12-819764-6.00008-9/,  ""10.1016/j.asoc.2020.106514/,  ""10.1016/j.elerap.2020.100989/,  ""10.1080/13683500.2019.1604638/,  ""10.1109/TASLP.2020.3012062/,  ""10.1109/ICRITO48877.2020.9197984/,  ""10.1007/978-3-030-62008-0_9/,  ""10.1109/ICTAI50040.2020.00071/,  ""10.1109/AIKE48582.2020.00018/,  ""10.34172/doh.2020.43/,  ""10.1007/s12206-020-1024-4/,  ""10.1007/978-981-15-8083-3_29/,  ""10.1017/dsd.2020.98/,  ""10.1016/j.jbi.2019.103141/,  ""10.3233/JIFS-179015/,  ""10.1007/978-3-030-24289-3_38/,  ""10.1007/978-3-030-27618-8_5/,  ""10.1007/978-3-030-27455-9_2/,  ""10.1109/ACCESS.2019.2927329/,  ""10.1007/978-981-15-0105-0_4/,  ""10.1007/978-3-030-31624-2_3/,  ""10.1109/HPCC/SmartCity/DSS.2019.00309/,  ""10.1002ra2.23/,  ""10.3233/WEB-190424/,  ""10.1007/978-3-030-34872-4_33/,  ""10.1109/BIBM47256.2019.8983167/,  ""10.1109/CAC48633.2019.8996952/,  ""10.1109/I2CT45611.2019.9033569/,  ""10.1007/978-981-15-0118-0_39/,  ""10.1007/978-981-13-1498-8_38/,  ""10.3233/JIFS-182776/,  ""10.1007/978-3-030-05411-3_23/,  ""10.1109/ACCESS.2019.2946288/,  ""10.1007/978-3-319-71746-3_16/,  ""10.1007/978-3-319-59463-7_25/,  ""10.1109/COMPSAC.2018.00065/,  ""10.1109/CCAA.2018.8777730/,  ""10.1007/978-3-319-73531-3_3/,  ""10.1007/978-3-030-00021-9_15/,  ""10.1007/978-3-319-67621-0_16/,  ""10.2200/S00832ED1V01Y201802AIM037/,  ""10.1007/978-3-319-99936-4_1/,  ""10.1007/s10479-017-2668-z/,  ""10.1109/INFRKM.2018.8464782/,  ""10.1007/978-3-319-90092-6_8/,  ""10.1186/s12918-018-0640-4/,  ""10.1109/SCCC.2018.8705252/,  ""10.1109/IJCNN.2018.8489778/,  ""10.1109/BigDataCongress.2018.00010/,  ""10.1109/JSYST.2017.2725920/,  ""10.1109/ASONAM.2018.8508523/,  ""10.1109/ACCESS.2018.2873708/,  ""10.1109/WI.2018.00-95/,  ""10.1007/978-3-319-61762-6_9/,  ""10.1017/dsj.2018.5/,  ""10.1109/ICIS.2017.7959986/,  ""10.1007/978-3-319-63579-8_15/,  ""10.2139/ssrn.2952567/,  ""10.2139/ssrn.2675331/,  ""10.1007/978-3-319-55705-2_11/,  ""10.3233/JIFS-169300/,  ""10.1007/978-3-319-63004-5_19/,  ""10.1109/ASRU.2017.8268973/,  ""10.1108/978-1-78743-115-720171016/,  ""10.3233/WEB-170356/,  ""10.1007/978-3-319-68699-8_17/,  ""10.1016/j.engappai.2017.05.006/,  ""10.1007/978-3-319-48308-5_4/,  ""10.1007/978-3-319-68124-5_25/,  ""10.1109/IALP.2017.8300606/,  ""10.1007/978-3-319-63579-8_20/,  ""10.1108/OIR-06-2016-0166/,  ""10.1109/ACCESS.2017.2739822/,  ""10.1109/WoWMoM.2017.7974354/,  ""10.1109/BIBM.2017.8217785/,  ""10.1109/UMEDIA.2017.8074123/,  ""10.1109/ACCESS.2017.2712744/,  ""10.1109/ICSEC.2017.8443795/,  ""10.1109/WISA.2017.52/,  ""10.2200/S00714ED1V01Y201603ICR048/,  ""10.2200/S00718ED1V01Y201605ICR049/,  ""10.1007/978-3-319-46922-5_23/,  ""10.1109/ICEEOT.2016.7755608/,  ""10.2200/S00737ED1V01Y201610AIM033/,  ""10.1007/978-3-319-30671-1_18/,  ""10.1007/978-3-319-46681-1_52/,  ""10.1177/0759106316642706/,  ""10.1109/ICCWAMTIP.2016.8079837/,  ""10.1093/comjnl/bxv114/,  ""10.1109/INVENTIVE.2016.7824855/,  ""10.1007/978-3-319-46523-4_37/,  ""10.1007/s10551-015-2622-4/,  ""10.1007/s13740-016-0063-6/,  ""10.1007/978-3-319-41754-7_17/,  ""10.1109/ICDMW.2016.0150/,  ""10.1109/MSN.2016.012/,  ""10.1109/WI.2016.0015/,  ""10.1007/978-3-319-44159-7_17/,  ""10.1109/WI.2016.0014/,  ""10.1109/WI.2016.0049/,  ""10.1109/ENIC.2016.023/,  ""10.1108/AJIM-06-2015-0091/,  ""10.2200/S00629ED1V01Y201502WBE011/,  ""10.1109/ICCSP.2015.7322722/,  ""10.2139/ssrn.2601719/,  ""10.1007/978-3-319-16354-3_70/,  ""10.1007/978-3-319-21042-1_68/,  ""10.1007/978-3-319-21042-1_17/,  ""10.1007/978-3-662-48119-6_18/,  ""10.1016/j.ipm.2014.08.003/,  ""10.1111/bjet.12277/,  ""10.1109/ICSE.2015.47/,  ""10.1109/ICSESS.2015.7339073/,  ""10.1109/TMM.2015.2417506/,  ""10.1109/LGRS.2015.2402391/,  ""10.1109/IJCNN.2015.7280376/,  ""10.1007/978-3-319-27729-5_6/,  ""10.1109/SmartCity.2015.82/,  ""10.1109/ICASSP.2015.7178965/,  ""10.1109/ICIS.2015.7166594/,  ""10.1007/978-3-319-10840-7_5/,  ""10.1007/978-3-319-13820-6_6/,  ""10.1007/978-3-319-11749-2_15/,  ""10.5715/jnlp.21.921/,  ""10.1007/978-3-319-12511-4_5/,  ""10.1109/BIGCOMP.2014.6741416/,  ""10.1109/BIBM.2014.6999197/,  ""10.1007/s13740-013-0031-3/,  ""10.1109/SAI.2014.6918274/,  ""10.1109/ICASSP.2014.6854974/,  ""10.1109/JBHI.2013.2274281/,  ""10.1186/1471-2105-15-S12-S10/,  ""10.1007/s11432-013-4860-3/,  ""10.1057/9781137443366_5/,  ""10.1109/ICDM.2013.11/,  ""10.1007/978-3-7091-1346-2_22/,  ""10.1007/978-3-642-37456-2_19/,  ""10.1007/978-81-322-1143-3_6/,  ""10.1007/978-1-4614-3097-1_4/,  ""10.1002/asi.22744/,  ""10.1002/meet.14505001042/,  ""10.1002/asi.22862/,  ""10.1007/978-3-642-44958-1_1/,  ""10.1007/978-3-642-37456-2_18/,  ""10.1007/978-3-642-37401-2_69/,  ""10.1016/j.procs.2013.09.144/,  ""10.1109/ICASSP.2013.6639330/,  ""10.1007/978-3-642-03718-4_18/,  ""10.1007/978-1-4614-3223-4_5/,  ""10.1007/978-1-4471-2467-2_86/,  ""10.1007/978-3-642-35341-3_28/,  ""10.1587/transinf.E95.D.1195/,  ""10.5715/jnlp.19.121/,  ""10.1002/meet.14504901209/,  ""10.1002/9781118562796.ch5/,  ""10.1016/j.physrep.2012.02.006/,  ""10.1109/ICPC.2012.6240485/,  ""10.1109/ISCIT.2012.6380855/,  ""10.1109/ICSMC.2012.6377902/,  ""10.1109/WI-IAT.2012.195/,  ""10.1109/SLT.2012.6424219/,  ""10.4018/978-1-60960-881-1.ch003/,  ""10.1109/CCIS.2012.6664637/,  ""10.1109/COMSNETS.2011.5716478/,  ""10.1109/ICRA.2011.5980404/,  ""10.1007/978-3-642-22898-8_2/,  ""10.1109/VAST.2011.6102461/,  ""10.1109/CCIS.2011.6045023/,  ""10.1109/ICCIAutom.2011.6183893/,  ""10.1007/978-3-642-23211-4_9/,  ""10.1007/978-3-642-17829-0_39/,  ""10.1109/ASRU.2011.6163963/,  ""10.1109/NLPKE.2011.6138198/,  ""10.1007/978-3-642-23059-2_17/,  ""10.1109/ICDIM.2011.6093316/,  ""10.1007/978-3-642-22898-8_4/,  ""10.1007/978-3-642-14246-8_15/,  ""10.1007/978-3-642-14246-8_16/,  ""10.1002/9780470689646.ch10/,  ""10.1007/978-3-642-15754-7_6/,  ""10.1109/ISCSLP.2010.5684896/,  ""10.1109/ICCSIT.2010.5564016/,  ""10.1007/978-3-642-04174-7_12/,  ""10.1631/jzus.A0820796/,  ""10.1007/978-3-642-04174-7_28/,  ""10.1109/ICICISYS.2009.5358121/,  ""10.1007/978-3-540-68636-1_9/,  ""10.1109/PICMET.2008.4599703/,  ""10.1109/SLT.2008.4777875/,  ""10.1109/IJCNN.2008.4633926/,  ""10.1002/asi.20896/,  ""10.1007/978-3-540-79721-0_77/,  ""10.1007/978-3-540-78646-7_18/,  ""10.1109/CVPR.2007.383490/,  ""10.1109/ISI.2007.379553/,  ""10.1109/ICDAR.2007.4377099/,  ""10.1007/978-3-540-71496-5_8/,  ""10.1108/K-05-2018-0216/,  ""10.1371/journal.pone.0202162/,  ""10.1007/s41237-019-00099-z/,  ""10.1111/coin.12248/,  ""10.1080/0965254X.2020.1749875/,  ""10.1371/journal.pone.0184188/,  ""10.4028/www.scientific.net/AMR.756-759.2152/,  ""10.1007/s10586-018-1789-8/,  ""10.1007/s12083-018-0692-7/,  ""10.1007/s41237-018-0050-3/,  ""10.1093/comjnl/bxw036/,  ""10.1007/s11192-020-03614-2/,  ""10.1007/s11205-020-02442-4/,  ""10.3390/rs12182889/,  ""10.1007/s11042-020-10391-w/,  ""10.2339oliteknik.831391/,  ""10.1007/s10115-021-01555-7/,  ""10.1080/10919392.2020.1736466/,  ""10.1007/s10791-021-09401-8/,  ""10.1007/s11356-021-15935-7/,  ""10.1007/s11192-021-04186-5/,  ""10.1093/bib/bbac194/,  ""10.1007/s11192-022-04401-x/',
      group:
        "SIGIR '06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2006  Pages   178–185https://doi.org/10.1145/1148170.1148204",
      year: "",
      authors: "Xing Wei",
      doi: "10.1145/1148170.1148204",
    },
    {
      FIELD1: 45,
      id: "7DBD47ED",
      name: "Term selection for searching printed Arabic",
      url: "https://dl.acm.org/doi/abs/10.1145/564376.564423",
      abstract:
        "\nSince many Arabic documents are available only in print, automating retrieval from collections of scanned Arabic document images using Optical Character Recognition (OCR) is an interesting problem. Arabic combines rich morphology with a writing system that presents unique challenges to OCR systems. These factors must be considered when selecting terms for automatic indexing. In this paper, alternative choices of indexing terms are explored using both an existing electronic text collection and a newly developed collection built from images of actual printed Arabic documents. Character n-grams or lightly stemmed words were found to typically yield near-optimal retrieval effectiveness, and combining both types of terms resulted in robust performance across a broad range of conditions.\n",
      citations:
        ' ""10.1002/widm.1447/,  ""10.1007/s12046-020-01492-1/,  ""10.1109/SCCS.2019.8852602/,  ""10.1109/ISACV.2017.8054932/,  ""10.1109/ICTAI.2016.0136/,  ""10.1109/SNPD.2016.7515887/,  ""10.1007/978-3-642-45358-8_10/,  ""10.1007/978-3-642-45114-0_31/,  ""10.1109/ISDA.2010.5687228/,  ""10.2200/S00277ED1V01Y201008HLT010/,  ""10.1007/978-1-4020-6046-5_13/,  ""10.1007/s10462-018-9622-6/,  ""10.1007/s10579-020-09504-6/',
      group:
        "SIGIR '02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2002  Pages   261–268https://doi.org/10.1145/564376.564423",
      year: "",
      authors: "Kareem Darwish",
      doi: "10.1145/564376.564423",
    },
    {
      FIELD1: 46,
      id: "80D09177",
      name: "Predicting information seeker satisfaction in community question answering",
      url: "https://dl.acm.org/doi/abs/10.1145/1390334.1390417",
      abstract:
        "\nQuestion answering communities such as Naver and Yahoo! Answers have emerged as popular, and often effective, means of information seeking on the web. By posting questions for other participants to answer, information seekers can obtain specific answers to their questions. Users of popular portals such as Yahoo! Answers already have submitted millions of questions and received hundreds of millions of answers from other participants. However, it may also take hours --and sometime days-- until a satisfactory answer is posted. In this paper we introduce the problem of predicting information seeker satisfaction in collaborative question answering communities, where we attempt to predict whether a question author will be satisfied with the answers submitted by the community participants. We present a general prediction model, and develop a variety of content, structure, and community-focused features for this task. Our experimental results, obtained from a largescale evaluation over thousands of real questions and user ratings, demonstrate the feasibility of modeling and predicting asker satisfaction. We complement our results with a thorough investigation of the interactions and information seeking patterns in question answering communities that correlate with information seeker satisfaction. Our models and predictions could be useful for a variety of applications such as user intent inference, answer ranking, interface design, and query suggestion and routing.\n",
      citations:
        ' ""10.1007/978-981-16-2540-4_34/,  ""10.1109/ICICCS51141.2021.9432089/,  ""10.1109/CSCWD49262.2021.9437843/,  ""10.1109/CogSIMA49017.2020.9216035/,  ""10.1109/QRS-C51114.2020.00041/,  ""10.1108/EL-09-2019-0223/,  ""10.1109/TBDATA.2016.2612236/,  ""10.1007/978-3-030-42835-8_3/,  ""10.1016/j.asoc.2020.106125/,  ""10.1109/IJCNN.2019.8852107/,  ""10.1007/978-981-13-1456-8_1/,  ""10.1109/IJCNN.2019.8852063/,  ""10.1109/ACCESS.2019.2892987/,  ""10.1007/978-3-319-77712-2_94/,  ""10.1007/s11390-018-1845-0/,  ""10.1007/978-3-319-90092-6_3/,  ""10.1109/TKDE.2017.2754373/,  ""10.14529/mmph180307/,  ""10.1109/TCSS.2018.2859964/,  ""10.1109/CyberC.2018.00057/,  ""10.1108/PROG-01-2015-0008/,  ""10.1109/TKDE.2017.2696535/,  ""10.1109/TSC.2015.2446991/,  ""10.1007/s13278-017-0459-9/,  ""10.1109/ICCUBEA.2017.8463975/,  ""10.1007/978-3-319-56756-3_4/,  ""10.1109/TSMC.2016.2580606/,  ""10.1007/978-3-319-57529-2_5/,  ""10.1016/j.jbi.2017.06.012/,  ""10.1007/978-3-319-56756-3_8/,  ""10.1007/978-3-319-39396-4_6/,  ""10.1109/WiSPNET.2016.7566588/,  ""10.2139/ssrn.2794149/,  ""10.1109/TCSS.2016.2564400/,  ""10.1007/978-3-319-30146-4_4/,  ""10.1109/BigData.2016.7840610/,  ""10.1287/mnsc.2015.2217/,  ""10.1007/978-3-319-22180-9_7/,  ""10.1002ra2.2015.145052010051/,  ""10.1007/978-3-319-27433-1_3/,  ""10.1007/978-3-642-55285-4_5/,  ""10.1109/ASONAM.2014.6921607/,  ""10.1109/ASONAM.2014.6921625/,  ""10.1007/978-3-642-54522-1_10/,  ""10.1007/978-3-642-40722-2_16/,  ""10.1007/978-3-642-45068-6_34/,  ""10.1002/meet.14505001052/,  ""10.1007/978-3-642-35085-6_8/,  ""10.4018/978-1-4666-2533-4.ch014/,  ""10.1109/IJCNN.2012.6252435/,  ""10.1049/iet-com.2011.0202/,  ""10.1007/s13278-011-0046-4/,  ""10.1109/ICCI-CC.2012.6311134/,  ""10.1007/978-3-642-30732-4_18/,  ""10.1007/978-3-642-34456-5_23/,  ""10.1002/meet.14504901075/,  ""10.1108/14684521211241413/,  ""10.1007/978-3-642-22418-8_45/,  ""10.1007/978-3-642-21852-1_62/,  ""10.1002/meet.2011.14504801269/,  ""10.1109/MIC.2010.82/,  ""10.1109/PASSAT/SocialCom.2011.67/,  ""10.2139/ssrn.1535171/,  ""10.1002/asi.21259/,  ""10.1007/s00799-019-00272-5/,  ""10.1007/s10844-020-00612-x/,  ""10.1007/s11063-021-10470-5/,  ""10.52547/jipm.36.3.709/,  ""10.1002/asi.24562/,  ""10.1007/s10844-021-00661-w/',
      group:
        "SIGIR '08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrievalJuly 2008  Pages   483–490https://doi.org/10.1145/1390334.1390417",
      year: "",
      authors: "Yandong Liu",
      doi: "10.1145/1390334.1390417",
    },
    {
      FIELD1: 47,
      id: "77EE3DFB",
      name: "Improving text categorization methods for event tracking",
      url: "https://dl.acm.org/doi/abs/10.1145/345508.345550",
      abstract:
        "\nAutomated tracking of events from chronologically ordered document streams is a new challenge for statistical text classification. Existing learning techniques must be adapted or improved in order to effectively handle difficult situations where the number of positive training instances per event is extremely small, the majority of training documents are unlabelled, and most of the events have a short duration in time. We adapted several supervised text categorization methods, specifically several new variants of the k-Nearest Neighbor (kNN) algorithm and a Rocchio approach, to track events. All of these methods showed significant improvement (up to 71% reduction in weighted error rates) over the performance of the original kNN algorithm on TDT benchmark collections, making kNN among the top-performing systems in the recent TDT3 official evaluation. Furthermore, by combining these methods, we significantly reduced the variance in performance of our event tracking system over different data collections, suggesting a robust solution for parameter optimization.\n",
      citations:
        ' ""10.1016/j.agwat.2021.107102/,  ""10.1177/1550147720916404/,  ""10.1007/978-981-13-2206-8_14/,  ""10.2139/ssrn.3222501/,  ""10.1007/978-3-319-57454-7_22/,  ""10.1007/978-3-319-44260-0_1/,  ""10.1177/0165551516653082/,  ""10.1109/KICSS.2016.7951441/,  ""10.1007/978-3-319-50496-4_33/,  ""10.1007/978-3-319-14120-6_17/,  ""10.1109/ICDE.2014.6816635/,  ""10.1587/transinf.E96.D.2786/,  ""10.1002/meet.14505001039/,  ""10.1587/transinf.E95.D.2327/,  ""10.4018/978-1-60960-200-0.ch001/,  ""10.1109/NLPKE.2011.6138173/,  ""10.1109/JCSSE.2011.5930150/,  ""10.1109/FSKD.2010.5569601/,  ""10.1109/ICEIT.2010.5607527/,  ""10.1109/SNLP.2009.5340908/,  ""10.1007/978-3-540-73351-5_8/,  ""10.1007/978-3-540-73435-2_12/,  ""10.1007/978-3-540-33473-6_8/,  ""10.1007/978-3-540-24586-5_73/,  ""10.4028/www.scientific.net/AMM.58-60.1088/,  ""10.4028/www.scientific.net/AMM.40-41.1006/,  ""10.1371/journal.pone.0176310/,  ""10.1007/s41060-017-0091-9/,  ""10.1089/big.2018.0175/,  ""10.1007/s10946-020-09861-1/,  ""10.1177/0165551519894928/,  ""10.1007/s11227-021-03975-2/',
      group:
        "SIGIR '00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrievalJuly 2000  Pages   65–72https://doi.org/10.1145/345508.345550",
      year: "",
      authors: "Yiming Yang",
      doi: "10.1145/345508.345550",
    },
    {
      FIELD1: 48,
      id: "7F495E20",
      name: "Question answering passage retrieval using dependency relations",
      url: "https://dl.acm.org/doi/abs/10.1145/1076034.1076103",
      abstract:
        "\nState-of-the-art question answering (QA) systems employ term-density ranking to retrieve answer passages. Such methods often retrieve incorrect passages as relationships among question terms are not considered. Previous studies attempted to address this problem by matching dependency relations between questions and answers. They used strict matching, which fails when semantically equivalent relationships are phrased differently. We propose fuzzy relation matching based on statistical models. We present two methods for learning relation mapping scores from past QA pairs: one based on mutual information and the other on expectation maximization. Experimental results show that our method significantly outperforms state-of-the-art density-based passage retrieval methods by up to 78% in mean reciprocal rank. Relation matching also brings about a 50% improvement in a system enhanced by query expansion.\n",
      citations:
        ' ""10.1109/TII.2021.3097183/,  ""10.1016/j.inffus.2022.06.002/,  ""10.1109/ICICCS51141.2021.9432089/,  ""10.1109/ICAICA52286.2021.9498018/,  ""10.1109/TSMC.2019.2917673/,  ""10.1007/978-3-030-63031-7_9/,  ""10.1007/978-3-030-22796-8_14/,  ""10.1007/978-3-030-31605-1_15/,  ""10.1007/978-3-030-25913-6_5/,  ""10.1109/SKG.2018.00040/,  ""10.3917/lang.212.0105/,  ""10.1109/UBMK.2017.8093464/,  ""10.1007/978-3-319-61572-1_19/,  ""10.1007/978-3-319-43997-6_4/,  ""10.1007/978-3-319-41754-7_11/,  ""10.1109/FSKD.2016.7603410/,  ""10.1007/978-3-319-22180-9_7/,  ""10.1109/ICASSP.2013.6639320/,  ""10.4018/978-1-4666-0330-1.ch015/,  ""10.1016/j.proeng.2012.01.979/,  ""10.1007/978-3-642-21384-7_5/,  ""10.1002/asi.21002/,  ""10.1371/journal.pone.0064601/,  ""10.1371/journal.pone.0071511/,  ""10.1007/s00500-020-04714-0/,  ""10.1002/widm.1412/',
      group:
        "SIGIR '05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2005  Pages   400–407https://doi.org/10.1145/1076034.1076103",
      year: "",
      authors: "Hang Cui",
      doi: "10.1145/1076034.1076103",
    },
    {
      FIELD1: 49,
      id: "7FB4861E",
      name: "AdaRank: a boosting algorithm for information retrieval",
      url: "https://dl.acm.org/doi/abs/10.1145/1277741.1277809",
      abstract:
        "\nIn this paper we address the issue of learning to rank for document retrieval. In the task, a model is automatically created with some training data and then is utilized for ranking of documents. The goodness of a model is usually evaluated with performance measures such as MAP (Mean Average Precision) and NDCG (Normalized Discounted Cumulative Gain). Ideally a learning algorithm would train a ranking model that could directly optimize the performance measures with respect to the training data. Existing methods, however, are only able to train ranking models by minimizing loss functions loosely related to the performance measures. For example, Ranking SVM and RankBoost train ranking models by minimizing classification errors on instance pairs. To deal with the problem, we propose a novel learning algorithm within the framework of boosting, which can minimize a loss function directly defined on the performance measures. Our algorithm, referred to as AdaRank, repeatedly constructs 'weak rankers' on the basis of reweighted training data and finally linearly combines the weak rankers for making ranking predictions. We prove that the training process of AdaRank is exactly that of enhancing the performance measure used. Experimental results on four benchmark datasets show that AdaRank significantly outperforms the baseline methods of BM25, Ranking SVM, and RankBoost.\n",
      citations:
        ' ""10.1007/978-981-16-3398-0_15/,  ""10.1109/ACCESS.2022.3142096/,  ""10.1007/978-3-030-96623-2_11/,  ""10.1007/978-3-030-96623-2_7/,  ""10.1002/cpe.5791/,  ""10.1038/s41598-022-10383-w/,  ""10.2298/CSIS201220042Y/,  ""10.1007/s10115-022-01726-0/,  ""10.1007/978-3-030-67670-4_16/,  ""10.1186/s12911-021-01454-5/,  ""10.1109/ICICSE52190.2021.9404146/,  ""10.1007/978-3-030-75768-7_21/,  ""10.1109/FiCloud49777.2021.00037/,  ""10.1007/978-3-030-91608-4_18/,  ""10.1109/BigData52589.2021.9672072/,  ""10.1109/ICCWAMTIP53232.2021.9674101/,  ""10.1111/tgis.12798/,  ""10.1016/j.knosys.2021.107577/,  ""10.1109/TKDE.2018.2889664/,  ""10.1109/TKDE.2019.2893361/,  ""10.1109/ICASSP40776.2020.9053127/,  ""10.1007/978-3-030-46133-1_15/,  ""10.1007/978-981-13-9409-6_144/,  ""10.1007/978-3-030-06164-7_11/,  ""10.20965/jaciii.2020.p0316/,  ""10.1109/TNNLS.2019.2927868/,  ""10.1016/B978-0-12-819764-6.00008-9/,  ""10.1109/Indo-TaiwanICAN48429.2020.9181315/,  ""10.1109/ACCESS.2020.3026758/,  ""10.1109/NRSC49500.2020.9235095/,  ""10.1109/DSAA49011.2020.00083/,  ""10.1109/MSIEID52046.2020.00105/,  ""10.1109/ICICTA51737.2020.00033/,  ""10.1109/TNNLS.2019.2936876/,  ""10.4018/IJIRR.2020070102/,  ""10.1007/s12046-019-1073-5/,  ""10.1109/TKDE.2018.2851257/,  ""10.1109/TCSS.2019.2907563/,  ""10.1007/978-3-030-28577-7_11/,  ""10.1142/S0218001419510078/,  ""10.1109/ICDM.2019.00018/,  ""10.1007/978-3-030-36805-0_13/,  ""10.1142/S021819401930001X/,  ""10.1109/AICAI.2019.8701391/,  ""10.1007/978-981-13-6661-1_12/,  ""10.1007/978-981-13-1951-8_68/,  ""10.1109/ICDMW.2019.00069/,  ""10.1109/TKDE.2019.2942590/,  ""10.1109/TPAMI.2018.2873701/,  ""10.1109/SANER.2019.8668033/,  ""10.4018/IJGHPC.2019010102/,  ""10.1017/S1351324919000032/,  ""10.1109/ICInfA.2018.8812518/,  ""10.1002/jnm.2310/,  ""10.1007/978-981-13-0896-3_3/,  ""10.1007/978-3-030-01012-6_16/,  ""10.1007/s10791-018-9330-5/,  ""10.1007/978-3-319-73531-3_7/,  ""10.1007/978-3-319-56994-9_59/,  ""10.1007/978-3-030-04257-8_30/,  ""10.1007/s13278-018-0516-z/,  ""10.1109/JIOT.2018.2801944/,  ""10.1109/TKDE.2017.2754253/,  ""10.1007/978-3-319-99253-2_36/,  ""10.1007/s10515-018-0231-z/,  ""10.1007/978-3-319-93935-3_3/,  ""10.1109/IJCNN.2018.8489646/,  ""10.1109/IJCNN.2018.8489418/,  ""10.1109/CIBCB.2018.8404965/,  ""10.1109/WI.2018.00-12/,  ""10.1109/SLT.2018.8639519/,  ""10.1007/978-1-4899-7687-1_893/,  ""10.1109/SOCA.2017.34/,  ""10.1016/B978-0-12-812013-2.00007-1/,  ""10.1109/BigData.2017.8258135/,  ""10.1109/TSMC.2016.2584786/,  ""10.1007/978-3-319-56608-5_60/,  ""10.1007/s00354-017-0019-x/,  ""10.1007/978-981-10-6805-8_10/,  ""10.1109/TKDE.2017.2654250/,  ""10.1109/SCC.2017.20/,  ""10.1007/978-3-319-69179-4_35/,  ""10.1109/CAC.2017.8244044/,  ""10.1186/s13326-017-0123-3/,  ""10.1109/SSCI.2017.8285374/,  ""10.1007/978-3-319-71249-9_2/,  ""10.1007/978-3-319-70145-5_3/,  ""10.1109/WCCCT.2016.56/,  ""10.1007/978-3-319-70145-5_2/,  ""10.1109/TSC.2017.2777487/,  ""10.1007/978-1-4899-7502-7_893-1/,  ""10.1108/IJWIS-12-2015-0046/,  ""10.1109/IJCNN.2016.7727464/,  ""10.1109/TKDE.2016.2535214/,  ""10.1109/TMM.2015.2477277/,  ""10.1109/ASONAM.2016.7752345/,  ""10.4018/978-1-4666-8833-9.ch003/,  ""10.1587/transinf.2015DAP0001/,  ""10.1007/978-3-319-39958-4_27/,  ""10.4018/978-1-4666-9562-7.ch063/,  ""10.1007/978-3-319-16354-3_63/,  ""10.1007/978-3-319-18032-8_40/,  ""10.1007/978-3-319-23525-7_1/,  ""10.1007/978-1-4899-7637-6_11/,  ""10.1186/s13321-015-0052-z/,  ""10.1109/DSAA.2015.7344898/,  ""10.1109/APSEC.2015.50/,  ""10.1109/TPAMI.2014.2360397/,  ""10.1109/CIT/IUCC/DASC/PICOM.2015.136/,  ""10.1109/TCYB.2014.2336697/,  ""10.1109/TSC.2014.2377724/,  ""10.1007/978-981-4585-18-7_47/,  ""10.1007/978-3-319-11382-1_14/,  ""10.1007/978-3-662-45924-9_33/,  ""10.1007/s13278-014-0174-8/,  ""10.1201/b16812-58/,  ""10.2200/S00607ED2V01Y201410HLT026/,  ""10.1109/ICoICT.2014.6914039/,  ""10.1109/ICACSIS.2014.7065896/,  ""10.1109/CBMI.2014.6849825/,  ""10.1109/ICMEW.2014.6890600/,  ""10.1109/TCIAIG.2013.2275199/,  ""10.1186/1471-2105-15-286/,  ""10.1002/asi.22789/,  ""10.1007/978-3-642-37450-0_27/,  ""10.1109/MLSP.2013.6661979/,  ""10.1109/SOLI.2013.6611452/,  ""10.1109/ICDM.2013.54/,  ""10.1109/TNNLS.2013.2247628/,  ""10.1527/tjsai.28.22/,  ""10.1186/1471-2105-14-286/,  ""10.1007/978-1-4614-3223-4_7/,  ""10.1007/978-3-642-33050-6_22/,  ""10.1007/978-3-540-92910-9_15/,  ""10.1007/978-3-642-33460-3_14/,  ""10.1002/9781118562796.ch2/,  ""10.1002/asi.22665/,  ""10.1109/CyberneticsCom.2012.6381614/,  ""10.1109/MLSP.2012.6349807/,  ""10.1109/ICMLC.2012.6359640/,  ""10.1007/978-3-642-14267-3_11/,  ""10.1007/978-3-642-14267-3_10/,  ""10.1007/978-3-642-14267-3_1/,  ""10.1007/978-0-85729-525-5_9/,  ""10.1002/9781119992691.ch13/,  ""10.1109/MLSP.2011.6064557/,  ""10.1587/transinf.E94.D.1854/,  ""10.2200/S00348ED1V01Y201104HLT012/,  ""10.1007/978-3-642-14267-3_4/,  ""10.1007/978-3-642-14267-3_19/,  ""10.1109/CIDM.2011.5949420/,  ""10.1016/j.procs.2010.12.070/,  ""10.1109/FG.2011.5771429/,  ""10.1002/int.20455/,  ""10.1109/MLSP.2011.6064549/,  ""10.1109/YCICT.2010.5713050/,  ""10.1109/YCICT.2010.5713094/,  ""10.1109/ICMLC.2010.5580775/,  ""10.1109/ICISE.2010.5690335/,  ""10.1109/ICASSP.2010.5494956/,  ""10.1021/ci9003865/,  ""10.1007/978-3-642-17187-1_19/,  ""10.1007/978-3-540-68636-1_25/,  ""10.1007/978-3-540-85930-7_52/,  ""10.1007/978-3-642-38457-8_11/,  ""10.1007/s13369-019-04180-3/,  ""10.1007/s10115-019-01430-6/,  ""10.1017/S1351324920000029/,  ""10.1002/cpe.5796/,  ""10.1007/s10044-019-00856-6/,  ""10.1007/s00500-019-03882-y/,  ""10.1007/s11704-012-1170-7/,  ""10.1371/journal.pone.0061567/,  ""10.1371/journal.pone.0050112/,  ""10.4028/www.scientific.net/AMR.931-932.1427/,  ""10.1111/coin.12413/,  ""10.1007/s10618-020-00730-8/,  ""10.3390/bdcc5030035/,  ""10.1002/cpe.6592/,  ""10.1007/s10791-021-09396-2/,  ""10.52547/jipm.36.4.1081/,  ""10.1007/s12652-021-03664-1/,  ""10.1007/s10489-021-02592-z/',
      group:
        "SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2007  Pages   391–398https://doi.org/10.1145/1277741.1277809",
      year: "",
      authors: "Jun Xu",
      doi: "10.1145/1277741.1277809",
    },
    {
      FIELD1: 50,
      id: "7F230A0D",
      name: "Probabilistic combination of text classifiers using reliability indicators: models and results",
      url: "https://dl.acm.org/doi/abs/10.1145/564376.564413",
      abstract:
        "\nThe intuition that different text classifiers behave in qualitatively different ways has long motivated attempts to build a better metaclassifier via some combination of classifiers. We introduce a probabilistic method for combining classifiers that considers the context-sensitive reliabilities of contributing classifiers. The method harnesses reliability indicators---variables that provide a valuable signal about the performance of classifiers in different situations. We provide background, present procedures for building metaclassifiers that take into consideration both reliability indicators and classifier outputs, and review a set of comparative studies undertaken to evaluate the methodology.\n",
      citations:
        ' ""10.1007/978-3-030-00066-0_1/,  ""10.1007/978-3-030-02671-4_10/,  ""10.1109/IJCNN.2016.7727691/,  ""10.1007/978-3-642-32790-2_2/,  ""10.4018/978-1-60566-010-3.ch034/,  ""10.1109/CEC.2006.1688611/,  ""10.1007/978-3-540-24681-7_4/,  ""10.1007/978-3-540-27868-9_89/,  ""10.1109/WI.2004.10029/,  ""10.1007/3-540-36618-0_22/,  ""10.20914/2310-1202-2018-4-128-132/',
      group:
        "SIGIR '02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2002  Pages   207–214https://doi.org/10.1145/564376.564413",
      year: "",
      authors: "Paul N. Bennett",
      doi: "10.1145/564376.564413",
    },
    {
      FIELD1: 51,
      id: "753B8644",
      name: "A new rank correlation coefficient for information retrieval",
      url: "https://dl.acm.org/doi/abs/10.1145/1390334.1390435",
      abstract:
        "\nIn the field of information retrieval, one is often faced with the problem of computing the correlation between two ranked lists. The most commonly used statistic that quantifies this correlation is Kendall's Τ. Often times, in the information retrieval community, discrepancies among those items having high rankings are more important than those among items having low rankings. The Kendall's Τ statistic, however, does not make such distinctions and equally penalizes errors both at high and low rankings. In this paper, we propose a new rank correlation coefficient, AP correlation (Τap), that is based on average precision and has a probabilistic interpretation. We show that the proposed statistic gives more weight to the errors at high rankings and has nice mathematical properties which make it easy to interpret. We further validate the applicability of the statistic using experimental data.\n",
      citations:
        ' ""10.1007/978-3-030-96960-8_10/,  ""10.1002/asi.24577/,  ""10.1038/s41598-022-09915-1/,  ""10.1007/978-1-0716-2197-4_15/,  ""10.1080/08839514.2021.2009164/,  ""10.1186/s42162-022-00194-8/,  ""10.1007/978-3-031-15037-1_11/,  ""10.1109/MDM55031.2022.00034/,  ""10.1016/j.ipm.2022.103007/,  ""10.1007/978-3-030-72240-1_23/,  ""10.1109/TKDE.2019.2962124/,  ""10.1109/ACCESS.2021.3107585/,  ""10.1109/ACCESS.2021.3116857/,  ""10.1016/j.procs.2021.08.138/,  ""10.1136/bmjopen-2020-037744/,  ""10.1007/978-3-030-58219-7_2/,  ""10.1142/S0219525920500125/,  ""10.1007/978-3-030-15712-8_50/,  ""10.1002/sta4.236/,  ""10.1109/TENSYMP46218.2019.8971073/,  ""10.1109/IC-AIAI48757.2019.00024/,  ""10.1007/978-3-319-73198-8_8/,  ""10.1214/18-EJS1462/,  ""10.1109/TKDE.2017.2729559/,  ""10.1007/978-3-319-57261-1_27/,  ""10.3233/WEB-160335/,  ""10.1007/978-3-319-30671-1_21/,  ""10.1007/978-3-319-30671-1_48/,  ""10.1007/978-3-319-30671-1_38/,  ""10.1111/itor.12146/,  ""10.1007/978-3-319-23525-7_26/,  ""10.1007/978-1-4899-7637-6_8/,  ""10.1002/9781119047063.refs/,  ""10.1108/AJIM-12-2014-0171/,  ""10.1002ra2.2015.1450520100119/,  ""10.1007/978-3-319-06028-6_1/,  ""10.1007/978-3-319-11197-1_53/,  ""10.1007/978-3-319-06028-6_13/,  ""10.1109/TIT.2014.2345760/,  ""10.1007/978-3-642-54798-0_6/,  ""10.1007/978-3-642-33326-2_7/,  ""10.1007/978-3-642-45068-6_4/,  ""10.4018/978-1-4666-2854-0.ch010/,  ""10.1109/ITW.2013.6691240/,  ""10.1007/978-3-642-35341-3_3/,  ""10.1109/WI-IAT.2012.128/,  ""10.1007/978-3-642-24583-1_2/,  ""10.1007/978-3-642-21786-9_44/,  ""10.1007/978-3-642-16321-0_23/,  ""10.1109/ICCAD.2010.5653959/,  ""10.1007/978-3-642-14400-4_20/,  ""10.2197/ipsjjip.17.156/,  ""10.1109/ICSM.2009.5306305/,  ""10.1002/asi.24077/,  ""10.1007/s10791-019-09356-x/,  ""10.1007/s10791-020-09371-3/,  ""10.1007/s11634-021-00442-x/',
      group:
        "SIGIR '08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrievalJuly 2008  Pages   587–594https://doi.org/10.1145/1390334.1390435",
      year: "",
      authors: "Emine Yilmaz",
      doi: "10.1145/1390334.1390435",
    },
    {
      FIELD1: 52,
      id: "7D1A4F7E",
      name: "Robust classification of rare queries using web knowledge",
      url: "https://dl.acm.org/doi/abs/10.1145/1277741.1277783",
      abstract:
        "\nWe propose a methodology for building a practical robust query classification system that can identify thousands of query classes with reasonable accuracy, while dealing in real-time with the query volume of a commercial web search engine. We use a blind feedback technique: given a query, we determine its topic by classifying the web search results retrieved by the query. Motivated by the needs of search advertising, we primarily focus on rare queries, which are the hardest from the point of view of machine learning, yet in aggregation account for a considerable fraction of search engine traffic. Empirical evaluation confirms that our methodology yields a considerably higher classification accuracy than previously reported. We believe that the proposed methodology will lead to better matching of online ads to rare queries and overall to a better user experience.\n",
      citations:
        ' ""10.1007/978-981-13-8676-3_12/,  ""10.1007/978-3-030-45439-5_45/,  ""10.1007/978-3-030-58334-7_4/,  ""10.1007/978-3-030-58334-7_2/,  ""10.1007/978-3-319-93037-4_30/,  ""10.4236/jis.2017.81005/,  ""10.1007/978-3-319-55699-4_11/,  ""10.1007/978-981-10-1675-2_19/,  ""10.3233/WEB-170362/,  ""10.1002/cpe.3891/,  ""10.1007/s10664-016-9479-8/,  ""10.1007/978-3-319-50127-7_57/,  ""10.1007/978-3-319-49586-6_45/,  ""10.1080/0952813X.2015.1042924/,  ""10.1007/978-3-319-39958-4_10/,  ""10.1109/ICCCBDA.2016.7529557/,  ""10.1007/978-3-319-25485-2_13/,  ""10.1527/tjsai.30.161/,  ""10.1109/DSAA.2014.7058134/,  ""10.1109/TMC.2013.113/,  ""10.1109/ICIINFS.2014.7036627/,  ""10.1177/0165551513507415/,  ""10.1109/IJCNN.2013.6707061/,  ""10.1002/meet.14505001085/,  ""10.1007/978-3-642-29084-8_13/,  ""10.1007/978-3-642-35341-3_12/,  ""10.1007/978-3-642-24965-5_17/,  ""10.1007/978-3-642-25661-5_64/,  ""10.1007/978-3-642-23017-2_1/,  ""10.1007/978-3-642-23982-3_38/,  ""10.1108/14684521111193184/,  ""10.1016/j.eswa.2011.04.029/,  ""10.1109/ICSIP.2010.5697471/,  ""10.1016/j.ipm.2009.09.005/,  ""10.1109/ICADIWT.2009.5273856/,  ""10.1007/978-3-642-04128-0_15/,  ""10.1007/s41060-018-0165-3/,  ""10.1007/s10660-021-09496-7/',
      group:
        "SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2007  Pages   231–238https://doi.org/10.1145/1277741.1277783",
      year: "",
      authors: "Andrei Z. Broder",
      doi: "10.1145/1277741.1277783",
    },
    {
      FIELD1: 53,
      id: "757887DB",
      name: "Tackling concept drift by temporal inductive transfer",
      url: "https://dl.acm.org/doi/abs/10.1145/1148170.1148216",
      abstract:
        "\nMachine learning is the mainstay for text classification. However, even the most successful techniques are defeated by many real-world applications that have a strong time-varying component. To advance research on this challenging but important problem, we promote a natural, experimental framework-the Daily Classification Task-which can be applied to large time-based datasets, such as Reuters RCV1.In this paper we dissect concept drift into three main subtypes. We demonstrate via a novel visualization that the recurrent themes subtype is present in RCV1. This understanding led us to develop a new learning model that transfers induced knowledge through time to benefit future classifier learning tasks. The method avoids two main problems with existing work in inductive transfer: scalability and the risk of negative transfer. In empirical tests, it consistently showed more than 10 points F-measure improvement for each of four Reuters categories tested.\n",
      citations:
        ' ""10.1007/s13278-021-00760-0/,  ""10.1109/ICTAI50040.2020.00069/,  ""10.1007/978-3-030-61527-7_11/,  ""10.1007/978-3-030-27615-7_20/,  ""10.1109/IJCNN.2019.8852137/,  ""10.1109/IJCNN.2019.8852205/,  ""10.1109/IJCNN.2019.8851686/,  ""10.1109/IJCNN.2019.8852173/,  ""10.2139/ssrn.3403404/,  ""10.1109/BigData.2018.8622585/,  ""10.1109/COASE.2017.8256253/,  ""10.1007/978-3-319-59081-3_42/,  ""10.1109/IJCNN.2017.7966108/,  ""10.1007/978-3-319-67008-9_29/,  ""10.1007/978-981-10-3611-8_43/,  ""10.1007/978-3-319-11430-9_7/,  ""10.1007/978-3-642-28604-9_35/,  ""10.1109/FSKD.2011.6019889/,  ""10.1109/AIS.2010.5547026/,  ""10.1007/s10115-009-0206-2/,  ""10.1007/978-3-642-14640-4_5/,  ""10.1109/IJCNN.2009.5178619/,  ""10.1109/CIDM.2007.368896/,  ""10.1007/s10994-019-05835-w/,  ""10.1080/17517575.2020.1825821/',
      group:
        "SIGIR '06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2006  Pages   252–259https://doi.org/10.1145/1148170.1148216",
      year: "",
      authors: "George Forman",
      doi: "10.1145/1148170.1148216",
    },
    {
      FIELD1: 54,
      id: "7C792585",
      name: "Clustering short texts using wikipedia",
      url: "https://dl.acm.org/doi/abs/10.1145/1277741.1277909",
      abstract:
        "\nSubscribers to the popular news or blog feeds (RSS/Atom) often face the problem of information overload as these feed sources usually deliver large number of items periodically. One solution to this problem could be clustering similar items in the feed reader to make the information more manageable for a user. Clustering items at the feed reader end is a challenging task as usually only a small part of the actual article is received through the feed. In this paper, we propose a method of improving the accuracy of clustering short texts by enriching their representation with additional features from Wikipedia. Empirical results indicate that this enriched representation of text items can substantially improve the clustering accuracy when compared to the conventional bag of words representation.\n",
      citations:
        ' ""10.1007/s13278-022-00870-3/,  ""10.1177/0894439320907027/,  ""10.1109/CCAI55564.2022.9807822/,  ""10.1186/s40352-022-00189-3/,  ""10.1007/978-3-030-99079-4_5/,  ""10.1007/978-981-16-1685-3_13/,  ""10.1109/TSMC.2019.2932436/,  ""10.1007/978-3-030-79457-6_48/,  ""10.1109/ICNLP52887.2021.00006/,  ""10.1109/ICAECA52838.2021.9675579/,  ""10.1109/ACCESS.2020.2983584/,  ""10.1007/978-3-030-51310-8_10/,  ""10.1002/9781119711582.ch9/,  ""10.1007/978-981-15-8101-4_43/,  ""10.1109/ACCESS.2020.3042778/,  ""10.1109/ICTAI50040.2020.00129/,  ""10.1007/978-3-030-63833-7_23/,  ""10.1007/978-981-13-1927-3_15/,  ""10.1109/ACCESS.2019.2903095/,  ""10.3233/IDA-184045/,  ""10.1109/ACCESS.2019.2927345/,  ""10.1007/978-3-030-36442-7_4/,  ""10.1007/978-3-030-34885-4_9/,  ""10.1109/DSAA.2019.00020/,  ""10.1109/ICMLA.2019.00122/,  ""10.1109/ICISCAE48440.2019.221680/,  ""10.1109/DASC/PiCom/CBDCom/CyberSciTech.2019.00103/,  ""10.1109/ACCESS.2018.2885987/,  ""10.1007/978-981-10-7605-3_63/,  ""10.1007/978-3-319-73618-1_69/,  ""10.1007/978-3-030-04221-9_42/,  ""10.1007/978-3-030-01298-4_1/,  ""10.1007/978-3-030-05090-0_29/,  ""10.1007/978-3-030-05090-0_28/,  ""10.1007/978-3-030-03056-8_10/,  ""10.1007/978-981-13-0896-3_22/,  ""10.1007/978-3-319-77116-8_18/,  ""10.1109/SCIS-ISIS.2018.00223/,  ""10.1186/s40537-017-0095-2/,  ""10.1007/978-3-319-70139-4_21/,  ""10.1115/1.4037478/,  ""10.1016/j.procs.2017.11.428/,  ""10.1109/TAAI.2017.37/,  ""10.1109/ICIOTA.2017.8073628/,  ""10.1007/978-3-319-51367-6_4/,  ""10.1007/s41870-017-0015-x/,  ""10.1007/978-3-319-55753-3_26/,  ""10.1109/CSCI.2017.152/,  ""10.1007/978-3-319-51367-6_1/,  ""10.1109/ICCA.2016.7505352/,  ""10.1109/INDIN.2016.7819344/,  ""10.1007/978-3-319-30671-1_42/,  ""10.1109/WI.2016.0029/,  ""10.1007/978-3-319-47160-0_43/,  ""10.1109/WI.2016.0022/,  ""10.1109/ICCSNT.2016.8070155/,  ""10.1109/IHMSC.2016.248/,  ""10.1109/ICDMW.2016.0101/,  ""10.1007/978-3-319-48472-3_40/,  ""10.1109/IT4OD.2016.7479307/,  ""10.1007/978-3-319-39396-4_31/,  ""10.1587/transinf.2016SLL0006/,  ""10.1007/978-3-319-32055-7_4/,  ""10.1007/978-3-319-32055-7_15/,  ""10.1587/transinf.2015DAP0031/,  ""10.1109/RE.2015.7320434/,  ""10.1109/TETC.2015.2418716/,  ""10.1007/s13278-015-0282-0/,  ""10.1109/FSKD.2015.7382029/,  ""10.1007/978-3-319-20807-7_38/,  ""10.1109/TBDATA.2015.2451635/,  ""10.1109/CCITSA.2015.13/,  ""10.1109/ICOT.2015.7498505/,  ""10.1007/978-3-319-20609-7_31/,  ""10.1109/SMC.2015.297/,  ""10.1007/978-3-319-22324-7_7/,  ""10.1007/978-3-319-22324-7_4/,  ""10.1007/978-3-319-22053-6_49/,  ""10.1109/AICCSA.2014.7073240/,  ""10.1109/SITA.2014.6847286/,  ""10.1007/978-3-662-44980-6_10/,  ""10.1109/ICRTIT.2014.6996189/,  ""10.1109/ICIS.2014.6912124/,  ""10.1109/ICMLC.2014.7009104/,  ""10.1007/978-3-319-11116-2_45/,  ""10.1007/978-3-319-11116-2_46/,  ""10.1007/978-3-319-12640-1_70/,  ""10.1007/978-3-662-45924-9_31/,  ""10.1109/NCVPRIPG.2013.6776152/,  ""10.1109/ICIS.2013.6607883/,  ""10.1007/978-1-4614-6880-6_1/,  ""10.1007/978-3-642-39693-9_3/,  ""10.1587/transinf.E96.D.2786/,  ""10.7763/IJCTE.2012.V4.562/,  ""10.1109/INSS.2012.6240529/,  ""10.1007/978-1-4614-3223-4_12/,  ""10.1007/978-3-642-35142-6_1/,  ""10.1007/978-3-642-20841-6_15/,  ""10.1109/ICoAC.2011.6165203/,  ""10.1007/978-3-642-24425-4_85/,  ""10.1109/ASRU.2011.6163953/,  ""10.1002/asi.21593/,  ""10.1007/978-3-642-16321-0_29/,  ""10.1007/978-90-481-9794-1_25/,  ""10.1109/ISI.2009.5137273/,  ""10.1007/978-3-642-01216-7_31/,  ""10.1108/17440080910947321/,  ""10.1109/ICDIM.2008.4746702/,  ""10.1007/s10462-019-09781-w/,  ""10.1007/s10115-020-01482-z/,  ""10.1002/cpe.6673/,  ""10.1002/9781118445112.stat07973/',
      group:
        "SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2007  Pages   787–788https://doi.org/10.1145/1277741.1277909",
      year: "",
      authors: "Somnath Banerjee",
      doi: "10.1145/1277741.1277909",
    },
    {
      FIELD1: 55,
      id: "7B869D82",
      name: "A probabilistic relational model for the integration of IR and databases",
      url: "https://dl.acm.org/doi/abs/10.1145/160688.160754",
      abstract:
        "\nIn this paper, a probabilistic relational model is presented which combines relational algebra with probabilistic retrieval. Based on certain independence assumptions, the operators of the relational algebra are redefined such that the probabilistic algebra is a generalization of the standard relational algebra. Furthermore, a special join operator implementing probabilistic retrieval is proposed. When applied to typical document databases, queries can not only ask for documents, but for any kind of object in the database. In addition, an implicit ranking of these objects is provided in case the query relates to probabilistic indexing or uses the probabilistic join operator. The proposed algebra is intended as a standard interface to combined database and IR systems, as a basis for  implementing user-friendly interfaces.\n",
      citations:
        ' ""10.1016/j.eswa.2005.09.009/,  ""10.1007/3-540-48309-8_5/,  ""10.1007/BFb0054472/',
      group:
        "SIGIR '93: Proceedings of the 16th annual international ACM SIGIR conference on Research and development in information retrievalJuly 1993  Pages   309–317https://doi.org/10.1145/160688.160754",
      year: "",
      authors: "Norbert Fuhr",
      doi: "10.1145/160688.160754",
    },
    {
      FIELD1: 56,
      id: "77D6F439",
      name: "Context-sensitive semantic smoothing for the language modeling approach to genomic IR",
      url: "https://dl.acm.org/doi/abs/10.1145/1148170.1148203",
      abstract:
        "\nSemantic smoothing, which incorporates synonym and sense information into the language models, is effective and potentially significant to improve retrieval performance. The implemented semantic smoothing models, such as the translation model which statistically maps document terms to query terms, and a number of works that have followed have shown good experimental results. However, these models are unable to incorporate contextual information. Thus, the resulting translation might be mixed and fairly general. To overcome this limitation, we propose a novel context-sensitive semantic smoothing method that decomposes a document or a query into a set of weighted context-sensitive topic signatures and then translate those topic signatures into query terms. In detail, we solve this problem through (1) choosing concept pairs as topic signatures and adopting an ontology-based approach to extract concept pairs; (2) estimating the translation model for each topic signature using the EM algorithm; and (3) expanding document and query models based on topic signature translations. The new smoothing method is evaluated on TREC 2004/05 Genomics Track collections and significant improvements are obtained. The MAP (mean average precision) achieves a 33.6% maximal gain over the simple language model, as well as a 7.8% gain over the language model with context-insensitive semantic smoothing.\n",
      citations:
        ' ""10.4018/978-1-4666-5888-2.ch170/,  ""10.1109/ISB.2013.6623786/,  ""10.4018/978-1-60960-881-1.ch003/,  ""10.1016/j.websem.2011.11.009/,  ""10.1007/978-3-642-16629-7_12/,  ""10.2139/ssrn.3198949/,  ""10.1016/j.ipm.2009.09.005/,  ""10.1109/SIS.2009.4937843/,  ""10.5626/JCSE.2009.3.3.143/,  ""10.1109/WiCom.2008.2543/,  ""10.1109/ICINFA.2008.4608247/,  ""10.1109/IJCNN.2008.4633926/,  ""10.1007/s11390-008-9115-1/,  ""10.1109/WiCom.2008.1329/,  ""10.1109/WiCom.2008.1147/',
      group:
        "SIGIR '06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2006  Pages   170–177https://doi.org/10.1145/1148170.1148203",
      year: "",
      authors: "Xiaohua Zhou",
      doi: "10.1145/1148170.1148203",
    },
    {
      FIELD1: 57,
      id: "7E08E4CD",
      name: "Better than the real thing?: iterative pseudo-query processing using cluster-based language models",
      url: "https://dl.acm.org/doi/abs/10.1145/1076034.1076041",
      abstract:
        "\nWe present a novel approach to pseudo-feedback-based ad hoc retrieval that uses language models induced from both documents and clusters. First, we treat the pseudo-feedback documents produced in response to the original query as a set of pseudo-query that themselves can serve as input to the retrieval process. Observing that the documents returned in response to the pseudo-query can then act as pseudo-query for subsequent rounds, we arrive at a formulation of pseudo-query-based retrieval as an iterative process. Experiments show that several concrete instantiations of this idea, when applied in conjunction with techniques designed to heighten precision, yield performance results rivaling those of a number of previously-proposed algorithms, including the standard language-modeling approach. The use of cluster-based language models is a key contributing factor to our algorithms' success.\n",
      citations:
        ' ""10.1007/978-981-16-5164-9_26/,  ""10.1007/978-3-319-30671-1_38/,  ""10.1016/j.ipm.2009.09.005/,  ""10.3745/KIPSTB.2009.16-B.3.247/,  ""10.1007/978-3-540-78646-7_17/,  ""10.1007/978-3-540-74851-9_21/,  ""10.1111/j.1467-8640.2007.00291.x/,  ""10.1080/10447310701360995/',
      group:
        "SIGIR '05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2005  Pages   19–26https://doi.org/10.1145/1076034.1076041",
      year: "",
      authors: "Oren Kurland",
      doi: "10.1145/1076034.1076041",
    },
    {
      FIELD1: 58,
      id: "786D044A",
      name: "Building implicit links from content for forum search",
      url: "https://dl.acm.org/doi/abs/10.1145/1148170.1148224",
      abstract:
        "\nThe objective of Web forums is to create a shared space for open communications and discussions of specific topics and issues. The tremendous information behind forum sites is not fully-utilized yet. Most links between forum pages are automatically created, which means the link-based ranking algorithm cannot be applied efficiently. In this paper, we proposed a novel ranking algorithm which tries to introduce the content information into link-based methods as implicit links. The basic idea is derived from the more focused random surfer: the surfer may more likely jump to a page which is similar to what he is reading currently. In this manner, we are allowed to introduce the content similarities into the link graph as a personalization bias. Our method, named Fine-grained Rank (FGRank), can be efficiently computed based on an automatically generated topic hierarchy. Not like the topic-sensitive PageRank, our method only need to compute single PageRank score for each page. Another contribution of this paper is to present a very efficient algorithm for automatically generating topic hierarchy and map each page in a large-scale collection onto the computed hierarchy. The experimental results show that the proposed method can improve retrieval performance, and reveal that content-based link graph is also important compared with the hyper-link graph.\n",
      citations:
        ' ""10.1016/j.cosrev.2021.100397/,  ""10.1007/978-3-030-26169-6_18/,  ""10.1007/978-3-319-13186-3_46/,  ""10.1007/s11390-014-1446-5/,  ""10.1109/ICEMMS.2010.5563410/,  ""10.1109/ICEMMS.2010.5563409/,  ""10.1007/978-3-642-14589-6_33/,  ""10.1007/978-3-642-16961-8_96/,  ""10.1007/978-3-540-68636-1_36/,  ""10.1007/978-3-540-77094-7_52/',
      group:
        "SIGIR '06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2006  Pages   300–307https://doi.org/10.1145/1148170.1148224",
      year: "",
      authors: "Gu Xu",
      doi: "10.1145/1148170.1148224",
    },
    {
      FIELD1: 59,
      id: "790AF21A",
      name: "Linear discriminant model for information retrieval",
      url: "https://dl.acm.org/doi/abs/10.1145/1076034.1076085",
      abstract:
        "\nThis paper presents a new discriminative model for information retrieval (IR), referred to as linear discriminant model (LDM), which provides a flexible framework to incorporate arbitrary features. LDM is different from most existing models in that it takes into account a variety of linguistic features that are derived from the component models of HMM that is widely used in language modeling approaches to IR. Therefore, LDM is a means of melding discriminative and generative models for IR. We present two algorithms of parameter learning for LDM. One is to optimize the average precision (AP) directly using an iterative procedure. The other is a perceptron-based algorithm that minimizes the number of discordant document-pairs in a rank list. The effectiveness of our approach has been evaluated on the task of ad hoc retrieval using six English and Chinese TREC test sets. Results show that (1) in most test sets, LDM significantly outperforms the state-of-the-art language modeling approaches and the classical probabilistic retrieval model; (2) it is more appropriate to train LDM using a measure of AP rather than likelihood if the IR system is graded on AP; and (3) linguistic features (e.g. phrases and dependences) are effective for IR if they are incorporated properly.\n",
      citations:
        ' ""10.1109/ACCESS.2020.3018151/,  ""10.1061/(ASCE)MT.1943-5533.0003024/,  ""10.1007/978-981-13-3648-5_10/,  ""10.1016/j.measurement.2019.01.001/,  ""10.2200/S00607ED2V01Y201410HLT026/,  ""10.1109/NLPKE.2011.6138167/,  ""10.1109/SoCPaR.2011.6089095/,  ""10.2200/S00348ED1V01Y201104HLT012/,  ""10.1007/978-3-642-14267-3_1/,  ""10.1007/978-3-642-14267-3_3/,  ""10.1007/978-3-642-22898-8_6/,  ""10.1007/978-3-642-17187-1_51/,  ""10.1109/ICMLC.2010.5580675/,  ""10.1109/CVPR.2008.4587361/,  ""10.1007/s11767-006-0256-5/,  ""10.1007/978-3-540-78646-7_18/,  ""10.1109/IRI.2007.4296655/,  ""10.1007/s10791-006-9019-z/,  ""10.1287/ijoc.2018.0837/',
      group:
        "SIGIR '05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2005  Pages   290–297https://doi.org/10.1145/1076034.1076085",
      year: "",
      authors: "Jianfeng Gao",
      doi: "10.1145/1076034.1076085",
    },
    {
      FIELD1: 60,
      id: "7BA8A899",
      name: "Bayesian online classifiers for text classification and filtering",
      url: "https://dl.acm.org/doi/abs/10.1145/564376.564395",
      abstract:
        "\nThis paper explores the use of Bayesian online classifiers to classify text documents. Empirical results indicate that these classifiers are comparable with the best text classification systems. Furthermore, the online approach offers the advantage of continuous learning in the batch-adaptive text filtering task.\n",
      citations:
        ' ""10.3846/jcem.2022.16012/,  ""10.1007/978-981-16-7330-6_66/,  ""10.3233/IDA-215942/,  ""10.1007/978-981-13-1274-8_26/,  ""10.1007/978-3-319-99626-4_37/,  ""10.1109/PCCC.2018.8710994/,  ""10.1109/IISA.2017.8316459/,  ""10.1007/978-3-319-62938-4_17/,  ""10.1109/CONFLUENCE.2017.7943132/,  ""10.3233/IDA-163055/,  ""10.1109/GSCIT.2016.27/,  ""10.2200/S00718ED1V01Y201605ICR049/,  ""10.1109/TETC.2014.2377559/,  ""10.1109/ICACCI.2014.6968447/,  ""10.1002/sam.11241/,  ""10.1109/ICIEV.2013.6572718/,  ""10.1109/Allerton.2013.6736696/,  ""10.1007/978-94-007-1839-5_173/,  ""10.1007/978-1-4614-3223-4_9/,  ""10.1007/978-3-642-31686-9_39/,  ""10.1007/978-3-642-19953-0_6/,  ""10.1016/j.patcog.2010.07.009/,  ""10.1109/ICMLC.2010.5580676/,  ""10.1002/sam.10055/,  ""10.1109/IRI.2009.5211540/,  ""10.1007/978-3-642-04174-7_30/,  ""10.1186/1471-2105-10-S1-S55/,  ""10.1002/asi.21022/,  ""10.1002/asi.21260/,  ""10.1109/TFUZZ.2008.925904/,  ""10.1108/17440080810919503/,  ""10.1109/CIISP.2007.369172/,  ""10.1108/14684520710780449/,  ""10.4028/www.scientific.net/AMR.989-994.2444/',
      group:
        "SIGIR '02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2002  Pages   97–104https://doi.org/10.1145/564376.564395",
      year: "",
      authors: "Kian Ming Adam Chai",
      doi: "10.1145/564376.564395",
    },
    {
      FIELD1: 61,
      id: "762787B5",
      name: "Feature engineering for mobile (SMS) spam filtering",
      url: "https://dl.acm.org/doi/abs/10.1145/1277741.1277951",
      abstract:
        "\nMobile spam in an increasing threat that may be addressed using filtering systems like those employed against email spam. We believe that email filtering techniques require some adaptation to reach good levels of performance on SMS spam, especially regarding message representation. In order to test this assumption, we have performed experiments on SMS filtering using top performing email spam filters on mobile spam messages using a suitable feature representation, with results supporting our hypothesis.\n",
      citations:
        ' ""10.1007/978-981-15-7961-5_66/,  ""10.1109/ITNEC.2019.8729471/,  ""10.1007/s10489-019-01463-y/,  ""10.1109/ICCS45141.2019.9065686/,  ""10.1109/IADCC.2018.8692097/,  ""10.1109/ICCUBEA.2018.8697372/,  ""10.4018/978-1-5225-4944-4.ch011/,  ""10.1109/ICHI.2018.00039/,  ""10.1109/ICACCCN.2018.8748286/,  ""10.1007/978-981-10-5780-9_2/,  ""10.1016/j.procs.2017.08.335/,  ""10.1109/FSKD.2016.7603347/,  ""10.1109/WCICA.2016.7578397/,  ""10.1007/978-3-319-29742-2_5/,  ""10.1007/978-981-10-2777-2_14/,  ""10.1109/FGCT.2015.7300257/,  ""10.1109/PST.2015.7232968/,  ""10.1017/S1351324914000102/,  ""10.1007/978-3-319-01854-6_46/,  ""10.1007/978-3-319-12568-8_47/,  ""10.1109/TELFOR.2012.6419492/,  ""10.1109/ICC.2012.6363989/,  ""10.1007/978-1-4614-1650-0_5/,  ""10.1109/ICCSNT.2011.6181918/,  ""10.1109/CCECE.2009.5090166/,  ""10.7763/IJMLC.2014.V4.409/,  ""10.4028/www.scientific.net/AMM.602-605.3843/,  ""10.1007/s10115-018-1278-7/,  ""10.29109/http-gujsc-gazi-edu-tr.372880/,  ""10.35377/saucis.03.03.735463/,  ""10.1111oms.13272/,  ""10.1007/s11042-022-12991-0/',
      group:
        "SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2007  Pages   871–872https://doi.org/10.1145/1277741.1277951",
      year: "",
      authors: "Gordon V. Cormack",
      doi: "10.1145/1277741.1277951",
    },
    {
      FIELD1: 62,
      id: "76D49856",
      name: "Robustness of regularized linear classification methods in text categorization",
      url: "https://dl.acm.org/doi/abs/10.1145/860435.860471",
      abstract:
        "\nReal-world applications often require the classification of documents under situations of small number of features, mis-labeled documents and rare positive examples. This paper investigates the robustness of three regularized linear classification methods (SVM, ridge regression and logistic regression) under above situations. We compare these methods in terms of their loss functions and score distributions, and establish the connection between their optimization problems and generalization error bounds. Several sets of controlled experiments on the Reuters-21578 corpus are conducted to investigate the robustness of these methods. Our results show that ridge regression seems to be the most promising candidate for rare class problems.\n",
      citations:
        ' ""10.1007/978-3-030-74761-9_13/,  ""10.1142/S0219649222500277/,  ""10.1007/978-981-19-1559-8_20/,  ""10.1109/TIFS.2021.3058771/,  ""10.1109/ICTAI52525.2021.00227/,  ""10.1109/ACCESS.2020.2976156/,  ""10.1007/978-3-030-64148-1_18/,  ""10.1016/j.future.2019.06.022/,  ""10.5715/jnlp.25.3/,  ""10.1109/ICACCI.2017.8125990/,  ""10.1007/s13042-015-0474-y/,  ""10.1007/s40593-016-0132-x/,  ""10.1109/BRACIS.2016.055/,  ""10.1109/CCIP.2015.7100687/,  ""10.1109/TNNLS.2013.2292894/,  ""10.1109/ICFIN.2009.5339603/,  ""10.1007/978-3-540-30116-5_61/,  ""10.1007/978-3-540-30116-5_19/,  ""10.1007/s10579-018-9424-0/,  ""10.4028/www.scientific.net/AMM.556-562.4982/,  ""10.1007/s42967-020-00084-4/',
      group:
        "SIGIR '03: Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrievalJuly 2003  Pages   190–197https://doi.org/10.1145/860435.860471",
      year: "",
      authors: "Jian Zhang",
      doi: "10.1145/860435.860471",
    },
    {
      FIELD1: 63,
      id: "78649A31",
      name: "Active learning for class imbalance problem",
      url: "https://dl.acm.org/doi/abs/10.1145/1277741.1277927",
      abstract:
        "\nThe class imbalance problem has been known to hinder the learning performance of classification algorithms. Various real-world classification tasks such as text categorization suffer from this phenomenon. We demonstrate that active learning is capable of solving the problem.\n",
      citations:
        ' ""10.1109/JIOT.2021.3090583/,  ""10.1186/s40001-022-00754-4/,  ""10.1109/ICPR48806.2021.9412182/,  ""10.1109/ACCESS.2021.3081366/,  ""10.1109/CAIBDA53561.2021.00054/,  ""10.1109/RTSI50628.2021.9597357/,  ""10.1109/ACCESS.2021.3130383/,  ""10.1007/s42979-020-0085-x/,  ""10.1007/s11390-020-9487-4/,  ""10.1109/TNNLS.2020.2964585/,  ""10.1007/978-3-030-10463-4_11/,  ""10.1109/ACCESS.2019.2927266/,  ""10.1109/IJCNN.2019.8852188/,  ""10.1109/IJCNN.2019.8852205/,  ""10.1109/IJCNN.2019.8851686/,  ""10.1016/j.knosys.2019.105231/,  ""10.1109/IJCNN.2019.8852173/,  ""10.1109/ACCESS.2019.2956508/,  ""10.1109/TNNLS.2018.2855446/,  ""10.1051/matecconf/201819703003/,  ""10.1007/978-3-030-04491-6_22/,  ""10.1007/978-3-319-98074-4_6/,  ""10.1007/978-3-319-67274-8_11/,  ""10.1109/ICSSSM.2017.7996301/,  ""10.1109/ACCESS.2017.2759180/,  ""10.1007/s00232-015-9856-z/,  ""10.1007/s13369-016-2179-2/,  ""10.1007/978-3-319-15702-3_37/,  ""10.1109/ICRSE.2015.7366475/,  ""10.1109/ICCPEIC.2014.6915337/,  ""10.1007/978-3-319-01857-7_29/,  ""10.1109/ICDM.2013.105/,  ""10.1007/978-3-642-33932-5_69/,  ""10.1002/9781118646106.ch1/,  ""10.1007/978-3-319-01604-7_26/,  ""10.1109/TNNLS.2012.2228231/,  ""10.1002/9781118646106.ch5/,  ""10.1016/j.patrec.2013.04.019/,  ""10.1007/978-3-642-19914-1_45/,  ""10.1007/s11460-011-0127-1/,  ""10.1002/9781118025604.ch3/,  ""10.1016/j.egypro.2011.10.542/,  ""10.1016/S1876-6102(14)00453-6/,  ""10.1136/amiajnl-2011-000217/,  ""10.1007/978-3-642-17832-0_23/,  ""10.1186/1471-2105-11-55/,  ""10.1109/ICCAE.2010.5451921/,  ""10.4236/jbise.2010.310133/,  ""10.1109/ROBOT.2010.5509634/,  ""10.1109/IJCNN.2008.4633969/,  ""10.1007/s00500-020-05056-7/,  ""10.1080/0952813X.2021.1924871/,  ""10.3390/rs13132619/,  ""10.1021/acs.jcim.8b00749/,  ""10.1002/cpe.6648/,  ""10.1371/journal.pone.0107676/,  ""10.1007/s00521-018-3469-2/,  ""10.1007/s40747-021-00435-5/,  ""10.3389/fdata.2021.715320/,  ""10.1007/s10489-021-02620-y/,  ""10.1007/s11042-022-13617-1/,  ""10.3390/cryst12091247/',
      group:
        "SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2007  Pages   823–824https://doi.org/10.1145/1277741.1277927",
      year: "",
      authors: "Seyda Ertekin",
      doi: "10.1145/1277741.1277927",
    },
    {
      FIELD1: 64,
      id: "7B6DB2E1",
      name: "Collaborative filtering with privacy via factor analysis",
      url: "https://dl.acm.org/doi/abs/10.1145/564376.564419",
      abstract:
        "\nCollaborative filtering (CF) is valuable in e-commerce, and for direct recommendations for music, movies, news etc. But today's systems have several disadvantages, including privacy risks. As we move toward ubiquitous computing, there is a great potential for individuals to share all kinds of information about places and things to do, see and buy, but the privacy risks are severe. In this paper we describe a new method for collaborative filtering which protects the privacy of individual data. The method is based on a probabilistic factor analysis model. Privacy protection is provided by a peer-to-peer protocol which is described elsewhere, but outlined in this paper. The factor analysis approach handles missing data without requiring default values for them. We give several experiments that suggest that this is most accurate method for CF to date. The new algorithm has other advantages in speed and storage over previous algorithms. Finally, we suggest applications of the approach to other kinds of statistical analyses of survey or questionaire data.\n",
      citations:
        ' ""10.1109/TETCI.2020.3023155/,  ""10.1007/978-3-030-82786-1_9/,  ""10.1360/SSI-2021-0304/,  ""10.1007/s11704-020-9462-9/,  ""10.1007/978-3-030-78086-9_11/,  ""10.1109/BigDataSE53435.2021.00026/,  ""10.1007/978-981-13-8676-3_17/,  ""10.4018/978-1-7998-0951-7.ch033/,  ""10.1016/j.comcom.2020.02.068/,  ""10.1016/j.procs.2020.03.372/,  ""10.1007/s00500-019-04605-z/,  ""10.1002/9781119711582.ch6/,  ""10.1109/ICEET48479.2020.9048206/,  ""10.1109/DICTA51227.2020.9363400/,  ""10.1002/9781119376996.ch7/,  ""10.1007/978-981-13-1595-4_12/,  ""10.1007/978-3-030-11928-7_30/,  ""10.1109/ICCKE48569.2019.8964698/,  ""10.1016/j.jpdc.2017.12.015/,  ""10.1007/978-1-4939-7131-2_189/,  ""10.1109/DSN.2018.00055/,  ""10.1007/s11390-018-1849-9/,  ""10.1109/ICASID.2018.8693183/,  ""10.1109/ICIS.2017.7960088/,  ""10.1007/978-1-4614-7163-9_189-1/,  ""10.1007/978-3-319-62004-6_10/,  ""10.1007/978-3-319-63579-8_16/,  ""10.4018/978-1-5225-0489-4.ch012/,  ""10.4018/978-1-5225-1837-2.ch059/,  ""10.1007/978-3-319-62004-6_11/,  ""10.4018/978-1-5225-0489-4.ch014/,  ""10.1016/j.neucom.2016.09.059/,  ""10.1109/ISM.2016.0023/,  ""10.1109/ISCC.2016.7543858/,  ""10.1109/ACIT-CSII-BCD.2016.075/,  ""10.1109/ACCESS.2016.2631546/,  ""10.1186/s13638-016-0710-5/,  ""10.1007/978-3-319-46227-1_8/,  ""10.1007/978-3-319-09885-2_23/,  ""10.1007/978-1-4899-7637-6_19/,  ""10.1109/TKDE.2015.2405556/,  ""10.1007/978-1-4899-7637-6_3/,  ""10.1109/TSC.2014.2381611/,  ""10.1140/epjb/e2015-60357-1/,  ""10.1109/ICASSP.2015.7178281/,  ""10.1109/SARNOF.2015.7324650/,  ""10.1109/ISKE.2015.25/,  ""10.1109/TSC.2014.2346492/,  ""10.1007/978-3-319-24177-7_6/,  ""10.1007/978-1-4614-7518-7_22/,  ""10.1007/s13369-013-0887-4/,  ""10.1007/s13278-014-0196-2/,  ""10.2200/S00574ED1V01Y201403DMK009/,  ""10.1109/CISP.2014.7003752/,  ""10.1007/s12243-013-0387-2/,  ""10.1007/978-3-319-09581-3_12/,  ""10.1007/978-1-4614-9242-9_8/,  ""10.1109/ICoAC.2014.7229742/,  ""10.1007/978-3-642-37832-4_16/,  ""10.1007/978-3-642-34207-3_2/,  ""10.1109/MSP.2012.2219653/,  ""10.4018/978-1-4666-2625-6.ch033/,  ""10.1109/PST.2013.6596038/,  ""10.4018/978-1-4666-3610-1.ch009/,  ""10.12720/joams.1.1.54-60/,  ""10.1007/978-1-4471-4555-4_12/,  ""10.1007/978-3-642-40203-6_23/,  ""10.2197/ipsjjip.21.617/,  ""10.4018/978-1-61350-501-4.ch011/,  ""10.1109/CTS.2012.6261090/,  ""10.1109/CTS.2012.6261088/,  ""10.1007/978-94-007-5699-1_32/,  ""10.1214/11-STS368/,  ""10.2200/S00414ED1V01Y201204DTM025/,  ""10.1007/978-3-642-30244-2_6/,  ""10.3156/jsoft.24.753/,  ""10.1109/ICASSP.2011.5947695/,  ""10.1109/Allerton.2011.6120295/,  ""10.1109/INM.2011.5990561/,  ""10.1109/ICSSSM.2011.5959336/,  ""10.1109/CASON.2011.6085923/,  ""10.1007/978-0-387-85820-3_5/,  ""10.1007/978-3-642-27260-8_6/,  ""10.4018/978-1-61692-880-3.ch020/,  ""10.1016/j.jet.2010.08.006/,  ""10.1007/978-3-642-19896-0_10/,  ""10.1007/978-3-642-23780-5_50/,  ""10.4018/jswis.2011100101/,  ""10.1108/10662241011050731/,  ""10.1109/ITHET.2010.5480054/,  ""10.1007/s12083-009-0051-9/,  ""10.1007/978-3-642-10687-3_11/,  ""10.1007/978-3-642-16567-2_5/,  ""10.1007/978-3-642-17080-5_3/,  ""10.1007/978-3-642-01091-0_5/,  ""10.1002/sam.10029/,  ""10.1109/IJCNN.2009.5178967/,  ""10.1109/GRC.2008.4664769/,  ""10.1109/NPC.2007.24/,  ""10.1007/978-3-540-72079-9_3/,  ""10.1007/978-3-540-75651-4_12/,  ""10.1007/978-3-540-72079-9_21/,  ""10.1007/978-3-540-72079-9_9/,  ""10.1007/1-84628-249-7_16/,  ""10.1007/978-3-540-30473-9_6/,  ""10.1016/j.eswa.2003.10.001/,  ""10.1007/978-3-540-25952-7_6/,  ""10.1109/ICDM.2003.1250993/,  ""10.17341/gazimmfd.300594/,  ""10.1371/journal.pone.0147944/,  ""10.3390/info10020042/,  ""10.1080/2573234X.2020.1763862/,  ""10.1007/s10586-017-1298-1/',
      group:
        "SIGIR '02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2002  Pages   238–245https://doi.org/10.1145/564376.564419",
      year: "",
      authors: "John Canny",
      doi: "10.1145/564376.564419",
    },
    {
      FIELD1: 65,
      id: "77D4A6C4",
      name: "Unsupervised document classification using sequential information maximization",
      url: "https://dl.acm.org/doi/abs/10.1145/564376.564401",
      abstract:
        "\nWe present a novel sequential clustering algorithm which is motivated by the Information Bottleneck (IB) method. In contrast to the agglomerative IB algorithm, the new sequential (sIB) approach is guaranteed to converge to a local maximum of the information with time and space complexity typically linear in the data size. information, as required by the original IB principle. Moreover, the time and space complexity are significantly improved. We apply this algorithm to unsupervised document classification. In our evaluation, on small and medium size corpora, the sIB is found to be consistently superior to all the other clustering methods we examine, typically by a significant margin. Moreover, the sIB results are comparable to those obtained by a supervised Naive Bayes classifier. Finally, we propose a simple procedure for trading cluster's recall to gain higher precision, and show how this approach can extract clusters which match the existing topics of the corpus almost perfectly.\n",
      citations:
        ' ""10.1109/TCYB.2020.3025636/,  ""10.1109/ACCESS.2021.3050411/,  ""10.1007/978-3-030-76620-7_23/,  ""10.1109/ACCESS.2020.2983433/,  ""10.1109/BigData50022.2020.9377787/,  ""10.1109/ICASSP.2019.8683613/,  ""10.1109/ACCESS.2019.2937967/,  ""10.3233/JIFS-179015/,  ""10.1109/TKDE.2018.2846252/,  ""10.1109/BigData47090.2019.9006108/,  ""10.1109/ACCESS.2018.2797694/,  ""10.1007/978-3-319-99579-3_49/,  ""10.4018/978-1-5225-5158-4.ch004/,  ""10.4018/978-1-5225-5191-1.ch003/,  ""10.1109/ICMLA.2018.00111/,  ""10.1007/978-3-319-66429-3_75/,  ""10.1109/ICTER.2017.8257786/,  ""10.1109/IJCNN.2017.7966289/,  ""10.4018/978-1-5225-0536-5.ch013/,  ""10.1109/FSKD.2017.8393013/,  ""10.1109/MLSP.2016.7738896/,  ""10.1007/978-3-319-28865-9_25/,  ""10.1109/ICSPCS.2015.7391731/,  ""10.1109/CCAA.2015.7148530/,  ""10.2139/ssrn.2516184/,  ""10.1109/ICDM.2013.76/,  ""10.1109/FPT.2013.6718332/,  ""10.1109/WCICA.2012.6359370/,  ""10.4018/978-1-60960-881-1.ch004/,  ""10.1007/s10844-012-0204-9/,  ""10.1109/WCICA.2012.6359386/,  ""10.1201/b12986-34/,  ""10.1109/CSAE.2011.5952644/,  ""10.5626/JCSE.2011.5.2.150/,  ""10.1007/978-3-642-24264-9_10/,  ""10.1007/978-3-642-12337-5_8/,  ""10.1007/978-3-642-15246-7_32/,  ""10.1109/TASL.2009.2015698/,  ""10.1007/s10827-009-0168-0/,  ""10.1109/ICDIM.2009.5356763/,  ""10.1109/KAMW.2008.4810664/,  ""10.1109/ISIT.2008.4595361/,  ""10.1109/WCICA.2008.4593357/,  ""10.1007/978-3-540-78646-7_34/,  ""10.1109/TIT.2008.928951/,  ""10.1109/ICASSP.2007.366284/,  ""10.1007/978-3-540-71703-4_78/,  ""10.1109/CIDM.2007.368899/,  ""10.1007/s10115-006-0009-7/,  ""10.1109/ICASSP.2006.1661458/,  ""10.1108/00220410610666501/,  ""10.1007/978-3-540-24741-8_9/,  ""10.1109/IV.2004.1320192/,  ""10.1016/j.physd.2004.08.022/,  ""10.1007/978-3-540-24752-4_13/,  ""10.1109/ICCV.2003.1238368/,  ""10.1109/ICDM.2003.1250966/,  ""10.1080/net.14.1.151.176/,  ""10.1162/153244303322753625/,  ""10.1371/journal.pcbi.1007065/,  ""10.3390/e24081132/',
      group:
        "SIGIR '02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2002  Pages   129–136https://doi.org/10.1145/564376.564401",
      year: "",
      authors: "Noam Slonim",
      doi: "10.1145/564376.564401",
    },
    {
      FIELD1: 66,
      id: "7B64A0AB",
      name: "Extending average precision to graded relevance judgments",
      url: "https://dl.acm.org/doi/abs/10.1145/1835449.1835550",
      abstract:
        "\nEvaluation metrics play a critical role both in the context of comparative evaluation of the performance of retrieval systems and in the context of learning-to-rank (LTR) as objective functions to be optimized. Many different evaluation metrics have been proposed in the IR literature, with average precision (AP) being the dominant one due a number of desirable properties it possesses. However, most of these measures, including average precision, do not incorporate graded relevance. In this work, we propose a new measure of retrieval effectiveness, the Graded Average Precision (GAP). GAP generalizes average precision to the case of multi-graded relevance and inherits all the desirable characteristics of AP: it has a nice probabilistic interpretation, it approximates the area under a graded precision-recall curve and it can be justified in terms of a simple but moderately plausible user model. We then evaluate GAP in terms of its informativeness and discriminative power. Finally, we show that GAP can reliably be used as an objective metric in learning to rank by illustrating that optimizing for GAP using SoftRank and LambdaRank leads to better performing ranking functions than the ones constructed by algorithms tuned to optimize for AP or NDCG even when using AP or NDCG as the test metrics.\n",
      citations:
        ' ""10.1080/13658816.2021.2005795/,  ""10.1007/978-3-030-72113-8_38/,  ""10.1109/TIM.2020.3038011/,  ""10.1007/978-3-030-34223-4_17/,  ""10.1007/978-3-319-98932-7_9/,  ""10.1007/978-1-4614-8265-9_80705/,  ""10.1109/ICWS.2017.124/,  ""10.1007/978-1-4899-7993-3_80705-1/,  ""10.1108/JD-08-2016-0099/,  ""10.1007/978-3-319-30671-1_14/,  ""10.1109/SKG.2016.033/,  ""10.4018/978-1-4666-8833-9.ch003/,  ""10.4018/978-1-4666-9562-7.ch063/,  ""10.1109/INFRKM.2016.7806339/,  ""10.1108/IJWIS-06-2014-0024/,  ""10.1108/S0065-283020150000039013/,  ""10.1007/978-3-319-06028-6_14/,  ""10.1007/s11042-012-1192-z/,  ""10.1007/978-3-642-54798-0_6/,  ""10.1016/j.physa.2012.11.052/,  ""10.1007/978-3-642-35341-3_4/,  ""10.1109/ICCKE.2012.6395381/,  ""10.1007/978-3-642-23318-0_11/,  ""10.1108/14684521111193175/,  ""10.1007/s11280-020-00846-3/',
      group:
        "SIGIR '10: Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrievalJuly 2010  Pages   603–610https://doi.org/10.1145/1835449.1835550",
      year: "",
      authors: "Stephen E. Robertson",
      doi: "10.1145/1835449.1835550",
    },
    {
      FIELD1: 67,
      id: "7CE9AA98",
      name: 'On the collective classification of email "speech acts"',
      url: "https://dl.acm.org/doi/abs/10.1145/1076034.1076094",
      abstract:
        '\nWe consider classification of email messages as to whether or not they contain certain "email acts", such as a request or a commitment. We show that exploiting the sequential correlation among email messages in the same thread can improve email-act classification. More specifically, we describe a new text-classification algorithm based on a dependency-network based collective classification method, in which the local classifiers are maximum entropy models based on words and certain relational features. We show that statistically significant improvements over a bag-of-words baseline classifier can be obtained for some, but not all, email-act classes. Performance improvements obtained by collective classification appears to be consistent across many email acts suggested by prior speech-act theory.\n',
      citations:
        ' ""10.1007/978-3-030-63820-7_76/,  ""10.1109/ICOASE51841.2020.9436547/,  ""10.1109/ACCESS.2019.2892757/,  ""10.5715/jnlp.26.59/,  ""10.1109/IJCNN.2019.8851772/,  ""10.1109/IJCNN.2019.8852141/,  ""10.1109/IJCNN.2019.8851765/,  ""10.1007/s13278-018-0487-0/,  ""10.1007/s41701-018-0030-6/,  ""10.1109/RTSI.2018.8548462/,  ""10.1075/cilt.340.07kin/,  ""10.1007/978-1-4899-7687-1_44/,  ""10.1109/CSCWD.2017.8066672/,  ""10.1109/WiMOB.2017.8115750/,  ""10.1109/ICDE.2016.7498311/,  ""10.1002/9781119292142.ch7/,  ""10.1007/978-3-319-28868-0_3/,  ""10.1007/978-3-319-10509-3_2/,  ""10.3233/AIC-150674/,  ""10.1007/978-3-319-19270-3_14/,  ""10.1007/978-3-319-12277-9_12/,  ""10.1007/978-3-319-11209-1_24/,  ""10.1007/978-3-319-10377-8_10/,  ""10.1007/s40593-013-0010-8/,  ""10.1007/978-3-642-40988-2_38/,  ""10.1007/978-3-642-28108-2_21/,  ""10.1007/978-1-4614-3223-4_6/,  ""10.1002/sam.10140/,  ""10.1002/j.2333-8504.2012.tb02298.x/,  ""10.1007/978-3-642-18181-8_11/,  ""10.1109/PASSAT/SocialCom.2011.107/,  ""10.1201/b11085-13/,  ""10.1007/978-1-4419-8462-3_13/,  ""10.1007/978-3-642-19047-6_4/,  ""10.2200/S00363ED1V01Y201105DTM017/,  ""10.1007/978-1-4419-6045-0_2/,  ""10.1007/978-1-4419-6287-4_4/,  ""10.1007/978-3-642-14363-2_22/,  ""10.1080/09500780802691736/,  ""10.1007/978-3-540-68234-9_12/',
      group:
        "SIGIR '05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2005  Pages   345–352https://doi.org/10.1145/1076034.1076094",
      year: "",
      authors: "Vitor R. Carvalho",
      doi: "10.1145/1076034.1076094",
    },
    {
      FIELD1: 68,
      id: "7C318F32",
      name: "A user-centred evaluation of ranking algorithms for interactive query expansion",
      url: "https://dl.acm.org/doi/abs/10.1145/160688.160710",
      abstract:
        "\nThe evaluation of 6 ranking algorithms for the ranking of terms for query expansion is discussed within the context of an investigation of interactive query expansion and relevance feedback in a real operational environment. The yardstick for the evaluation was provided by the user relevance judgements on the lists of the candidate terms for query expansion. The evaluation focuses on the similarities in the performance of the different algorithms and how the algorithms with similar performance treat terms.\n",
      citations:
        ' ""10.1007/978-981-15-9938-5_16/,  ""10.1007/978-1-4614-8495-0_2/,  ""10.1108/14684521111128014/,  ""10.1007/978-3-642-13033-5_44/,  ""10.1109/BIBE.2003.1188983/,  ""10.1007/3-540-48775-1_2/,  ""10.1007/978-1-4471-2099-5_9/',
      group:
        "SIGIR '93: Proceedings of the 16th annual international ACM SIGIR conference on Research and development in information retrievalJuly 1993  Pages   146–159https://doi.org/10.1145/160688.160710",
      year: "",
      authors: "Efthimis N. Efthimiadis",
      doi: "10.1145/160688.160710",
    },
    {
      FIELD1: 69,
      id: "766EB39C",
      name: "GaP: a factor model for discrete data",
      url: "https://dl.acm.org/doi/abs/10.1145/1008992.1009016",
      abstract:
        '\nWe present a probabilistic model for a document corpus that combines many of the desirable features of previous models. The model is called "GaP" for Gamma-Poisson, the distributions of the first and last random variable. GaP is a factor model, that is it gives an approximate factorization of the document-term matrix into a product of matrices Λ and X. These factors have strictly non-negative terms. GaP is a generative probabilistic model that assigns finite probabilities to documents in a corpus. It can be computed with an efficient and simple EM recurrence. For a suitable choice of parameters, the GaP factorization maximizes independence between the factors. So it can be used as an independent-component algorithm adapted to document data. The form of the GaP model is empirically as well as analytically motivated. It gives very accurate results as a probabilistic model (measured via perplexity) and as a retrieval model. The GaP model projects documents and terms into a low-dimensional space of "themes," and models texts as "passages" of terms on the same theme.\n',
      citations:
        ' ""10.1109/TKDE.2020.2992529/,  ""10.1080/08839514.2022.2032923/,  ""10.1214/21-AOAS1540/,  ""10.1109/TSP.2021.3060000/,  ""10.1109/ACCESS.2021.3106879/,  ""10.1287/mnsc.2020.3827/,  ""10.1109/LSP.2020.2991613/,  ""10.1109/ICMLA51294.2020.00060/,  ""10.1214/19-AOAS1265/,  ""10.1007/978-3-030-10928-8_38/,  ""10.1007/978-3-319-73031-8_1/,  ""10.2208/jscejipm.74.111/,  ""10.1080/01621459.2016.1260468/,  ""10.1214/17-BA1070/,  ""10.1109/TKDE.2018.2789445/,  ""10.1109/TKDE.2017.2783926/,  ""10.1109/HiPC.2018.00013/,  ""10.1109/QRS-C.2016.24/,  ""10.1109/ICCSNT.2016.8070127/,  ""10.1080/01621459.2015.1075407/,  ""10.3150/15-BEJ729/,  ""10.1109/TKDE.2014.2362525/,  ""10.1109/TPAMI.2013.211/,  ""10.1109/ICASSP.2014.6854798/,  ""10.1016/j.dsp.2014.02.018/,  ""10.1109/CSCWD.2012.6221814/,  ""10.1002/9781118562796.ch5/,  ""10.1109/ICASSP.2011.5946901/,  ""10.1109/CIDM.2007.368938/,  ""10.1109/ICTD.2006.301843/,  ""10.1080/10618600.2020.1826954/,  ""10.1093/imaiai/iaaa020/,  ""10.1007/s10618-020-00712-w/,  ""10.1177/0022243720943209/,  ""10.1080/07350015.2020.1802285/,  ""10.1093/jcr/ucab034/',
      group:
        "SIGIR '04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2004  Pages   122–129https://doi.org/10.1145/1008992.1009016",
      year: "",
      authors: "John Canny",
      doi: "10.1145/1008992.1009016",
    },
    {
      FIELD1: 70,
      id: "774B1D6E",
      name: "Regularized clustering for documents",
      url: "https://dl.acm.org/doi/abs/10.1145/1277741.1277760",
      abstract:
        "\nIn recent years, document clustering has been receiving more and more attentions as an important and fundamental technique for unsupervised document organization, automatictopic extraction, and fast information retrieval or filtering. In this paper, we propose a novel method for clustering documents using regularization. Unlike traditional globally regularized clustering methods, our method first construct a local regularized linear label predictor for each document vector, and then combine all those local regularizers with a global smoothness regularizer. So we call our algorithm Clustering with Local and Global Regularization (CLGR). We will show that the cluster memberships of the documents can be achieved by eigenvalue decomposition of a sparse symmetric matrix, which can be efficiently solved by iterative methods. Finally our experimental evaluations on several datasets are presented to show the superiorities of CLGR over traditional document clustering methods.\n",
      citations:
        ' ""10.1109/ISKE54062.2021.9755411/,  ""10.1007/978-3-030-16142-2_6/,  ""10.3103/S0146411614020023/,  ""10.1109/PAAP.2014.13/,  ""10.1007/978-94-007-6516-0_28/,  ""10.1587/transinf.E95.D.982/,  ""10.1587/transinf.E94.D.1227/,  ""10.1007/978-3-642-12035-0_17/,  ""10.4103/0256-4602.67153/,  ""10.3745/KIPSTB.2010.17B.2.177/,  ""10.1109/TKDE.2009.40/,  ""10.1109/ICET.2009.5353159/,  ""10.1007/978-3-540-87481-2_30/',
      group:
        "SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2007  Pages   95–102https://doi.org/10.1145/1277741.1277760",
      year: "",
      authors: "Fei Wang",
      doi: "10.1145/1277741.1277760",
    },
    {
      FIELD1: 71,
      id: "7EF446BE",
      name: "Personalized recommendation driven by information flow",
      url: "https://dl.acm.org/doi/abs/10.1145/1148170.1148258",
      abstract:
        "\nWe propose that the information access behavior of a group of people can be modeled as an information flow issue, in which people intentionally or unintentionally influence and inspire each other, thus creating an interest in retrieving or getting a specific kind of information or product. Information flow models how information is propagated in a social network. It can be a real social network where interactions between people reside; it can be, moreover, a virtual social network in that people only influence each other unintentionally, for instance, through collaborative filtering. We leverage users' access patterns to model information flow and generate effective personalized recommendations. First, an early adoption based information flow (EABIF) network describes the influential relationships between people. Second, based on the fact that adoption is typically category specific, we propose a topic-sensitive EABIF (TEABIF) network, in which access patterns are clustered with respect to the categories. Once an item has been accessed by early adopters, personalized recommendations are achieved by estimating whom the information will be propagated to with high probabilities. In our experiments with an online document recommendation system, the results demonstrate that the EABIF and the TEABIF can respectively achieve an improved (precision, recall) of (91.0%, 87.1%) and (108.5%, 112.8%) compared to traditional collaborative filtering, given an early adopter exists.\n",
      citations:
        ' ""10.1007/s00607-021-00987-x/,  ""10.1007/978-981-19-2069-1_16/,  ""10.1109/TCSS.2020.3046686/,  ""10.1109/ACCESS.2020.2979163/,  ""10.1587/transinf.2019DAP0008/,  ""10.1016/j.tcs.2020.06.008/,  ""10.1016/j.tcs.2019.07.032/,  ""10.1109/ACCESS.2019.2944927/,  ""10.1109/SUMMA48161.2019.8947520/,  ""10.1109/ACCESS.2019.2922155/,  ""10.1109/ICDE.2019.00047/,  ""10.1007/978-3-030-00916-8_37/,  ""10.1109/SKG.2018.00038/,  ""10.1007/978-1-4939-7131-2_286/,  ""10.1587/transinf.2017DAT0001/,  ""10.1109/SERVICES.2017.22/,  ""10.1007/978-1-4614-7163-9_286-1/,  ""10.1109/ACCESS.2017.2672680/,  ""10.1109/TCYB.2016.2537366/,  ""10.1007/978-3-319-32025-0_19/,  ""10.1007/978-3-319-39937-9_20/,  ""10.1007/s13278-016-0414-1/,  ""10.1186/s13673-015-0041-2/,  ""10.1016/j.eswa.2014.02.038/,  ""10.1016/j.ins.2014.03.121/,  ""10.1038/nbt.2635/,  ""10.1007/978-3-642-37401-2_32/,  ""10.1587/transcom.E95.B.1558/,  ""10.1587/transinf.E95.D.3026/,  ""10.1007/978-3-642-27663-7_2/,  ""10.1109/GLOCOM.2012.6503419/,  ""10.1109/PASSAT/SocialCom.2011.107/,  ""10.1109/ISI.2011.5984053/,  ""10.1109/WCICA.2010.5554627/,  ""10.1109/ICMULT.2010.5631066/,  ""10.1109/RCIS.2010.5507361/,  ""10.4018/jats.2010070103/,  ""10.1109/IJCNN.2008.4634360/,  ""10.1007/s10115-020-01461-4/,  ""10.3390/e23070796/,  ""10.1007/s11042-019-7470-2/,  ""10.1371/journal.pone.0259834/',
      group:
        "SIGIR '06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2006  Pages   509–516https://doi.org/10.1145/1148170.1148258",
      year: "",
      authors: "Xiaodan Song",
      doi: "10.1145/1148170.1148258",
    },
    {
      FIELD1: 72,
      id: "78F88FC8",
      name: "An improved markov random field model for supporting verbose queries",
      url: "https://dl.acm.org/doi/abs/10.1145/1571941.1572023",
      abstract:
        "\nRecent work in supervised learning of term-based retrieval models has shown significantly improved accuracy can often be achieved via better model estimation. In this paper, we show retrieval accuracy with Metzler and Croft's Markov random field (MRF) approach can be similarly improved via supervised learning. While the original MRF method estimates a parameter for each of its three feature classes from data, parameters within each class are set via a uniform weighting scheme adopted from the standard unigram. We conjecture greater MRF retrieval accuracy should be possible by better estimating within-class parameters, particularly for verbose queries employing natural language terms. Retrieval experiments with these queries on three TREC document collections show our improved MRF consistently out-performs both the original MRF and supervised unigram baselines. Additional experiments using blind-feedback and evaluation with optimal weighting demonstrate both the immediate value and further potential of our method.\n",
      citations:
        ' ""10.1002/asi.24619/,  ""10.1007/978-3-030-03520-4_14/,  ""10.1002/asi.23476/,  ""10.1002/asi.22789/,  ""10.1007/978-3-642-27323-0_54/,  ""10.4028/www.scientific.net/AMR.268-270.1773/',
      group:
        "SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrievalJuly 2009  Pages   476–483https://doi.org/10.1145/1571941.1572023",
      year: "",
      authors: "Matthew Lease",
      doi: "10.1145/1571941.1572023",
    },
    {
      FIELD1: 73,
      id: "7AFCF36A",
      name: "On an equivalence between PLSI and LDA",
      url: "https://dl.acm.org/doi/abs/10.1145/860435.860537",
      abstract:
        "\nLatent Dirichlet Allocation (LDA) is a fully generative approach to language modelling which overcomes the inconsistent generative semantics of Probabilistic Latent Semantic Indexing (PLSI). This paper shows that PLSI is a maximum a posteriori estimated LDA model under a uniform Dirichlet prior, therefore the perceived shortcomings of PLSI can be resolved and elucidated within the LDA framework.\n",
      citations:
        ' ""10.1186/s12911-022-01747-3/,  ""10.1109/TVT.2021.3125396/,  ""10.1007/978-3-030-96623-2_3/,  ""10.1007/978-981-16-0100-2_7/,  ""10.1007/978-3-030-83014-4_14/,  ""10.1109/JSTSP.2020.3045297/,  ""10.1109/ICMCIS52405.2021.9486416/,  ""10.1007/s13278-021-00772-w/,  ""10.1007/978-981-13-8676-3_46/,  ""10.3233/IDA-194528/,  ""10.1109/ICIMCIS51567.2020.9354320/,  ""10.1109/ICCIT51783.2020.9392719/,  ""10.3233/IDA-183836/,  ""10.1109/ICCC47050.2019.9064483/,  ""10.1109/ISCAIE.2018.8405511/,  ""10.1109/TNNLS.2016.2626379/,  ""10.4018/978-1-5225-5191-1.ch003/,  ""10.1109/ICASSP.2018.8461940/,  ""10.1049/iet-its.2017.0316/,  ""10.1016/j.engappai.2017.05.006/,  ""10.1007/978-3-319-42999-1_17/,  ""10.1088/1742-6596/801/1/012073/,  ""10.4018/978-1-5225-0536-5.ch013/,  ""10.1007/978-3-319-24261-3_10/,  ""10.1109/CVPR.2015.7298712/,  ""10.1016/j.ipm.2014.08.003/,  ""10.1109/TNNLS.2014.2299806/,  ""10.2200/S00574ED1V01Y201403DMK009/,  ""10.4018/978-1-4666-4426-7.ch004/,  ""10.1007/978-3-319-12823-8_45/,  ""10.1007/s11263-012-0596-6/,  ""10.1007/978-1-4614-3223-4_4/,  ""10.1109/CCIS.2012.6664628/,  ""10.1109/ICSAI.2012.6223526/,  ""10.1002/9781118562796.ch5/,  ""10.1109/MLSP.2011.6064562/,  ""10.1109/MLSP.2011.6064628/,  ""10.1007/978-3-642-23318-0_6/,  ""10.1527/tjsai.26.262/,  ""10.1007/978-3-642-03739-9_28/,  ""10.1109/SLT.2010.5700880/,  ""10.1007/978-3-642-04174-7_12/,  ""10.1007/978-3-540-79721-0_77/,  ""10.1007/s10115-019-01429-z/,  ""10.1177/0361198120987230/,  ""10.1080/01621459.2022.2123813/',
      group:
        "SIGIR '03: Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrievalJuly 2003  Pages   433–434https://doi.org/10.1145/860435.860537",
      year: "",
      authors: "Mark Girolami",
      doi: "10.1145/860435.860537",
    },
    {
      FIELD1: 74,
      id: "75AB4C29",
      name: "Learning to rank with SoftRank and Gaussian processes",
      url: "https://dl.acm.org/doi/abs/10.1145/1390334.1390380",
      abstract:
        '\nIn this paper we address the issue of learning to rank for document retrieval using Thurstonian models based on sparse Gaussian processes. Thurstonian models represent each document for a given query as a probability distribution in a score space; these distributions over scores naturally give rise to distributions over document rankings. However, in general we do not have observed rankings with which to train the model; instead, each document in the training set is judged to have a particular relevance level: for example "Bad", "Fair", "Good", or "Excellent". The performance of the model is then evaluated using information retrieval (IR) metrics such as Normalised Discounted Cumulative Gain (NDCG). Recently Taylor et al. presented a method called SoftRank which allows the direct gradient optimisation of a smoothed version of NDCG using a Thurstonian model. In this approach, document scores are represented by the outputs of a neural network, and score distributions are created artificially by adding random noise to the scores. The SoftRank mechanism is a general one; it can be applied to different IR metrics, and make use of different underlying models. In this paper we extend the SoftRank framework to make use of the score uncertainties which are naturally provided by a Gaussian process (GP), which is a probabilistic non-linear regression model. We further develop the model by using sparse Gaussian process techniques, which give improved performance and efficiency, and show competitive results against baseline methods when tested on the publicly available LETOR OHSUMED data set. We also explore how the available uncertainty information can be used in prediction and how it affects model performance.\n',
      citations:
        ' ""10.1007/978-3-030-75768-7_21/,  ""10.1007/978-3-030-58545-7_39/,  ""10.1142/S0218001419510078/,  ""10.1007/978-1-4899-7687-1_108/,  ""10.1007/978-1-4899-7502-7_108-1/,  ""10.1109/CVPR.2015.7298962/,  ""10.1007/978-3-319-13500-7_10/,  ""10.2200/S00607ED2V01Y201410HLT026/,  ""10.1109/MLSP.2012.6349812/,  ""10.1007/978-3-642-14267-3_4/,  ""10.2200/S00348ED1V01Y201104HLT012/,  ""10.1007/978-3-642-15939-8_32/,  ""10.1007/978-3-642-04180-8_61/',
      group:
        "SIGIR '08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrievalJuly 2008  Pages   259–266https://doi.org/10.1145/1390334.1390380",
      year: "",
      authors: "John Guiver",
      doi: "10.1145/1390334.1390380",
    },
    {
      FIELD1: 75,
      id: "7549BAB0",
      name: "Impedance coupling in content-targeted advertising",
      url: "https://dl.acm.org/doi/abs/10.1145/1076034.1076119",
      abstract:
        '\nThe current boom of the Web is associated with the revenues originated from on-line advertising. While search-based advertising is dominant, the association of ads with a Web page (during user navigation) is becoming increasingly important. In this work, we study the problem of associating ads with a Web page, referred to as content-targeted advertising, from a computer science perspective. We assume that we have access to the text of the Web page, the keywords declared by an advertiser, and a text associated with the advertiser\'s business. Using no other information and operating in fully automatic fashion, we propose ten strategies for solving the problem and evaluate their effectiveness. Our methods indicate that a matching strategy that takes into account the semantics of the problem (referred to as AAK for "ads and keywords") can yield gains in average precision figures of 60% compared to a trivial vector-based strategy. Further, a more sophisticated impedance coupling strategy, which expands the text of the Web page to reduce vocabulary impedance with regard to an advertisement, can yield extra gains in average precision of 50%. These are first results. They suggest that great accuracy in content-targeted advertising can be attained with appropriate algorithms.\n',
      citations:
        ' ""10.1007/978-3-030-44440-2_4/,  ""10.1109/ICDE48307.2020.00146/,  ""10.1109/ACCESS.2020.2997949/,  ""10.1109/ICDMW51313.2020.00066/,  ""10.4018/978-1-5225-5191-1.ch038/,  ""10.1007/s13278-018-0524-z/,  ""10.1007/978-1-4614-8265-9_455/,  ""10.1007/978-3-319-56793-8_1/,  ""10.1007/978-1-4899-7687-1_826/,  ""10.1109/ICDSE.2016.7823962/,  ""10.1007/978-1-4899-7993-3_455-2/,  ""10.1109/ICCCBDA.2016.7529557/,  ""10.1007/978-3-319-33625-1_34/,  ""10.1109/ISM.2015.75/,  ""10.1109/HPCSim.2014.6903711/,  ""10.1109/TKDE.2014.2313868/,  ""10.1109/ICDE.2014.6816731/,  ""10.4018/978-1-4666-5019-0.ch008/,  ""10.1109/rICT-ICeVT.2013.6741549/,  ""10.4018/978-1-4666-2542-6.ch006/,  ""10.1109/ACC.2013.6580778/,  ""10.4018/978-1-4666-2785-7.ch006/,  ""10.1007/978-3-642-31546-6_3/,  ""10.1007/978-3-642-37932-1_11/,  ""10.1007/978-3-642-39878-0_14/,  ""10.1007/978-3-642-54105-6_5/,  ""10.1016/j.neucom.2013.04.018/,  ""10.4018/978-1-60960-189-8.ch007/,  ""10.1007/978-3-642-20095-3_49/,  ""10.4018/978-1-60960-189-8.ch004/,  ""10.4018/978-1-60960-189-8.ch003/,  ""10.1109/ICCP.2011.6047839/,  ""10.4018/978-1-60960-189-8.ch011/,  ""10.4018/978-1-60960-189-8.ch013/,  ""10.1109/ITAPP.2010.5566329/,  ""10.1109/JPROC.2009.2039841/,  ""10.1007/978-3-642-15470-6_8/,  ""10.1007/978-3-642-15208-5_13/,  ""10.1007/s10115-009-0222-2/,  ""10.1109/WISA.2010.35/,  ""10.1109/ICME.2009.5202834/,  ""10.1007/978-0-387-39940-9_455/,  ""10.1109/MMSP.2008.4665039/,  ""10.1007/3-540-31590-X_13/,  ""10.1007/s10844-018-0540-5/,  ""10.1007/s11042-022-13747-6/',
      group:
        "SIGIR '05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2005  Pages   496–503https://doi.org/10.1145/1076034.1076119",
      year: "",
      authors: "Berthier Ribeiro-Neto",
      doi: "10.1145/1076034.1076119",
    },
    {
      FIELD1: 76,
      id: "7848A468",
      name: "A model of information retrieval based on a terminological logic",
      url: "https://dl.acm.org/doi/pdf/10.1145/160688.160753",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 77,
      id: "78B87EAD",
      name: "Discovering key concepts in verbose queries",
      url: "https://dl.acm.org/doi/abs/10.1145/1390334.1390419",
      abstract:
        "\nCurrent search engines do not, in general, perform well with longer, more verbose queries. One of the main issues in processing these queries is identifying the key concepts that will have the most impact on effectiveness. In this paper, we develop and evaluate a technique that uses query-dependent, corpus-dependent, and corpus-independent features for automatic extraction of key concepts from verbose queries. We show that our method achieves higher accuracy in the identification of key concepts than standard weighting methods such as inverse document frequency. Finally, we propose a probabilistic model for integrating the weighted key concepts identified by our method into a query, and demonstrate that this integration significantly improves retrieval effectiveness for a large set of natural language description queries derived from TREC topics on several newswire and web collections.\n",
      citations:
        ' ""10.1109/BigDataService49289.2020.00019/,  ""10.1007/978-3-030-60029-7_19/,  ""10.1109/IJCNN.2019.8852269/,  ""10.1109/IJCNN.2019.8851742/,  ""10.1109/IJCNN.2019.8851877/,  ""10.1109/NEXTCOMP.2019.8883643/,  ""10.1109/IJCNN.2019.8852093/,  ""10.1007/978-3-319-93935-3_7/,  ""10.1007/978-3-030-03520-4_14/,  ""10.1109/TKDE.2017.2754373/,  ""10.1007/978-3-319-92034-4_28/,  ""10.1007/978-3-319-70145-5_14/,  ""10.1063/1.5005471/,  ""10.1007/978-3-319-45763-5_9/,  ""10.1007/978-3-319-70145-5_4/,  ""10.1109/BigData.2017.8257996/,  ""10.1109/BESC.2016.7804498/,  ""10.1007/s41019-016-0012-2/,  ""10.1007/978-3-319-46523-4_37/,  ""10.1109/ICACCI.2016.7732096/,  ""10.2197/ipsjjip.24.721/,  ""10.1109/ComManTel.2015.7394255/,  ""10.1109/FSKD.2015.7382158/,  ""10.1007/978-3-319-11680-8_51/,  ""10.1016/j.ipm.2014.10.009/,  ""10.1007/978-3-319-06028-6_20/,  ""10.1007/978-3-319-07983-7_15/,  ""10.1016/j.ipm.2014.03.003/,  ""10.1109/FSKD.2013.6816362/,  ""10.1109/ICASSP.2013.6638271/,  ""10.1109/ICAdLT.2013.6568454/,  ""10.1007/978-3-642-45068-6_12/,  ""10.1007/978-3-642-45068-6_11/,  ""10.1587/transinf.E96.D.1016/,  ""10.1109/ICIP.2012.6467260/,  ""10.1109/HiPC.2012.6507486/,  ""10.1002/9781118360491.ch8/,  ""10.1002/meet.14504901188/,  ""10.1007/978-3-642-20291-9_37/,  ""10.1109/ICASSP.2011.5947617/,  ""10.1007/978-3-642-23318-0_21/,  ""10.2139/ssrn.3199534/,  ""10.1109/ISCSLP.2010.5684847/,  ""10.1109/IUCS.2010.5666249/,  ""10.2200/S00235ED1V01Y201004ICR015/,  ""10.1371/journal.pone.0064601/,  ""10.1371/journal.pone.0085236/,  ""10.1007/s10115-018-1267-x/,  ""10.1007/s10462-021-09972-4/,  ""10.1007/s10489-021-02376-5/',
      group:
        "SIGIR '08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrievalJuly 2008  Pages   491–498https://doi.org/10.1145/1390334.1390419",
      year: "",
      authors: "Michael Bendersky",
      doi: "10.1145/1390334.1390419",
    },
    {
      FIELD1: 78,
      id: "7B3B1FAC",
      name: "Automatic evaluation of world wide web search services",
      url: "https://dl.acm.org/doi/abs/10.1145/564376.564474",
      abstract:
        "\nUsers of the World-Wide Web are not only confronted by an immense overabundance of information, but also by a plethora of tools for searching for the web pages that suit their information needs. Web search engines differ widely in interface, features, coverage of the web, ranking methods, delivery of advertising, and more. In this paper, we present a method for comparing search engines automatically based on how they rank known item search results. Because the engines perform their search on overlapping (but different) subsets of the web collected at different points in time, evaluation of search engines poses significant challenges to the traditional information retrieval methodology. Our method uses known item searching; comparing the relative ranks of the items in the search engines' rankings. Our approach automatically constructs known item queries using query log analysis and automatically constructs the result via analysis of editor comments from the ODP (Open Directory Project). Additionally, we present our comparison on five (Lycos, Netscape, Fast, Google, HotBot) well-known search services and find that some services perform known item searches better than others, but the majority are statistically equivalent.\n",
      citations:
        ' ""10.1007/978-3-030-24322-7_54/,  ""10.1109/ISTEL.2016.7881901/,  ""10.1109/ICWR.2016.7498450/,  ""10.1108/EL-03-2015-0035/,  ""10.1109/PERVASIVE.2015.7087015/,  ""10.1109/ISTEL.2014.7000767/,  ""10.1109/IAdCC.2013.6514341/,  ""10.1108/14684521111193193/,  ""10.1108/14684521111161954/,  ""10.1017/CBO9780511997686.009/,  ""10.1007/978-3-642-15766-0_70/,  ""10.1016/j.is.2009.04.004/,  ""10.1007/978-81-8489-203-1_34/,  ""10.2200/S00191ED1V01Y200904ICR006/,  ""10.1108/00012530710817573/,  ""10.1108/00220410610714930/,  ""10.29252/jsdp.15.3.3/,  ""10.1007/s10664-019-09755-0/',
      group:
        "SIGIR '02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2002  Pages   421–422https://doi.org/10.1145/564376.564474",
      year: "",
      authors: "Abdur Chowdhury",
      doi: "10.1145/564376.564474",
    },
    {
      FIELD1: 79,
      id: "793EF8EC",
      name: "A statistical learning learning model of text classification for support vector machines",
      url: "https://dl.acm.org/doi/abs/10.1145/383952.383974",
      abstract:
        "\nThis paper develops a theoretical learning model of text classification for Support Vector Machines (SVMs). It connects the statistical properties of text-classification tasks with the generalization performance of a SVM in a quantitative way. Unlike conventional approaches to learning text classifiers, which rely primarily on empirical evidence, this model explains why and when SVMs perform well for text classification. In particular, it addresses the following questions: Why can support vector machines handle the large feature spaces in text classification effectively? How is this related to the statistical properties of text? What are sufficient conditions for applying SVMs to text-classification problems successfully?\n",
      citations:
        ' ""10.1007/978-3-030-84669-5_2/,  ""10.3846/jcem.2022.16012/,  ""10.1515/comp-2019-0011/,  ""10.1016/j.patrec.2011.01.018/,  ""10.1287/ijoc.1070.0255/,  ""10.3389/fdata.2022.880554/',
      group:
        "SIGIR '01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrievalSeptember 2001  Pages   128–136https://doi.org/10.1145/383952.383974",
      year: "",
      authors: "Thorsten Joachims",
      doi: "10.1145/383952.383974",
    },
    {
      FIELD1: 80,
      id: "77D63394",
      name: "Constructing informative prior distributions from domain knowledge in text classification",
      url: "https://dl.acm.org/doi/abs/10.1145/1148170.1148255",
      abstract:
        "\nSupervised learning approaches to text classification are in practice often required to work with small and unsystematically collected training sets. The alternative to supervised learning is usually viewed to be building classifiers by hand, using a domain expert's understanding of which features of the text are related to the class of interest. This is expensive, requires a degree of sophistication about linguistics and classification, and makes it difficult to use combinations of weak predictors. We propose instead combining domain knowledge with training examples in a Bayesian framework. Domain knowledge is used to specify a prior distribution for the parameters of a logistic regression model, and labeled training data is used to produce a posterior distribution, whose mode we take as the final classifier. We show on three text categorization data sets that this approach can rescue what would otherwise be disastrously bad training situations, producing much more effective classifiers.\n",
      citations:
        ' ""10.1016/j.ipm.2013.05.002/,  ""10.1007/978-3-642-35527-1_19/,  ""10.4018/978-1-60960-818-7.ch308/,  ""10.4018/978-1-60960-818-7.ch314/,  ""10.4018/978-1-61692-859-9.ch009/,  ""10.1007/s11704-009-0013-7/,  ""10.1108/17440080710848107/',
      group:
        "SIGIR '06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2006  Pages   493–500https://doi.org/10.1145/1148170.1148255",
      year: "",
      authors: "Aynur Dayanik",
      doi: "10.1145/1148170.1148255",
    },
    {
      FIELD1: 81,
      id: "77422F39",
      name: "Automatic web query classification using labeled and unlabeled training data",
      url: "https://dl.acm.org/doi/abs/10.1145/1076034.1076138",
      abstract:
        "\nAccurate topical categorization of user queries allows for increased effectiveness, efficiency, and revenue potential in general-purpose web search systems. Such categorization becomes critical if the system is to return results not just from a general web collection but from topic-specific databases as well. Maintaining sufficient categorization recall is very difficult as web queries are typically short, yielding few features per query. We examine three approaches to topical categorization of general web queries: matching against a list of manually labeled queries, supervised learning of classifiers, and mining of selectional preference rules from large unlabeled query logs. Each approach has its advantages in tackling the web query classification recall problem, and combining the three techniques allows us to classify a substantially larger proportion of queries than any of the individual techniques. We examine the performance of each approach on a real web query stream and show that our combined method accurately classifies 46% of queries, outperforming the recall of the best single approach by nearly 20%, with a 7% improvement in overall effectiveness.\n",
      citations:
        ' ""10.1007/978-3-030-16946-6_27/,  ""10.1007/978-3-030-58334-7_2/,  ""10.1109/ICMLC.2018.8526957/,  ""10.4236/jis.2017.81005/,  ""10.1007/978-3-319-66429-3_81/,  ""10.1109/ICMLC.2017.8108983/,  ""10.1109/ISCID.2017.212/,  ""10.1186/s40537-017-0095-2/,  ""10.1109/PIC.2015.7489835/,  ""10.1109/RIOS.2015.7270748/,  ""10.3233/WEB-150308/,  ""10.1007/978-3-642-24965-5_17/,  ""10.1109/ICCAE.2010.5451873/,  ""10.1007/978-3-642-02196-1_3/,  ""10.1007/978-3-540-77255-2_87/',
      group:
        "SIGIR '05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2005  Pages   581–582https://doi.org/10.1145/1076034.1076138",
      year: "",
      authors: "Steven M. Beitzel",
      doi: "10.1145/1076034.1076138",
    },
    {
      FIELD1: 82,
      id: "7F323E4F",
      name: "Towards musical query-by-semantic-description using the CAL500 data set",
      url: "https://dl.acm.org/doi/abs/10.1145/1277741.1277817",
      abstract:
        "\nQuery-by-semantic-description (QBSD)is a natural paradigm for retrieving content from large databases of music. A major impediment to the development of good QBSD systems for music information retrieval has been the lack of a cleanly-labeled, publicly-available, heterogeneous data set of songs and associated annotations. We have collected the Computer Audition Lab 500-song (CAL500) data set by having humans listen to and annotate songs using a survey designed to capture 'semantic associations' between music and words. We adapt the supervised multi-class labeling (SML) model, which has shown good performance on the task of image retrieval, and use the CAL500 data to learn a model for music retrieval. The model parameters are estimated using the weighted mixture hierarchies expectation-maximization algorithm which has been specifically designed to handle real-valued semantic association between words and songs, rather than binary class labels. The output of the SML model, a vector of class-conditional probabilities, can be interpreted as a semantic multinomial distribution over a vocabulary. By also representing a semantic query as a query multinomial distribution, we can quickly rank order the songs in a database based on the Kullback-Leibler divergence between the query multinomial and each song's semantic multinomial. Qualitative and quantitative results demonstrate that our SML model can both annotate a novel song with meaningful words and retrieve relevant songs given a multi-word, text-based query.\n",
      citations:
        ' ""10.1007/s11704-021-0569-4/,  ""10.1016/j.physa.2022.127261/,  ""10.1109/ACCESS.2019.2897849/,  ""10.1109/ICTAI.2019.00078/,  ""10.1109/TETCI.2017.2771298/,  ""10.1007/978-3-030-04780-1_25/,  ""10.1587/transinf.2017MUL0001/,  ""10.1007/978-3-030-01692-0_4/,  ""10.1214/17-AOAS1127/,  ""10.1007/s13735-016-0115-6/,  ""10.1007/978-3-319-68699-8_19/,  ""10.1007/978-981-10-3959-1_2/,  ""10.1007/978-3-662-44722-2_18/,  ""10.1109/ICASSP.2014.6853977/,  ""10.1109/ICME.2014.6890290/,  ""10.1109/TMM.2014.2311016/,  ""10.1109/ICME.2014.6890335/,  ""10.1109/ICMEW.2013.6618342/,  ""10.1109/MMSP.2013.6659297/,  ""10.1007/978-1-4471-4555-4_20/,  ""10.1007/978-3-642-28744-2_22/,  ""10.1007/978-3-642-27302-5_3/,  ""10.4018/978-1-61520-919-4.ch014/,  ""10.1201/b11041-13/,  ""10.1186/1687-4722-2011-11/,  ""10.1109/TASL.2009.2022435/,  ""10.1109/ICME.2009.5202634/,  ""10.1109/ACII.2009.5349591/,  ""10.1007/978-3-540-78646-7_68/,  ""10.4028/www.scientific.net/AMR.791-793.1283/',
      group:
        "SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2007  Pages   439–446https://doi.org/10.1145/1277741.1277817",
      year: "",
      authors: "Douglas Turnbull",
      doi: "10.1145/1277741.1277817",
    },
    {
      FIELD1: 83,
      id: "7C4CFB31",
      name: "Learning to rank at query-time using association rules",
      url: "https://dl.acm.org/doi/abs/10.1145/1390334.1390381",
      abstract:
        "\nSome applications have to present their results in the form of ranked lists. This is the case of many information retrieval applications, in which documents must be sorted according to their relevance to a given query. This has led the interest of the information retrieval community in methods that automatically learn effective ranking functions. In this paper we propose a novel method which uncovers patterns (or rules) in the training data associating features of the document with its relevance to the query, and then uses the discovered rules to rank documents. To address typical problems that are inherent to the utilization of association rules (such as missing rules and rule explosion), the proposed method generates rules on a demand-driven basis, at query-time. The result is an extremely fast and effective ranking method. We conducted a systematic evaluation of the proposed method using the LETOR benchmark collections. We show that generating rules on a demand-driven basis can boost ranking performance, providing gains ranging from 12% to 123%, outperforming the state-of-the-art methods that learn to rank, with no need of time-consuming and laborious pre-processing. As a highlight, we also show that additional information, such as query terms, can make the generated rules more discriminative, further improving ranking performance.\n",
      citations:
        ' ""10.1109/IJCNN.2018.8489646/,  ""10.1109/ICOA.2018.8370597/,  ""10.1108/IJWIS-12-2015-0046/,  ""10.4018/ijdsst.2015070102/,  ""10.1007/978-3-319-10933-6_18/,  ""10.1002/asi.22958/,  ""10.1007/978-3-642-37450-0_27/,  ""10.1002/int.20455/,  ""10.1007/978-3-642-23737-9_7/,  ""10.1007/978-3-642-14267-3_19/,  ""10.1007/978-3-642-14267-3_2/,  ""10.1007/978-3-642-14267-3_1/,  ""10.1007/978-0-85729-525-5_9/,  ""10.2139/ssrn.1736062/,  ""10.1109/ICISE.2010.5690335/,  ""10.7763/IJCTE.2009.V1.73/,  ""10.1371/journal.pone.0050112/,  ""10.1002/cpe.4464/,  ""10.1007/s00500-020-04990-w/',
      group:
        "SIGIR '08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrievalJuly 2008  Pages   267–274https://doi.org/10.1145/1390334.1390381",
      year: "",
      authors: "Adriano A. Veloso",
      doi: "10.1145/1390334.1390381",
    },
    {
      FIELD1: 84,
      id: "7FBE07E1",
      name: "On the local optimality of LambdaRank",
      url: "https://dl.acm.org/doi/abs/10.1145/1571941.1572021",
      abstract:
        "\nA machine learning approach to learning to rank trains a model to optimize a target evaluation measure with repect to training data. Currently, existing information retrieval measures are impossible to optimize directly except for models with a very small number of parameters. The IR community thus faces a major challenge: how to optimize IR measures of interest directly. In this paper, we present a solution. Specifically, we show that LambdaRank, which smoothly approximates the gradient of the target measure, can be adapted to work with four popular IR target evaluation measures using the same underlying gradient construction. It is likely, therefore, that this construction is extendable to other evaluation measures. We empirically show that LambdaRank finds a locally optimal solution for mean [email protected], mean NDCG, MAP and MRR with a 99% confidence rate. We also show that the amount of effective training data varies with IR measure and that with a sufficiently large training set size, matching the training optimization measure to the target evaluation measure yields the best accuracy.\n",
      citations:
        ' ""10.1109/ACCESS.2022.3142096/,  ""10.1007/978-3-030-84186-7_8/,  ""10.1007/978-3-030-75768-7_21/,  ""10.1109/TCSVT.2019.2899055/,  ""10.1109/ICICTA51737.2020.00033/,  ""10.1007/978-3-319-48740-3_20/,  ""10.1093/bioinformatics/btv413/,  ""10.2139/ssrn.2590020/,  ""10.2200/S00607ED2V01Y201410HLT026/,  ""10.1007/s10994-011-5270-7/,  ""10.2200/S00348ED1V01Y201104HLT012/,  ""10.1017/CBO9781139042918.009/,  ""10.1007/s10044-019-00856-6/,  ""10.1007/s10791-019-09366-9/,  ""10.1287/mnsc.2018.3255/',
      group:
        "SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrievalJuly 2009  Pages   460–467https://doi.org/10.1145/1571941.1572021",
      year: "",
      authors: "Pinar Donmez",
      doi: "10.1145/1571941.1572021",
    },
    {
      FIELD1: 85,
      id: "8132EDEF",
      name: "The wisdom of the few: a collaborative filtering approach based on expert opinions from the web",
      url: "https://dl.acm.org/doi/abs/10.1145/1571941.1572033",
      abstract:
        "\nNearest-neighbor collaborative filtering provides a successful means of generating recommendations for web users. However, this approach suffers from several shortcomings, including data sparsity and noise, the cold-start problem, and scalability. In this work, we present a novel method for recommending items to users based on expert opinions. Our method is a variation of traditional collaborative filtering: rather than applying a nearest neighbor algorithm to the user-rating data, predictions are computed using a set of expert neighbors from an independent dataset, whose opinions are weighted according to their similarity to the user. This method promises to address some of the weaknesses in traditional collaborative filtering, while maintaining comparable accuracy. We validate our approach by predicting a subset of the Netflix data set. We use ratings crawled from a web portal of expert reviews, measuring results both in terms of prediction accuracy and recommendation list precision. Finally, we explore the ability of our method to generate useful recommendations, by reporting the results of a user-study where users prefer the recommendations generated by our approach.\n",
      citations:
        ' ""10.1109/CITC54365.2021.00020/,  ""10.1007/978-3-030-23760-8_1/,  ""10.1108/JM2-09-2019-0229/,  ""10.1007/978-3-030-16142-2_28/,  ""10.1142/S2196888819500192/,  ""10.1109/CEC.2019.8790235/,  ""10.1145/3359242/,  ""10.1007/s40815-018-0508-1/,  ""10.1007/s10758-017-9335-y/,  ""10.1007/978-3-030-03596-9_27/,  ""10.1007/978-3-319-90092-6_7/,  ""10.1007/978-3-319-98443-8_19/,  ""10.1109/SKG.2018.00023/,  ""10.1109/CBD.2018.00063/,  ""10.1115/1.4037610/,  ""10.1109/CEC.2017.7969435/,  ""10.1007/978-3-319-68765-0_25/,  ""10.1080/07491409.2017.1346534/,  ""10.1007/978-3-319-57529-2_8/,  ""10.1109/WISA.2017.21/,  ""10.1109/CSITSS.2017.8447672/,  ""10.1109/IT4OD.2016.7479277/,  ""10.1007/s12525-016-0230-5/,  ""10.1007/978-3-319-49001-4_1/,  ""10.1007/978-3-319-30671-1_71/,  ""10.1109/CEC.2016.7743786/,  ""10.1016/j.procs.2015.04.055/,  ""10.1007/978-1-4899-7637-6_11/,  ""10.1007/978-1-4899-7637-6_7/,  ""10.1109/TMM.2014.2311012/,  ""10.1007/978-3-319-07293-7_1/,  ""10.1007/978-3-319-08786-3_33/,  ""10.1007/978-3-319-13734-6_17/,  ""10.1109/ISDA.2013.6920729/,  ""10.1007/978-3-642-28977-4_10/,  ""10.1587/transinf.E95.D.932/,  ""10.1007/978-3-642-23088-2_40/,  ""10.1109/ICDIM.2011.6093367/,  ""10.1109/ICCRD.2011.5764131/,  ""10.1109/ICSESS.2011.5982269/,  ""10.1007/978-0-387-85820-3_2/,  ""10.1109/ICMULT.2010.5630989/,  ""10.1007/978-3-642-15390-7_61/,  ""10.18178/ijmlc.2016.6.2.580/,  ""10.4028/www.scientific.net/AMR.765-767.989/,  ""10.1002/cpe.4168/',
      group:
        "SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrievalJuly 2009  Pages   532–539https://doi.org/10.1145/1571941.1572033",
      year: "",
      authors: "Xavier Amatriain",
      doi: "10.1145/1571941.1572033",
    },
    {
      FIELD1: 86,
      id: "8096B9A8",
      name: "Enhancing text clustering by leveraging Wikipedia semantics",
      url: "https://dl.acm.org/doi/abs/10.1145/1390334.1390367",
      abstract:
        '\nMost traditional text clustering methods are based on "bag of words" (BOW) representation based on frequency statistics in a set of documents. BOW, however, ignores the important information on the semantic relationships between key terms. To overcome this problem, several methods have been proposed to enrich text representation with external resource in the past, such as WordNet. However, many of these approaches suffer from some limitations: 1) WordNet has limited coverage and has a lack of effective word-sense disambiguation ability; 2) Most of the text representation enrichment strategies, which append or replace document terms with their hypernym and synonym, are overly simple. In this paper, to overcome these deficiencies, we first propose a way to build a concept thesaurus based on the semantic relations (synonym, hypernym, and associative relation) extracted from Wikipedia. Then, we develop a unified framework to leverage these semantic relations in order to enhance traditional content similarity measure for text clustering. The experimental results on Reuters and OHSUMED datasets show that with the help of Wikipedia thesaurus, the clustering performance of our method is improved as compared to previous methods. In addition, with the optimized weights for hypernym, synonym, and associative concepts that are tuned with the help of a few labeled data users provided, the clustering performance can be further improved.\n',
      citations:
        ' ""10.1007/s10664-021-10009-1/,  ""10.1016/j.jksuci.2020.02.003/,  ""10.1002/9781119711582.ch9/,  ""10.1007/978-3-030-05090-0_28/,  ""10.1007/978-3-030-11027-7_8/,  ""10.1007/978-3-319-93417-4_28/,  ""10.1007/978-3-319-73500-9_8/,  ""10.1109/ICOEI.2017.8300793/,  ""10.1186/s13173-017-0058-7/,  ""10.1007/978-3-319-59268-8_10/,  ""10.1007/978-3-319-60438-1_45/,  ""10.1007/978-3-319-42291-6_16/,  ""10.1080/17517575.2015.1080301/,  ""10.1007/978-3-319-49304-6_41/,  ""10.1007/978-1-4899-7637-6_4/,  ""10.1007/978-3-319-22047-5_9/,  ""10.1527/tjsai.30.510/,  ""10.1109/TBDATA.2015.2451635/,  ""10.1007/978-3-319-08326-1_44/,  ""10.1007/978-3-319-13326-3_30/,  ""10.1016/j.procs.2014.05.314/,  ""10.1109/ACCESS.2014.2332453/,  ""10.1007/978-3-319-01766-2_73/,  ""10.1007/978-3-642-37456-2_22/,  ""10.1007/978-3-642-41687-3_22/,  ""10.1016/j.neucom.2013.04.018/,  ""10.4018/978-1-4666-2827-4.ch008/,  ""10.1109/IEEEGCC.2013.6705759/,  ""10.1109/IJCNN.2013.6706853/,  ""10.1007/978-1-4614-3223-4_12/,  ""10.1007/978-3-642-29934-6_41/,  ""10.1587/transinf.E95.D.982/,  ""10.1007/s10844-012-0204-9/,  ""10.1109/INISTA.2012.6246996/,  ""10.1007/978-3-642-22263-4_2/,  ""10.1007/978-3-642-23863-5_1/,  ""10.1007/978-3-642-25661-5_60/,  ""10.1007/978-3-642-25661-5_53/,  ""10.1007/978-3-642-21353-3_9/,  ""10.1007/978-3-642-24425-4_85/,  ""10.1007/978-3-642-20841-6_15/,  ""10.1007/978-3-642-20841-6_39/,  ""10.4018/978-1-60960-625-1.ch004/,  ""10.1109/ICMT.2011.6002315/,  ""10.1007/978-3-642-23577-1_32/,  ""10.1016/j.sbspro.2011.10.595/,  ""10.1109/ICCIAutom.2011.6183985/,  ""10.1007/978-3-642-15390-7_1/,  ""10.1007/978-3-642-15390-7_2/,  ""10.1007/978-90-481-9794-1_25/,  ""10.1109/ICDEW.2010.5452698/,  ""10.1007/978-3-642-16581-8_8/,  ""10.1109/IJCNN.2009.5179022/,  ""10.1080/0960085X.2020.1816145/,  ""10.1007/s10115-018-1278-7/,  ""10.4028/www.scientific.net/AMM.644-650.1523/',
      group:
        "SIGIR '08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrievalJuly 2008  Pages   179–186https://doi.org/10.1145/1390334.1390367",
      year: "",
      authors: "Jian Hu",
      doi: "10.1145/1390334.1390367",
    },
    {
      FIELD1: 87,
      id: "78878051",
      name: "Phonetic confusion matrix based spoken document retrieval",
      url: "https://dl.acm.org/doi/abs/10.1145/345508.345552",
      abstract:
        "\nCombined word-based index and phonetic indexes have been used to improve the performance of spoken document retrieval systems primarily by addressing the out-of-vocabulary retrieval problem. However, a known problem with phonetic recognition is its limited accuracy in comparison with word level recognition. We propose a novel method for phonetic retrieval in the CueVideo system based on the probabilistic formulation of term weighting using phone confusion data in a Bayesian framework. We evaluate this method of spoken document retrieval against word-based retrieval for the search levels identified in a realistic video-based distributed learning setting. Using our test data, we achieved an average recall of 0.88 with an average precision of 0.69 for retrieval of out-of-vocabulary words on phonetic transcripts with 35% word error rate. For in-vocabulary words, we achieved a 17% improvement in recall over word-based retrieval with a 17% loss in precision for word error rites ranging from 35 to 65%.\n",
      citations:
        ' ""10.1109/ISCSLP.2014.6936639/,  ""10.1109/SLT.2014.7078612/,  ""10.1108/LHT-08-2013-0108/,  ""10.1109/ASRU.2013.6707774/,  ""10.1109/ISCSLP.2012.6423480/,  ""10.1109/ICASSP.2010.5494967/,  ""10.1109/TENCON.2010.5686601/,  ""10.1109/ASRU.2009.5372952/,  ""10.1109/ICASSP.2008.4518771/,  ""10.1007/978-3-540-73325-6_90/,  ""10.1109/IRI.2007.4296690/,  ""10.1109/ICASSP.2006.1660182/,  ""10.1109/ICASSP.2006.1660180/,  ""10.1109/MSP.2005.1511823/,  ""10.1109/ISIMP.2004.1434146/,  ""10.1007/978-1-4757-6928-9_1/,  ""10.1177/016555150302900201/,  ""10.1007/3-540-45637-6_9/,  ""10.1109/TSA.2002.802541/,  ""10.1007/3-540-45637-6_4/,  ""10.1109/HICSS.2001.926512/,  ""10.1109/HICSS.2001.926513/,  ""10.1016/S0923-5965(00)00025-4/,  ""10.1007/s10803-019-04246-z/',
      group:
        "SIGIR '00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrievalJuly 2000  Pages   81–87https://doi.org/10.1145/345508.345552",
      year: "",
      authors: "Savitha Srinivasan",
      doi: "10.1145/345508.345552",
    },
    {
      FIELD1: 88,
      id: "75A02708",
      name: "Reducing long queries using query quality predictors",
      url: "https://dl.acm.org/doi/abs/10.1145/1571941.1572038",
      abstract:
        "\nLong queries frequently contain many extraneous terms that hinder retrieval of relevant documents. We present techniques to reduce long queries to more effective shorter ones that lack those extraneous terms. Our work is motivated by the observation that perfectly reducing long TREC description queries can lead to an average improvement of 30% in mean average precision. Our approach involves transforming the reduction problem into a problem of learning to rank all sub-sets of the original query (sub-queries) based on their predicted quality, and selecting the top sub-query. We use various measures of query quality described in the literature as features to represent sub-queries, and train a classifier. Replacing the original long query with the top-ranked sub-query chosen by the ranker results in a statistically significant average improvement of 8% on our test sets. Analysis of the results shows that query reduction is well-suited for moderately-performing long queries, and a small set of query quality predictors are well-suited for the task of ranking sub-queries.\n",
      citations:
        ' ""10.1109/TSE.2020.3000520/,  ""10.1109/ACCESS.2020.2985915/,  ""10.1109/NEXTCOMP.2019.8883643/,  ""10.1109/ITME.2019.00046/,  ""10.1002ra2.15/,  ""10.1109/WI.2018.00-51/,  ""10.1007/978-3-319-92034-4_28/,  ""10.1007/978-981-10-3689-7_5/,  ""10.1007/978-3-319-70145-5_4/,  ""10.1007/978-3-319-56608-5_3/,  ""10.1007/978-3-319-45763-5_9/,  ""10.1007/978-3-319-70145-5_14/,  ""10.1109/BigData.2017.8257996/,  ""10.1093/database/bax021/,  ""10.1007/978-3-319-30671-1_23/,  ""10.1007/978-3-319-30671-1_38/,  ""10.1007/s41019-016-0012-2/,  ""10.1007/978-3-319-16354-3_59/,  ""10.1109/ICICES.2014.7033845/,  ""10.1109/ICDE.2014.6816658/,  ""10.1007/978-3-319-07248-7_16/,  ""10.1007/978-3-319-06028-6_20/,  ""10.1007/978-3-642-45068-6_12/,  ""10.1007/978-3-642-23318-0_21/,  ""10.1007/978-3-642-20291-9_37/,  ""10.1109/ICASSP.2011.5947617/,  ""10.1007/978-3-642-24583-1_37/,  ""10.1002/aris.2011.1440450111/,  ""10.1109/ISCSLP.2010.5684847/,  ""10.1109/IUCS.2010.5666249/,  ""10.1109/NLPKE.2010.5587826/,  ""10.2200/S00235ED1V01Y201004ICR015/',
      group:
        "SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrievalJuly 2009  Pages   564–571https://doi.org/10.1145/1571941.1572038",
      year: "",
      authors: "Giridhar Kumaran",
      doi: "10.1145/1571941.1572038",
    },
    {
      FIELD1: 89,
      id: "754BE1D0",
      name: "The effect multiple query representations on information retrieval system performance",
      url: "https://dl.acm.org/doi/pdf/10.1145/160688.160760",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 90,
      id: "75695BC8",
      name: "Latent semantic indexing is an optimal special case of multidimensional scaling",
      url: "https://dl.acm.org/doi/abs/10.1145/133160.133191",
      abstract:
        "\nLatent Semantic Indexing (LSI) is a technique for representing documents, queries, and terms as vectors in a multidimensional real-valued space. The representtions are approximations to the original term space encoding, and are found using the matrix technique of Singular Value Decomposition. In comparison Multidimensional Scaling (MDS) is a class of data analysis techniques for representing data points as points in a multidimensional real-valued space. The objects are represented so that inter-point similarities in the space match inter-object similarity information provided by the researcher. We illustrate how the document representations given by LSI are equivalent to the optimal representations found when solving a particular MDS problem in which the given inter-object similarity  information is provided by the inner product similarities between the documents themselves. We further analyze a more general MDS problem in which the interdocument similarity information, although still in inner product form is arbitrary with respect to the vector space encoding of the documents.\n",
      citations:
        ' ""10.1007/978-981-10-0534-3_31/,  ""10.1007/978-3-642-45252-9_4/,  ""10.4018/978-1-61350-126-9.ch015/,  ""10.1109/FUZZY.2011.6007525/,  ""10.1007/978-3-642-22688-5_29/,  ""10.1007/978-3-642-15420-1_11/,  ""10.1007/978-3-540-74825-0_23/,  ""10.1109/ITI.2005.1491118/,  ""10.1109/ICONIP.2002.1198992/,  ""10.1111/j.1468-2958.2002.tb00802.x/,  ""10.1002/asi.1137/,  ""10.1007/978-1-4471-0443-8_13/,  ""10.1109/ICNN.1996.549089/,  ""10.1007/s10699-019-09592-w/',
      group:
        "SIGIR '92: Proceedings of the 15th annual international ACM SIGIR conference on Research and development in information retrievalJune 1992  Pages   161–167https://doi.org/10.1145/133160.133191",
      year: "",
      authors: "Brian T. Bartell",
      doi: "10.1145/133160.133191",
    },
    {
      FIELD1: 91,
      id: "801985B8",
      name: "Studying the use of popular destinations to enhance web search interaction",
      url: "https://dl.acm.org/doi/abs/10.1145/1277741.1277771",
      abstract:
        "\nWe present a novel Web search interaction feature which, for a given query, provides links to websites frequently visited by other users with similar information needs. These popular destinations complement traditional search results, allowing direct navigation to authoritative resources for the query topic. Destinations are identified using the history of search and browsing behavior of many users over an extended time period, whose collective behavior provides a basis for computing source authority. We describe a user study which compared the suggestion of destinations with the previously proposed suggestion of related queries, as well as with traditional, unaided Web search. Results show that search enhanced by destination suggestions outperforms other systems for exploratory tasks, with best performance obtained from mining past user behavior at query-level granularity.\n",
      citations:
        ' ""10.2200/S01103ED1V01Y202105ICR074/,  ""10.1109/JCDL52503.2021.00043/,  ""10.1007/978-3-030-38825-6_8/,  ""10.1007/978-3-030-58334-7_8/,  ""10.2478/dim-2020-0047/,  ""10.1007/978-3-030-29387-1_18/,  ""10.1007/978-3-319-90092-6_7/,  ""10.2964/jsik_2018_008/,  ""10.4018/978-1-5225-1837-2.ch095/,  ""10.4018/978-1-5225-0613-3.ch004/,  ""10.1108/JD-06-2015-0068/,  ""10.1007/978-81-322-2012-1_42/,  ""10.1007/978-3-319-06160-3_5/,  ""10.1109/TKDE.2014.2316794/,  ""10.1109/DSAA.2014.7058083/,  ""10.1007/978-3-642-40501-3_23/,  ""10.1002/asi.22901/,  ""10.1007/978-1-4471-5301-6_7/,  ""10.1109/RCIS.2013.6577714/,  ""10.1109/SOCPAR.2013.7054105/,  ""10.1007/978-3-642-35341-3_48/,  ""10.1007/978-1-4614-1695-1_23/,  ""10.1109/ICoAC.2012.6416825/,  ""10.1007/978-3-642-23160-5_4/,  ""10.1007/978-3-642-23318-0_20/,  ""10.1109/ICCSNT.2011.6182453/,  ""10.1109/CEWIT.2011.6135877/,  ""10.1109/CBMI.2011.5972523/,  ""10.1007/978-3-642-24469-8_21/,  ""10.2200/S00174ED1V01Y200901ICR003/,  ""10.1007/s11760-008-0087-y/',
      group:
        "SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2007  Pages   159–166https://doi.org/10.1145/1277741.1277771",
      year: "",
      authors: "Ryen W. White",
      doi: "10.1145/1277741.1277771",
    },
    {
      FIELD1: 92,
      id: "7D807FD5",
      name: "Refined experts: improving classification in large taxonomies",
      url: "https://dl.acm.org/doi/abs/10.1145/1571941.1571946",
      abstract:
        '\nWhile large-scale taxonomies--especially for web pages--have been in existence for some time, approaches to automatically classify documents into these taxonomies have met with limited success compared to the more general progress made in text classification. We argue that this stems from three causes: increasing sparsity of training data at deeper nodes in the taxonomy, error propagation where a mistake made high in the hierarchy cannot be recovered, and increasingly complex decision surfaces in higher nodes in the hierarchy. While prior research has focused on the first problem, we introduce methods that target the latter two problems--first by biasing the training distribution to reduce error propagation and second by propagating up "first-guess" expert information in a bottom-up manner before making a refined top down choice. Finally, we present an empirical study demonstrating that the suggested changes lead to 10--30% improvements in F1 scores versus an accepted competitive baseline, hierarchical SVMs.\n',
      citations:
        ' ""10.1109/TGRS.2021.3111117/,  ""10.1109/ICKG52313.2021.00063/,  ""10.1007/978-3-030-74296-6_21/,  ""10.1007/978-3-030-61616-8_60/,  ""10.1007/978-3-030-16148-4_6/,  ""10.1007/978-3-030-37334-4_31/,  ""10.1007/978-3-030-01620-3_1/,  ""10.1007/978-3-030-01620-3_2/,  ""10.1007/978-3-030-01620-3_6/,  ""10.1109/ICMLA.2017.0-146/,  ""10.1109/ICCTIM.2015.7224591/,  ""10.1186/s12859-015-0777-8/,  ""10.1109/DSAA.2014.7058134/,  ""10.1007/978-3-319-12511-4_11/,  ""10.5715/jnlp.21.41/,  ""10.1016/j.cviu.2014.03.010/,  ""10.1109/ICAICT.2014.7035939/,  ""10.1177/0165551513507415/,  ""10.1007/978-3-642-42054-2_42/,  ""10.1002/asi.22926/,  ""10.1007/978-3-642-29764-9_4/,  ""10.1162/COLI_a_00148/,  ""10.1007/978-1-4614-3223-4_6/,  ""10.1007/978-3-642-35527-1_27/,  ""10.1007/978-3-642-30732-4_21/,  ""10.1007/978-3-642-22913-8_7/,  ""10.1109/ACSSC.2010.5757470/,  ""10.1109/ICDIM.2010.5664247/,  ""10.1007/s11192-019-03246-1/,  ""10.1007/s10618-021-00762-8/',
      group:
        "SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrievalJuly 2009  Pages   11–18https://doi.org/10.1145/1571941.1571946",
      year: "",
      authors: "Paul N. Bennett",
      doi: "10.1145/1571941.1571946",
    },
    {
      FIELD1: 93,
      id: "7DC03A9C",
      name: "Locality preserving indexing for document representation",
      url: "https://dl.acm.org/doi/abs/10.1145/1008992.1009012",
      abstract:
        "\nDocument representation and indexing is a key problem for document analysis and processing, such as clustering, classification and retrieval. Conventionally, Latent Semantic Indexing (LSI) is considered effective in deriving such an indexing. LSI essentially detects the most representative features for document representation rather than the most discriminative features. Therefore, LSI might not be optimal in discriminating documents with different semantics. In this paper, a novel algorithm called Locality Preserving Indexing (LPI) is proposed for document indexing. Each document is represented by a vector with low dimensionality. In contrast to LSI which discovers the global structure of the document space, LPI discovers the local structure and obtains a compact document representation subspace that best detects the essential semantic structure. We compare the proposed LPI approach with LSI on two standard databases. Experimental results show that LPI provides better representation in the sense of semantic structure.\n",
      citations:
        ' ""10.1007/s11063-021-10478-x/,  ""10.1109/BIBM52615.2021.9669697/,  ""10.1109/INDICON47234.2019.9030348/,  ""10.1109/ACCESS.2019.2958489/,  ""10.1007/978-981-10-7512-4_88/,  ""10.1109/TTHZ.2018.2813085/,  ""10.4236/jcc.2017.53004/,  ""10.1007/s13735-016-0110-y/,  ""10.1007/978-3-319-50496-4_61/,  ""10.1109/ICKEA.2016.7802982/,  ""10.1109/BIGCOMP.2014.6741438/,  ""10.1007/978-3-319-01778-5_21/,  ""10.1007/978-3-319-01778-5_17/,  ""10.1007/978-3-319-12000-3_2/,  ""10.1109/ICDM.2013.99/,  ""10.1007/978-3-642-37456-2_11/,  ""10.4018/ijcvip.2013040102/,  ""10.1016/j.proeng.2012.01.134/,  ""10.1007/978-3-642-27308-7_66/,  ""10.1109/ICCSNT.2012.6525936/,  ""10.1109/ICHB.2011.6094327/,  ""10.1109/CISP.2009.5304042/,  ""10.1109/CISP.2009.5301056/,  ""10.1109/CISP.2009.5304135/,  ""10.1109/NLPKE.2008.4906771/,  ""10.1109/NLPKE.2008.4906785/,  ""10.1109/ICMLC.2008.4620838/,  ""10.1007/978-3-540-79721-0_86/,  ""10.1109/NLPKE.2007.4368016/,  ""10.1109/ALPIT.2007.88/,  ""10.1002/asi.20596/,  ""10.1109/ICHIT.2006.253479/,  ""10.1109/ICDM.2004.10004/',
      group:
        "SIGIR '04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2004  Pages   96–103https://doi.org/10.1145/1008992.1009012",
      year: "",
      authors: "Xiaofei He",
      doi: "10.1145/1008992.1009012",
    },
    {
      FIELD1: 94,
      id: "79B04EB3",
      name: "Relaxed online SVMs for spam filtering",
      url: "https://dl.acm.org/doi/abs/10.1145/1277741.1277813",
      abstract:
        "\nSpam is a key problem in electronic communication, including large-scale email systems and the growing number of blogs. Content-based filtering is one reliable method of combating this threat in its various forms, but some academic researchers and industrial practitioners disagree on how best to filter spam. The former have advocated the use of Support Vector Machines (SVMs) for content-based filtering, as this machine learning methodology gives state-of-the-art performance for text classification. However, similar performance gains have yet to be demonstrated for online spam filtering. Additionally, practitioners cite the high cost of SVMs as reason to prefer faster (if less statistically robust) Bayesian methods. In this paper, we offer a resolution to this controversy. First, we show that online SVMs indeed give state-of-the-art classification performance on online spam filtering on large benchmark data sets. Second, we show that nearly equivalent performance may be achieved by a Relaxed Online SVM (ROSVM) at greatly reduced computational cost. Our results are experimentally verified on email spam, blog spam, and splog detection tasks.\n",
      citations:
        ' ""10.1007/978-3-030-53970-2_4/,  ""10.1155/2021/2993877/,  ""10.1109/ICCICT50803.2021.9510066/,  ""10.1007/s12652-020-02087-8/,  ""10.1007/978-3-030-36962-0_4/,  ""10.1109/ASYU50717.2020.9259889/,  ""10.1109/ACCESS.2020.3041951/,  ""10.1109/ICDM50108.2020.00097/,  ""10.1109/ACCESS.2019.2925916/,  ""10.1186/s40163-019-0098-8/,  ""10.1016/j.procs.2018.10.239/,  ""10.1109/IJCNN.2018.8489246/,  ""10.1109/ICDSE.2018.8527737/,  ""10.1109/TNNLS.2018.2802721/,  ""10.1109/ICCMC.2017.8282698/,  ""10.1109/BIGCOM.2017.55/,  ""10.1109/ICAICT.2017.8687020/,  ""10.1109/FSKD.2016.7603347/,  ""10.1007/978-3-319-47880-7_5/,  ""10.1007/978-3-319-26450-9_12/,  ""10.1080/1206212X.2016.1218237/,  ""10.1109/ICDMW.2016.0148/,  ""10.1109/STARTUP.2016.7583948/,  ""10.1109/ICC.2015.7249515/,  ""10.1109/TIFS.2014.2368355/,  ""10.1007/978-3-319-20294-5_3/,  ""10.1109/MELCON.2014.6820574/,  ""10.1109/ICMLC.2014.7009106/,  ""10.1016/j.jnca.2014.03.010/,  ""10.1109/ICC.2014.6883388/,  ""10.1109/ICMLC.2014.7009101/,  ""10.1007/978-3-319-01854-6_46/,  ""10.1007/978-81-322-1602-5_81/,  ""10.1109/CCNC.2013.6488455/,  ""10.1109/NCA.2013.16/,  ""10.1007/978-3-642-36530-0_6/,  ""10.1007/978-94-007-6359-3_11/,  ""10.1007/978-3-642-41491-6_13/,  ""10.1007/s00521-012-1048-5/,  ""10.1080/18756891.2012.696915/,  ""10.1109/IFOST.2012.6357637/,  ""10.1007/978-3-642-25237-2_12/,  ""10.1007/978-3-642-35755-8_15/,  ""10.1007/s12065-012-0076-5/,  ""10.1109/ICASSP.2011.5946913/,  ""10.1007/978-3-642-24731-6_18/,  ""10.1109/ISIAS.2010.5604187/,  ""10.1109/ICMLC.2010.5580676/,  ""10.3745/KIPSTB.2010.17B.3.249/,  ""10.1109/ICNC.2010.5584334/,  ""10.1007/978-3-642-16720-1_23/,  ""10.1109/IALP.2010.65/,  ""10.1002/spe.925/,  ""10.1109/INDIN.2009.5195918/,  ""10.1109/CISDA.2009.5356547/,  ""10.1007/978-3-642-03348-3_31/,  ""10.1109/FSKD.2008.12/,  ""10.1007/s13042-018-00906-1/,  ""10.1007/s10462-020-09814-9/,  ""10.1002/int.22625/,  ""10.1287/deca.2020.0420/',
      group:
        "SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2007  Pages   415–422https://doi.org/10.1145/1277741.1277813",
      year: "",
      authors: "D. Sculley",
      doi: "10.1145/1277741.1277813",
    },
    {
      FIELD1: 95,
      id: "804B5947",
      name: "Bayesian extension to the language model for ad hoc information retrieval",
      url: "https://dl.acm.org/doi/abs/10.1145/860435.860439",
      abstract:
        "\nWe propose a Bayesian extension to the ad-hoc Language Model. Many smoothed estimators used for the multinomial query model in ad-hoc Language Models (including Laplace and Bayes-smoothing) are approximations to the Bayesian predictive distribution. In this paper we derive the full predictive distribution in a form amenable to implementation by classical IR models, and then compare it to other currently used estimators. In our experiments the proposed model outperforms Bayes-smoothing, and its combination with linear interpolation smoothing outperforms all other estimators.\n",
      citations:
        ' ""10.1007/978-3-031-14054-9_20/,  ""10.1007/978-1-4614-8265-9_936/,  ""10.1007/978-1-4899-7993-3_936-2/,  ""10.1007/978-1-4899-7993-3_936-3/,  ""10.2200/S00494ED1V01Y201304ICR027/,  ""10.1109/BMEI.2011.6098246/,  ""10.1007/978-3-642-17829-0_10/,  ""10.1007/978-3-642-17187-1_4/,  ""10.1007/978-0-387-39940-9_936/,  ""10.1007/0-387-25739-X_10/,  ""10.1109/IJCNN.2004.1381205/,  ""10.1007/978-3-540-30213-1_27/',
      group:
        "SIGIR '03: Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrievalJuly 2003  Pages   4–9https://doi.org/10.1145/860435.860439",
      year: "",
      authors: "Hugo Zaragoza",
      doi: "10.1145/860435.860439",
    },
    {
      FIELD1: 96,
      id: "7BBA4F8C",
      name: "Analysis of a low-dimensional linear model under recommendation attacks",
      url: "https://dl.acm.org/doi/abs/10.1145/1148170.1148259",
      abstract:
        "\nCollaborative filtering techniques have become popular in the past decade as an effective way to help people deal with information overload. Recent research has identified significant vulnerabilities in collaborative filtering techniques. Shilling attacks, in which attackers introduce biased ratings to influence recommendation systems, have been shown to be effective against memory-based collaborative filtering algorithms. We examine the effectiveness of two popular shilling attacks (the random attack and the average attack) on a model-based algorithm that uses Singular Value Decomposition (SVD) to learn a low-dimensional linear model. Our results show that the SVD-based algorithm is much more resistant to shilling attacks than memory-based algorithms. Furthermore, we develop an attack detection method directly built on the SVD-based algorithm and show that this method detects random shilling attacks with high detection rates and very low false alarm rates.\n",
      citations:
        ' ""10.1109/ACCESS.2019.2905862/,  ""10.1007/s40815-018-0508-1/,  ""10.1007/s11518-018-5374-8/,  ""10.1007/978-3-319-59162-9_38/,  ""10.1007/978-3-319-59288-6_34/,  ""10.1109/BigData.2017.8258235/,  ""10.1109/ICSSSM.2015.7170330/,  ""10.1007/978-1-4899-7637-6_7/,  ""10.1109/IJCNN.2014.6889419/,  ""10.1109/MLSP.2013.6661953/,  ""10.4018/japuc.2013040106/,  ""10.1287/ijoc.1100.0440/,  ""10.1109/ICSESS.2011.5982269/,  ""10.1007/978-0-387-85820-3_20/,  ""10.1007/978-0-387-85820-3_2/,  ""10.1109/ICMULT.2010.5630989/,  ""10.1287/mnsc.1100.1232/,  ""10.2139/ssrn.1483311/,  ""10.1007/978-3-642-02894-6_1/,  ""10.1007/s11761-007-0013-0/,  ""10.1371/journal.pone.0196533/,  ""10.1371/journal.pone.0130968/,  ""10.4028/www.scientific.net/AMR.645.247/,  ""10.1007/s10462-018-9655-x/',
      group:
        "SIGIR '06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2006  Pages   517–524https://doi.org/10.1145/1148170.1148259",
      year: "",
      authors: "Sheng Zhang",
      doi: "10.1145/1148170.1148259",
    },
    {
      FIELD1: 97,
      id: "7DBCD42C",
      name: "The use of unlabeled data to improve supervised learning for text summarization",
      url: "https://dl.acm.org/doi/abs/10.1145/564376.564397",
      abstract:
        "\nWith the huge amount of information available electronically, there is an increasing demand for automatic text summarization systems. The use of machine learning techniques for this task allows one to adapt summaries to the user needs and to the corpus characteristics. These desirable properties have motivated an increasing amount of work in this field over the last few years. Most approaches attempt to generate summaries by extracting sentence segments and adopt the supervised learning paradigm which requires to label documents at the text span level. This is a costly process, which puts strong limitations on the applicability of these methods. We investigate here the use of semi-supervised algorithms for summarization. These techniques make use of few labeled data together with a larger amount of unlabeled data. We propose new semi-supervised algorithms for training classification models for text summarization. We analyze their performances on two data sets - the Reuters news-wire corpus and the Computation and Language (cmp_lg) collection of TIPSTER SUMMAC. We perform comparisons with a baseline - non learning - system, and a reference trainable summarizer system.\n",
      citations:
        ' ""10.1080/1206212X.2020.1829844/,  ""10.1007/978-3-030-45442-5_32/,  ""10.5715/jnlp.27.825/,  ""10.1142/S0218001419400020/,  ""10.1007/978-3-319-75786-5_17/,  ""10.1007/978-3-319-63315-2_37/,  ""10.1109/FSKD.2016.7603271/,  ""10.1016/j.neucom.2014.07.046/,  ""10.1016/j.neucom.2015.01.020/,  ""10.1007/978-3-319-12637-1_11/,  ""10.1007/978-3-642-38824-8_14/,  ""10.1109/FSKD.2012.6234047/,  ""10.1007/978-3-642-23199-5_29/,  ""10.1007/978-3-642-14770-8_10/,  ""10.1007/978-3-642-14922-1_59/,  ""10.3743/KOSIM.2008.25.1.191/,  ""10.1007/978-3-540-78646-7_34/,  ""10.1007/s10791-006-9017-1/,  ""10.1109/ICCIS.2006.252361/,  ""10.1109/ISCIT.2006.340009/,  ""10.1007/s10115-005-0219-4/',
      group:
        "SIGIR '02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2002  Pages   105–112https://doi.org/10.1145/564376.564397",
      year: "",
      authors: "Massih-Reza Amini",
      doi: "10.1145/564376.564397",
    },
    {
      FIELD1: 98,
      id: "769E8B85",
      name: "Relevance and contributing information types of searched documents in task performance",
      url: "https://dl.acm.org/doi/abs/10.1145/345508.345512",
      abstract:
        "\nEnd-users base the relevance judgements of the searched documents on the expected contribution to their task of the information contained in the documents. There is a shortage of studies analyzing the relationships between the experienced contribution, relevance assessments and type of information initially sought. This study categorizes the types of information in documents being used in writing a research proposal for a master's thesis by eleven students throughout the various stages of the proposal writing process. The role of the specificity of the searched information in influencing its contribution is analyzed. The results demonstrate that different types of information are sought at different stages of the writing process and thus the contribution of the information also differs at the different stages. The categories of the contributing information can be understood of topicality.\n",
      citations:
        ' ""10.4018/978-1-5225-5191-1.ch099/,  ""10.1108/EL-04-2017-0077/,  ""10.4018/978-1-4666-9562-7.ch055/,  ""10.4018/978-1-4666-4353-6.ch004/,  ""10.4018/978-1-4666-6042-7.ch038/,  ""10.1002/asi.22839/,  ""10.1201/b11499-5/,  ""10.1007/978-1-4614-1415-5_24/,  ""10.1002/asi.21386/,  ""10.1108/00220410910952384/,  ""10.1108/00220410910983083/,  ""10.1108/00220410810912442/,  ""10.1109/IRI-05.2005.1506443/,  ""10.1108/00220410310506312/,  ""10.1108/00220410310485712/,  ""10.1177/01655515211060527/',
      group:
        "SIGIR '00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrievalJuly 2000  Pages   2–9https://doi.org/10.1145/345508.345512",
      year: "",
      authors: "Pertti Vakkari",
      doi: "10.1145/345508.345512",
    },
    {
      FIELD1: 99,
      id: "8040DD14",
      name: "Learning effective ranking functions for newsgroup search",
      url: "https://dl.acm.org/doi/abs/10.1145/1008992.1009060",
      abstract:
        "\nWeb communities are web virtual broadcasting spaces where people can freely discuss anything. While such communities function as discussion boards, they have even greater value as large repositories of archived information. In order to unlock the value of this resource, we need an effective means for searching archived discussion threads. Unfortunately the techniques that have proven successful for searching document collections and the Web are not ideally suited to the task of searching archived community discussions. In this paper, we explore the problem of creating an effective ranking function to predict the most relevant messages to queries in community search. We extract a set of predictive features from the thread trees of newsgroup messages as well as features of message authors and lexical distribution within a message thread. Our final results indicate that when using linear regression with this feature set, our search system achieved a 28.5% performance improvement compared to our baseline system.\n",
      citations:
        ' ""10.1063/1.5005400/,  ""10.1007/978-3-319-39958-4_24/,  ""10.1007/978-3-319-05912-9_5/,  ""10.1007/978-3-642-45068-6_25/,  ""10.1109/BASNA.2010.5730301/,  ""10.1109/IJCNN.2008.4634359/',
      group:
        "SIGIR '04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2004  Pages   394–401https://doi.org/10.1145/1008992.1009060",
      year: "",
      authors: "Wensi Xi",
      doi: "10.1145/1008992.1009060",
    },
    {
      FIELD1: 100,
      id: "5F0E68AD",
      name: "Hierarchical neural networks for text categorization",
      url: "https://dl.acm.org/doi/pdf/10.1145/312624.312700",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 101,
      id: "753B0371",
      name: "Temporal collaborative filtering with adaptive neighbourhoods",
      url: "https://dl.acm.org/doi/abs/10.1145/1571941.1572133",
      abstract:
        "\nCollaborative Filtering aims to predict user tastes, by minimising the mean error produced when predicting hidden user ratings. The aim of a deployed recommender system is to iteratively predict users' preferences over a dynamic, growing dataset, and system administrators are confronted with the problem of having to continuously tune the parameters calibrating their CF algorithm. In this work, we formalise CF as a time-dependent, iterative prediction problem. We then perform a temporal analysis of the Netflix dataset, and evaluate the temporal performance of two CF algorithms. We show that, due to the dynamic nature of the data, certain prediction methods that improve prediction accuracy on the Netflix probe set do not show similar improvements over a set of iterative train-test experiments with growing data. We then address the problem of parameter selection and update, and propose a method to automatically assign and update per-user neighbourhood sizes that (on the temporal scale) outperforms setting global parameters.\n",
      citations:
        ' ""10.1007/978-3-030-91699-2_22/,  ""10.1007/978-3-030-18289-2_3/,  ""10.1016/j.knosys.2020.105988/,  ""10.1109/ACCESS.2020.3035703/,  ""10.1007/978-3-319-77525-8_328/,  ""10.1007/978-3-030-15712-8_63/,  ""10.1109/ICIEA.2018.8397743/,  ""10.1007/978-3-319-90092-6_10/,  ""10.1109/TCSS.2017.2772295/,  ""10.1007/978-3-319-63962-8_328-1/,  ""10.1016/j.elerap.2018.01.012/,  ""10.1002/cpe.4098/,  ""10.1109/ICSESS.2018.8663914/,  ""10.1109/ICDE.2017.126/,  ""10.1109/ICDIM.2017.8244679/,  ""10.1007/978-981-10-5373-3_2/,  ""10.1007/978-3-319-45817-5_14/,  ""10.1007/978-3-319-29659-3_9/,  ""10.1007/978-3-319-14178-7_6/,  ""10.1109/TMM.2015.2410135/,  ""10.1002/cpe.3370/,  ""10.1007/s13278-014-0164-x/,  ""10.1016/j.swevo.2013.08.003/,  ""10.1007/978-3-642-40643-0_3/,  ""10.1109/ICASSP.2012.6288274/,  ""10.1007/978-3-642-19896-0_6/,  ""10.1371/journal.pone.0135090/,  ""10.4028/www.scientific.net/AMM.651-653.1695/,  ""10.1007/s11257-021-09306-7/',
      group:
        "SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrievalJuly 2009  Pages   796–797https://doi.org/10.1145/1571941.1572133",
      year: "",
      authors: "Neal Lathia",
      doi: "10.1145/1571941.1572133",
    },
    {
      FIELD1: 102,
      id: "7DC10A63",
      name: "SpotSigs: robust and efficient near duplicate detection in large web collections",
      url: "https://dl.acm.org/doi/abs/10.1145/1390334.1390431",
      abstract:
        '\nMotivated by our work with political scientists who need to manually analyze large Web archives of news sites, we present SpotSigs, a new algorithm for extracting and matching signatures for near duplicate detection in large Web crawls. Our spot signatures are designed to favor natural-language portions of Web pages over advertisements and navigational bars. The contributions of SpotSigs are twofold: 1) by combining stopword antecedents with short chains of adjacent content terms, we create robust document signatures with a natural ability to filter out noisy components of Web pages that would otherwise distract pure n-gram-based approaches such as Shingling; 2) we provide an exact and efficient, self-tuning matching algorithm that exploits a novel combination of collection partitioning and inverted index pruning for high-dimensional similarity search. Experiments confirm an increase in combined precision and recall of more than 24 percent over state-of-the-art approaches such as Shingling or I-Match and up to a factor of 3 faster execution times than Locality Sensitive Hashing (LSH), over a demonstrative "Gold Set" of manually assessed near-duplicate news articles as well as the TREC WT10g Web collection.\n',
      citations:
        ' ""10.1177/00027642211021650/,  ""10.1007/978-3-031-08751-6_41/,  ""10.1038/s41467-021-22910-w/,  ""10.1007/978-3-030-53337-3_21/,  ""10.3233/JIFS-179015/,  ""10.1109/ICDE.2019.00078/,  ""10.1007/978-3-030-37078-7_21/,  ""10.1109/ACCESS.2019.2939872/,  ""10.1109/BigData47090.2019.9006324/,  ""10.1109/APSEC48747.2019.00074/,  ""10.1007/978-3-319-99004-0_3/,  ""10.2478/icame-2019-0004/,  ""10.1007/978-3-030-01132-1_22/,  ""10.1109/ICIRCA.2018.8597326/,  ""10.1007/s13042-017-0657-9/,  ""10.1109/SANER.2018.8330262/,  ""10.1109/ICDMW.2017.29/,  ""10.1109/ICNSC.2017.8000087/,  ""10.1007/978-3-319-48057-2_4/,  ""10.1109/STARTUP.2016.7583952/,  ""10.1109/AINA.2016.37/,  ""10.1007/978-3-319-21042-1_30/,  ""10.1007/978-3-319-28940-3_40/,  ""10.1007/978-3-319-22852-5_17/,  ""10.1109/GET.2015.7453837/,  ""10.1109/CoCoNet.2015.7411276/,  ""10.4236/jdaip.2015.34012/,  ""10.2200/S00662ED1V01Y201508ICR045/,  ""10.1109/ICCSP.2015.7322567/,  ""10.1109/RIVF.2015.7049886/,  ""10.1007/978-3-319-07353-8_23/,  ""10.1007/978-3-319-10085-2_22/,  ""10.1201/b16812-58/,  ""10.1287/isre.2014.0533/,  ""10.1007/978-3-642-41230-1_24/,  ""10.1007/978-3-642-45068-6_18/,  ""10.1007/s13218-012-0224-1/,  ""10.1007/978-3-642-32498-7_16/,  ""10.1109/SCET.2012.6342140/,  ""10.4018/978-1-60960-881-1.ch004/,  ""10.1007/978-3-642-20841-6_44/,  ""10.1007/978-1-4471-2236-4_16/,  ""10.1007/978-3-642-16339-5_20/,  ""10.1007/s12652-020-01750-4/,  ""10.1007/s10115-018-1299-2/,  ""10.4028/www.scientific.net/AMM.263-266.1341/,  ""10.4028/www.scientific.net/AMM.241-244.3159/',
      group:
        "SIGIR '08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrievalJuly 2008  Pages   563–570https://doi.org/10.1145/1390334.1390431",
      year: "",
      authors: "Martin Theobald",
      doi: "10.1145/1390334.1390431",
    },
    {
      FIELD1: 103,
      id: "7CFA0F26",
      name: "Effective missing data prediction for collaborative filtering",
      url: "https://dl.acm.org/doi/abs/10.1145/1277741.1277751",
      abstract:
        "\nMemory-based collaborative filtering algorithms have been widely adopted in many popular recommender systems, although these approaches all suffer from data sparsity and poor prediction quality problems. Usually, the user-item matrix is quite sparse, which directly leads to inaccurate recommendations. This paper focuses the memory-based collaborative filtering problems on two crucial factors: (1) similarity computation between users or items and (2) missing data prediction algorithms. First, we use the enhanced Pearson Correlation Coefficient (PCC) algorithm by adding one parameter which overcomes the potential decrease of accuracy when computing the similarity of users or items. Second, we propose an effective missing data prediction algorithm, in which information of both users and items is taken into account. In this algorithm, we set the similarity threshold for users and items respectively, and the prediction algorithm will determine whether predicting the missing data or not. We also address how to predict the missing data by employing a combination of user and item information. Finally, empirical studies on dataset MovieLens have shown that our newly proposed method outperforms other state-of-the-art collaborative filtering algorithms and it is more robust against data sparsity.\n",
      citations:
        ' ""10.1109/TPDS.2021.3111810/,  ""10.3233/AAC-200544/,  ""10.1109/I2CT54291.2022.9824545/,  ""10.2298/CSIS210518054M/,  ""10.1007/978-981-19-3444-5_38/,  ""10.1109/ICDE53745.2022.00027/,  ""10.1109/TSC.2020.2995571/,  ""10.1109/TSMC.2019.2931723/,  ""10.1016/j.neucom.2021.08.110/,  ""10.1109/ICCAIS52680.2021.9624507/,  ""10.1109/ICCITM53167.2021.9677842/,  ""10.1109/JIOT.2020.2987979/,  ""10.1007/978-3-030-45442-5_34/,  ""10.1007/978-981-15-4569-6_3/,  ""10.1007/978-981-15-3357-0_7/,  ""10.1109/Confluence47617.2020.9058016/,  ""10.1007/978-981-15-1480-7_45/,  ""10.1002/9781119501121.ch9/,  ""10.1109/ACCESS.2020.3002544/,  ""10.1109/ACCESS.2020.3005953/,  ""10.1109/ACCESS.2020.3008514/,  ""10.1109/MIPR49039.2020.00041/,  ""10.1109/ELECOM49001.2020.9297009/,  ""10.1109/CISS48834.2020.1570617370/,  ""10.1109/DSAA49011.2020.00075/,  ""10.1109/DICTA51227.2020.9363400/,  ""10.1109/ISCID51228.2020.00032/,  ""10.1109/ACCESS.2019.2937508/,  ""10.1109/SSCI44817.2019.9002724/,  ""10.1109/PERCOM.2019.8767397/,  ""10.1109/ITNEC.2019.8729461/,  ""10.1007/978-981-13-8260-4_33/,  ""10.1007/978-3-030-34365-1_14/,  ""10.1016/j.asoc.2019.105762/,  ""10.1109/TKDE.2017.2698461/,  ""10.1007/978-3-030-00828-4_25/,  ""10.1186/s12918-018-0638-y/,  ""10.1007/978-1-4939-7131-2_189/,  ""10.4018/978-1-5225-5396-0.ch018/,  ""10.1016/j.cl.2018.01.003/,  ""10.1007/s11390-018-1849-9/,  ""10.1109/TCSS.2018.2879044/,  ""10.1109/ITME.2018.00168/,  ""10.1109/PERCOM.2018.8444598/,  ""10.1109/TSC.2016.2589244/,  ""10.1109/TBDATA.2017.2719703/,  ""10.1109/ICNISC.2017.00048/,  ""10.1109/SPAC.2017.8304282/,  ""10.1109/ICCCBDA.2017.7951925/,  ""10.1007/978-1-4614-7163-9_189-1/,  ""10.1109/TSC.2015.2479228/,  ""10.1109/ICGI.2017.39/,  ""10.1007/978-3-319-70004-5_30/,  ""10.1109/ACCESS.2017.2778424/,  ""10.23919/PICMET.2017.8125452/,  ""10.23919/CNSM.2017.8255983/,  ""10.1007/978-3-319-68542-7_65/,  ""10.1109/SCC.2016.52/,  ""10.1109/ICWS.2016.12/,  ""10.1201/9781315374017-8/,  ""10.1109/ACCESS.2016.2633282/,  ""10.1109/SNPD.2016.7515958/,  ""10.1109/ICWS.2016.86/,  ""10.1109/ICBDA.2016.7509842/,  ""10.1007/978-981-10-1536-6_7/,  ""10.1109/SMC.2016.7844813/,  ""10.1007/978-3-319-29659-3_2/,  ""10.1007/978-981-10-2663-8_46/,  ""10.1587/transinf.2014EDP7174/,  ""10.1007/978-1-4899-7637-6_2/,  ""10.1109/ICCSNT.2015.7490744/,  ""10.1007/978-3-319-27119-4_26/,  ""10.1007/s11390-015-1570-x/,  ""10.1007/978-3-319-25255-1_11/,  ""10.1109/TWC.2015.2424965/,  ""10.1109/TSC.2014.2346492/,  ""10.1109/ACCESS.2015.2498191/,  ""10.1002/tee.22120/,  ""10.1007/s13278-014-0153-0/,  ""10.1109/CIDM.2014.7008679/,  ""10.1109/ICWS.2014.47/,  ""10.1109/IJCNN.2014.6889418/,  ""10.1109/TSC.2013.3/,  ""10.1109/ICCCT2.2014.7066693/,  ""10.1109/TETC.2013.2283233/,  ""10.1109/INFOCOM.2014.6848135/,  ""10.1109/JBHI.2013.2288803/,  ""10.1109/CBD.2014.47/,  ""10.1007/978-3-319-08786-3_13/,  ""10.1007/978-1-4614-7518-7_22/,  ""10.4018/ijrsda.2014010104/,  ""10.1007/s13278-012-0083-7/,  ""10.1007/978-3-642-34207-3_5/,  ""10.1109/BMEI.2013.6747022/,  ""10.1109/ICIInfS.2013.6732035/,  ""10.1109/TSMCB.2012.2231411/,  ""10.1016/j.swevo.2013.07.001/,  ""10.1007/s13278-013-0103-2/,  ""10.1007/978-3-642-36907-0_10/,  ""10.1007/978-3-642-34207-3_2/,  ""10.4018/jwsr.2013010103/,  ""10.1007/978-3-642-25456-7_9/,  ""10.1109/Allerton.2012.6483287/,  ""10.1109/ICSSEM.2012.6340786/,  ""10.1109/ISTEL.2012.6483164/,  ""10.1007/s11390-012-1301-5/,  ""10.1007/978-0-387-85820-3_4/,  ""10.1007/978-3-642-22688-5_31/,  ""10.1109/EMEIT.2011.6023888/,  ""10.1109/GRC.2011.6122607/,  ""10.1109/ICSESS.2011.5982269/,  ""10.1007/978-90-481-9794-1_22/,  ""10.1007/978-3-642-12101-2_1/,  ""10.20965/jaciii.2010.p0654/,  ""10.1109/FSKD.2010.5569294/,  ""10.1109/IJCNN.2009.5178967/,  ""10.1109/ICCSIT.2009.5234936/,  ""10.1007/978-3-540-92814-0_12/,  ""10.1109/IEEM.2008.4738117/,  ""10.4304/jcp.8.1.186-193/,  ""10.1371/journal.pone.0181380/,  ""10.4028/www.scientific.net/AMR.339.396/,  ""10.31590/ejosat.822968/,  ""10.1007/s11227-017-2196-2/,  ""10.1007/s00500-019-04143-8/,  ""10.1371/journal.pone.0242089/,  ""10.48084/etasr.3821/,  ""10.31590/ejosat.779171/,  ""10.35377/saucis.03.02.714969/,  ""10.1080/08839514.2020.1775011/,  ""10.1007/s10489-020-01811-3/,  ""10.35377/saucis...953348/,  ""10.21541/apjess.1060744/,  ""10.1177/01466216221124089/',
      group:
        "SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2007  Pages   39–46https://doi.org/10.1145/1277741.1277751",
      year: "",
      authors: "Hao Ma",
      doi: "10.1145/1277741.1277751",
    },
    {
      FIELD1: 104,
      id: "7993E3BE",
      name: "Automatic image annotation by using concept-sensitive salient objects for image content representation",
      url: "https://dl.acm.org/doi/abs/10.1145/1008992.1009055",
      abstract:
        "\nMulti-level annotation of images is a promising solution to enable more effective semantic image retrieval by using various keywords at different semantic levels. In this paper, we propose a multi-level approach to annotate the semantics of natural scenes by using both the dominant image components and the relevant semantic concepts. In contrast to the well-known image-based and region-based approaches, we use the salient objects as the dominant image components to achieve automatic image annotation at the content level. By using the salient objects for image content representation, a novel image classification technique is developed to achieve automatic image annotation at the concept level. To detect the salient objects automatically, a set of detection functions are learned from the labeled image regions by using Support Vector Machine (SVM) classifiers with an automatic scheme for searching the optimal model parameters. To generate the semantic concepts, finite mixture models are used to approximate the class distributions of the relevant salient objects. An adaptive EM algorithm has been proposed to determine the optimal model structure and model parameters simultaneously. We have also demonstrated that our algorithms are very effective to enable multi-level annotation of natural scenes in a large-scale dataset.\n",
      citations:
        ' ""10.46300/9106.2022.16.23/,  ""10.1109/CVPR.2018.00785/,  ""10.1109/DICTA.2017.8227422/,  ""10.1109/IKT.2015.7288777/,  ""10.1007/s00521-012-1237-2/,  ""10.1007/978-1-4614-1909-9_5/,  ""10.1007/978-3-642-18449-9_8/,  ""10.1109/ICPR.2008.4761476/,  ""10.1002/ima.20149/,  ""10.1108/07378830810880351/,  ""10.1109/NAFIPS.2007.383844/,  ""10.1109/CBMI.2007.385419/,  ""10.20965/jaciii.2007.p0633/,  ""10.1007/978-3-540-38233-1_5/,  ""10.1007/978-3-540-73417-8_25/,  ""10.1109/VAST.2006.261425/,  ""10.1109/ISSPA.2005.1580235/,  ""10.1007/s11042-020-08862-1/',
      group:
        "SIGIR '04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2004  Pages   361–368https://doi.org/10.1145/1008992.1009055",
      year: "",
      authors: "Jianping Fan",
      doi: "10.1145/1008992.1009055",
    },
    {
      FIELD1: 105,
      id: "7C523A12",
      name: "Results of applying probabilistic IR to OCR text",
      url: "https://link.springer.com/chapter/10.1007/978-1-4471-2099-5_21",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 106,
      id: "7AB99336",
      name: "A comparison of classifiers and document representations for the routing problem",
      url: "https://dl.acm.org/doi/pdf/10.1145/215206.215365",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 107,
      id: "7A27208B",
      name: "Improving text retrieval for the routing problem using latent semantic indexing",
      url: "https://link.springer.com/chapter/10.1007/978-1-4471-2099-5_29",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 108,
      id: "7889A2C5",
      name: "Orthogonal locality preserving indexing",
      url: "https://dl.acm.org/doi/abs/10.1145/1076034.1076039",
      abstract:
        "\nWe consider the problem of document indexing and representation. Recently, Locality Preserving Indexing (LPI) was proposed for learning a compact document subspace. Different from Latent Semantic Indexing which is optimal in the sense of global Euclidean structure, LPI is optimal in the sense of local manifold structure. However, LPI is extremely sensitive to the number of dimensions. This makes it difficult to estimate the intrinsic dimensionality, while inaccurately estimated dimensionality would drastically degrade its performance. One reason leading to this problem is that LPI is non-orthogonal. Non-orthogonality distorts the metric structure of the document space. In this paper, we propose a new algorithm called Orthogonal LPI. Orthogonal LPI iteratively computes the mutually orthogonal basis functions which respect the local geometrical structure. Moreover, our empirical study shows that OLPI can have more locality preserving power than LPI. We compare the new algorithm to LSI and LPI. Extensive experimental results show that Orthogonal LPI obtains better performance than both LSI and LPI. More crucially, it is insensitive to the number of dimensions, which makes it an efficient data preprocessing method for text clustering, classification, retrieval, etc.\n",
      citations:
        ' ""10.1109/TNNLS.2020.3027852/,  ""10.1016/j.eswa.2022.116650/,  ""10.1109/TBDATA.2020.3014937/,  ""10.1109/ICASSP43922.2022.9746167/,  ""10.1017/ATSIP.2020.27/,  ""10.1038/s41598-021-96265-z/,  ""10.2139/ssrn.3735819/,  ""10.1109/ICMCCE51767.2020.00440/,  ""10.1109/TPAMI.2020.3012541/,  ""10.1016/j.neunet.2018.10.001/,  ""10.1109/INDICON47234.2019.9030348/,  ""10.1109/SAFEPROCESS45799.2019.9213321/,  ""10.1109/TCYB.2018.2799862/,  ""10.1109/BICTA.2009.5338132/,  ""10.1016/B978-1-59749-272-0.50008-6/,  ""10.1109/NLPKE.2008.4906771/,  ""10.1109/CCPR.2008.48/,  ""10.1109/HSI.2008.4581521/,  ""10.1007/s00521-019-04317-3/',
      group:
        "SIGIR '05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2005  Pages   3–10https://doi.org/10.1145/1076034.1076039",
      year: "",
      authors: "Deng Cai",
      doi: "10.1145/1076034.1076039",
    },
    {
      FIELD1: 109,
      id: "770D962D",
      name: "ICA and SOM in text document analysis",
      url: "https://dl.acm.org/doi/abs/10.1145/564376.564444",
      abstract:
        "\nIn this study we show experimental results on using Independent Component Analysis (ICA) and the Self-Organizing Map (SOM) in document analysis. Our documents are segments of spoken dialogues carried out over the telephone in a customer service, transcribed into text. The task is to analyze the topics of the discussions, and to group the discussions into meaningful subsets. The quality of the grouping is studied by comparing to a manual topical classification of the documents.\n",
      citations:
        ' ""10.1007/978-3-642-14589-6_13/,  ""10.1017/S1351324910000057/,  ""10.3745/JIPS.2007.3.1.033/,  ""10.1109/ICIAS.2007.4658363/,  ""10.1016/j.neucom.2006.07.007/,  ""10.1007/978-3-540-30499-9_160/,  ""10.1109/IJCNN.2004.1379914/',
      group:
        "SIGIR '02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2002  Pages   361–362https://doi.org/10.1145/564376.564444",
      year: "",
      authors: "Ella Bingham",
      doi: "10.1145/564376.564444",
    },
    {
      FIELD1: 110,
      id: "78CE47C4",
      name: "A user browsing model to predict search engine click data from past observations.",
      url: "https://dl.acm.org/doi/abs/10.1145/1390334.1390392",
      abstract:
        "\nSearch engine click logs provide an invaluable source of relevance information but this information is biased because we ignore which documents from the result list the users have actually seen before and after they clicked. Otherwise, we could estimate document relevance by simple counting. In this paper, we propose a set of assumptions on user browsing behavior that allows the estimation of the probability that a document is seen, thereby providing an unbiased estimate of document relevance. To train, test and compare our model to the best alternatives described in the Literature, we gather a large set of real data and proceed to an extensive cross-validation experiment. Our solution outperforms very significantly all previous models. As a side effect, we gain insight into the browsing behavior of users and we can compare it to the conclusions of an eye-tracking experiments by Joachims et al. [12]. In particular, our findings confirm that a user almost always see the document directly after a clicked document. They also explain why documents situated just after a very relevant document are clicked more often.\n",
      citations:
        ' ""10.7232/JKIIE.2022.48.2.138/,  ""10.1002/9781119815075.ch27/,  ""10.1007/s11390-022-2031-y/,  ""10.1007/978-3-031-14627-5_1/,  ""10.1007/978-3-030-90428-9_1/,  ""10.4018/978-1-7998-0961-6.ch001/,  ""10.1007/978-3-030-60290-1_4/,  ""10.1109/ICSC.2020.00022/,  ""10.1145/3394486.3403343/,  ""10.1007/978-3-030-32686-9_4/,  ""10.1109/LCN44214.2019.8990880/,  ""10.1109/ICSPIS48872.2019.9066071/,  ""10.1109/EuroSPW.2019.00055/,  ""10.1109/ICDE.2019.00206/,  ""10.2478/dim-2019-0010/,  ""10.1109/BigData47090.2019.9006033/,  ""10.1109/BigData47090.2019.9006172/,  ""10.1007/978-3-319-90092-6_7/,  ""10.1109/ACCESS.2018.2868998/,  ""10.1109/BigData.2017.8258078/,  ""10.1007/978-3-319-56608-5_8/,  ""10.1007/978-3-319-68155-9_16/,  ""10.1109/TSC.2017.2777487/,  ""10.1007/978-3-319-41718-9_3/,  ""10.1200/JOP.2015.010504/,  ""10.2139/ssrn.2668265/,  ""10.1007/978-3-319-07353-8_9/,  ""10.1136/amiajnl-2012-001473/,  ""10.1007/978-3-319-06028-6_67/,  ""10.2139/ssrn.2510114/,  ""10.1007/978-3-319-08245-5_16/,  ""10.1109/JCDL.2014.6970157/,  ""10.1109/TIP.2014.2346991/,  ""10.1111/j.1475-5661.2012.00539.x/,  ""10.1007/978-3-642-45068-6_33/,  ""10.1007/978-3-642-45068-6_1/,  ""10.1109/ICDM.2013.20/,  ""10.4018/ijcini.2013040104/,  ""10.1109/CCIS.2012.6664361/,  ""10.1007/978-3-642-22913-8_14/,  ""10.1109/PACRIM.2011.6033004/,  ""10.1007/978-3-642-17749-1_26/,  ""10.1007/978-3-642-16321-0_22/,  ""10.2139/ssrn.1417625/,  ""10.2196/jmir.2664/,  ""10.4028/www.scientific.net/AMR.756-759.1035/',
      group:
        "SIGIR '08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrievalJuly 2008  Pages   331–338https://doi.org/10.1145/1390334.1390392",
      year: "",
      authors: "Georges E. Dupret",
      doi: "10.1145/1390334.1390392",
    },
    {
      FIELD1: 111,
      id: "7B337E8B",
      name: "The decomposition of human-written summary sentences",
      url: "https://dl.acm.org/doi/pdf/10.1145/312624.312666",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 112,
      id: "7FDB9438",
      name: "A browser for bibliographic information retrieval, based on an application of lattice theory",
      url: "https://dl.acm.org/doi/pdf/10.1145/160688.160737",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 113,
      id: "7C02181E",
      name: "Efficient bayesian hierarchical user modeling for recommendation system",
      url: "https://dl.acm.org/doi/abs/10.1145/1277741.1277752",
      abstract:
        "\nA content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual user's interest. A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model. Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive. The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications. This paper proposes a new fast learning technique to learn a large number of individual user profiles. The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens.\n",
      citations:
        ' ""10.1007/s10115-021-01628-7/,  ""10.1109/ICPR48806.2021.9412376/,  ""10.1109/ICCMC48092.2020.ICCMC-00022/,  ""10.1007/978-3-030-22871-2_44/,  ""10.1007/978-981-10-3187-8_5/,  ""10.1007/978-1-4939-7131-2_189/,  ""10.1109/ICASID.2018.8693109/,  ""10.1109/ACCESS.2017.2787741/,  ""10.1109/SMAP.2018.8501880/,  ""10.1109/ICBK.2017.30/,  ""10.1007/978-1-4614-7163-9_189-1/,  ""10.1007/978-3-319-54472-4_26/,  ""10.1109/TETC.2017.2686487/,  ""10.1007/978-3-319-48051-0_14/,  ""10.1186/s13638-016-0710-5/,  ""10.1201/9781315374017-8/,  ""10.1007/s11390-015-1570-x/,  ""10.1109/THMS.2014.2363467/,  ""10.1109/TKDE.2015.2405556/,  ""10.1109/TBC.2014.2378494/,  ""10.1109/CLEI.2015.7359992/,  ""10.1007/978-3-319-25255-1_41/,  ""10.1007/978-3-319-19135-5_2/,  ""10.1007/978-1-4899-7637-6_7/,  ""10.1109/MMSP.2014.6958801/,  ""10.1109/ICICES.2014.7033867/,  ""10.1109/ICIS.2014.6912121/,  ""10.1109/ISDA.2014.7066284/,  ""10.1007/s11277-013-1468-2/,  ""10.1109/ICDMW.2014.60/,  ""10.1007/978-3-319-11116-2_53/,  ""10.1002/9781118718124.ch10/,  ""10.1109/ICMSE.2013.6586258/,  ""10.1109/ICMSE.2013.6586259/,  ""10.1186/1687-1499-2012-22/,  ""10.4018/978-1-4666-1598-4.ch009/,  ""10.1214/11-STS368/,  ""10.4018/ijom.2012010105/,  ""10.1109/CIDM.2011.5949455/,  ""10.1109/ICDKE.2011.6053931/,  ""10.4018/978-1-60960-487-5.ch018/,  ""10.1109/FSKD.2011.6019912/,  ""10.1007/978-0-387-85820-3_2/,  ""10.1007/978-3-642-23935-9_58/,  ""10.1016/j.neucom.2010.07.034/,  ""10.1109/FSKD.2010.5569602/,  ""10.1016/j.procs.2010.08.015/,  ""10.1007/978-3-642-03348-3_37/,  ""10.1371/journal.pone.0165868/,  ""10.1007/s00500-019-03861-3/,  ""10.1007/s00163-019-00314-8/,  ""10.1002/cpe.4418/,  ""10.1093/biomet/asz053/,  ""10.1007/s10618-022-00849-w/',
      group:
        "SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2007  Pages   47–54https://doi.org/10.1145/1277741.1277752",
      year: "",
      authors: "Yi Zhang",
      doi: "10.1145/1277741.1277752",
    },
    {
      FIELD1: 114,
      id: "798E5678",
      name: "A probabilistic graphical model for joint answer ranking in question answering",
      url: "https://dl.acm.org/doi/abs/10.1145/1277741.1277801",
      abstract:
        "\nGraphical models have been applied to various information retrieval and natural language processing tasks in the recent literature. In this paper, we apply a probabilistic graphical model for answer ranking in question answering. This model estimates the joint probability of correctness of all answer candidates, from which the probability of correctness of an individual candidate can be inferred. The joint prediction model can estimate both the correctness of individual answers as well as their correlations, which enables a list of accurate and comprehensive answers. This model was compared with a logistic regression model which directly estimates the probability of correctness of each individual answer candidate. An extensive set of empirical results based on TREC questions demonstrates the effectiveness of the joint model for answer ranking. Furthermore, we combine the joint model with the logistic regression model to improve the efficiency and accuracy of answer ranking.\n",
      citations:
        ' ""10.1007/978-3-030-42835-8_3/,  ""10.1016/j.future.2020.02.042/,  ""10.1109/TNNLS.2019.2945133/,  ""10.1109/TIT.2019.2932255/,  ""10.1109/SKG.2018.00040/,  ""10.1007/978-3-030-01298-4_24/,  ""10.1007/978-3-319-76941-7_62/,  ""10.1007/978-3-319-69179-4_46/,  ""10.1109/UBMK.2017.8093464/,  ""10.1007/s13278-011-0046-4/,  ""10.1007/978-3-642-22418-8_45/,  ""10.1007/978-3-642-21822-4_25/,  ""10.1007/978-3-642-14246-8_43/,  ""10.1109/FSKD.2010.5569521/,  ""10.1007/s11760-019-01465-w/',
      group:
        "SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2007  Pages   343–350https://doi.org/10.1145/1277741.1277801",
      year: "",
      authors: "Jeongwoo Ko",
      doi: "10.1145/1277741.1277801",
    },
    {
      FIELD1: 115,
      id: "7FF02B6C",
      name: "Extracting structured information from user queries with semi-supervised conditional random fields",
      url: "https://dl.acm.org/doi/abs/10.1145/1571941.1572039",
      abstract:
        "\nWhen search is against structured documents, it is beneficial to extract information from user queries in a format that is consistent with the backend data structure. As one step toward this goal, we study the problem of query tagging which is to assign each query term to a pre-defined category. Our problem could be approached by learning a conditional random field (CRF) model (or other statistical models) in a supervised fashion, but this would require substantial human-annotation effort. In this work, we focus on a semi-supervised learning method for CRFs that utilizes two data sources: (1) a small amount of manually-labeled queries, and (2) a large amount of queries in which some word tokens have derived labels, i.e., label information automatically obtained from additional resources. We present two principled ways of encoding derived label information in a CRF model. Such information is viewed as hard evidence in one setting and as soft evidence in the other. In addition to the general methodology of how to use derived labels in semi-supervised CRFs, we also present a practical method on how to obtain them by leveraging user click data and an in-domain database that contains structured documents. Evaluation on product search queries shows the effectiveness of our approach in improving tagging accuracies.\n",
      citations:
        ' ""10.1007/978-3-030-99739-7_5/,  ""10.1007/978-3-030-45439-5_43/,  ""10.1186/s12911-019-0865-1/,  ""10.1007/978-3-319-93935-3_7/,  ""10.1007/s13042-017-0657-9/,  ""10.1109/TIP.2018.2830189/,  ""10.1007/978-3-662-49521-6_4/,  ""10.1007/978-3-319-07881-6_39/,  ""10.2200/S00566ED1V01Y201401ICR033/,  ""10.1007/978-3-319-02597-1_7/,  ""10.1007/978-3-642-35734-3_15/,  ""10.1136/amiajnl-2012-000812/,  ""10.1109/ASRU.2011.6163968/,  ""10.1109/ICASSP.2011.5947630/,  ""10.1109/JSTSP.2010.2075990/,  ""10.1371/journal.pone.0108396/,  ""10.18178/ijmlc.2015.5.6.548/',
      group:
        "SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrievalJuly 2009  Pages   572–579https://doi.org/10.1145/1571941.1572039",
      year: "",
      authors: "Xiao Li",
      doi: "10.1145/1571941.1572039",
    },
    {
      FIELD1: 116,
      id: "7A074A4D",
      name: "Analyzing feature trajectories for event detection",
      url: "https://dl.acm.org/doi/abs/10.1145/1277741.1277779",
      abstract:
        "\nWe consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words. A set of words with identical trends can be grouped together to reconstruct an event in a completely un-supervised manner. The document frequency of each word across time is treated like a time series, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point. In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each feature's burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events. All of the above methods can be applied to time series data in general. We extensively evaluated our methods on the 1-year Reuters News Corpus [3] and showed that they were able to uncover meaningful aperiodic and periodic events.\n",
      citations:
        ' ""10.1007/978-981-15-8983-6_42/,  ""10.1007/978-981-16-0100-2_9/,  ""10.1007/978-3-030-36687-2_55/,  ""10.1109/ACCESS.2020.2964714/,  ""10.1007/978-3-030-50146-4_30/,  ""10.1214/20-AOAS1344/,  ""10.1109/COMSNETS48256.2020.9027299/,  ""10.1007/978-3-030-11680-4_5/,  ""10.2200/S00903ED1V01Y201902DMK017/,  ""10.1109/JEEIT.2019.8717425/,  ""10.1109/MCI.2019.2919395/,  ""10.1007/978-3-319-93940-7_18/,  ""10.1109/DSC.2019.00068/,  ""10.1109/TKDE.2019.2931340/,  ""10.1007/978-3-319-66414-9_2/,  ""10.1007/s11042-017-5531-y/,  ""10.1007/978-3-319-76941-7_70/,  ""10.1016/j.procs.2018.10.415/,  ""10.1109/ICSCSE.2018.00157/,  ""10.1109/ASONAM.2018.8508618/,  ""10.1109/TCYB.2017.2762344/,  ""10.1007/978-3-319-56608-5_38/,  ""10.1007/978-3-319-59569-6_11/,  ""10.1007/978-3-319-39958-4_12/,  ""10.1109/IJCNN.2016.7727381/,  ""10.1007/978-3-319-39958-4_24/,  ""10.1109/MIPRO.2016.7522146/,  ""10.1007/s13278-016-0414-1/,  ""10.1007/978-3-319-45817-5_32/,  ""10.1109/BigData.2016.7840602/,  ""10.1007/978-3-319-46922-5_20/,  ""10.1109/IST.2016.7738257/,  ""10.1007/978-3-319-45814-4_27/,  ""10.1109/TCYB.2015.2489841/,  ""10.1109/THMS.2015.2489681/,  ""10.1002ra2.2016.14505301047/,  ""10.1109/TMM.2015.2425143/,  ""10.1109/TITS.2014.2371815/,  ""10.1007/978-3-319-16354-3_25/,  ""10.1007/978-3-319-10422-5_24/,  ""10.1007/978-3-319-23461-8_29/,  ""10.1016/j.neucom.2014.08.045/,  ""10.1109/ICCCS.2014.7068182/,  ""10.1007/978-3-319-11289-3_14/,  ""10.1007/978-3-319-11746-1_7/,  ""10.1007/s13735-014-0056-x/,  ""10.1109/IJCNN.2013.6707027/,  ""10.1007/978-3-642-41154-0_24/,  ""10.1007/s11390-013-1377-6/,  ""10.1109/WI-IAT.2012.251/,  ""10.1007/978-3-642-25646-2_53/,  ""10.1007/978-3-642-25646-2_52/,  ""10.1007/978-3-642-32115-3_26/,  ""10.1007/978-3-642-35341-3_46/,  ""10.1007/978-3-642-24583-1_10/,  ""10.1007/978-3-642-20539-2_24/,  ""10.1109/TCSVT.2011.2148470/,  ""10.1007/978-3-642-24704-0_17/,  ""10.1109/PIC.2010.5687459/,  ""10.1109/FSKD.2010.5569864/,  ""10.1007/978-3-642-14246-8_41/,  ""10.1631/jzus.C0910245/,  ""10.4028/www.scientific.net/KEM.467-469.129/,  ""10.1007/s11227-021-03717-4/,  ""10.1080/0952813X.2020.1785019/,  ""10.1007/s00799-021-00308-9/',
      group:
        "SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2007  Pages   207–214https://doi.org/10.1145/1277741.1277779",
      year: "",
      authors: "Qi He",
      doi: "10.1145/1277741.1277779",
    },
    {
      FIELD1: 117,
      id: "7A78A07C",
      name: "User adaptation: good results from poor systems",
      url: "https://dl.acm.org/doi/abs/10.1145/1390334.1390362",
      abstract:
        '\nSeveral recent studies have found only a weak relationship between the performance of a retrieval system and the "success" achievable by human searchers. We hypothesize that searchers are successful precisely because they alter their behavior. To explore the possible causal relation between system performance and search behavior, we control system performance, hoping to elicit adaptive search behaviors. 36 subjects each completed 12 searches using either a standard system or one of two degraded systems. Using a general linear model, we isolate the main effect of system performance, by measuring and removing main effects due to searcher variation, topic difficulty, and the position of each search in the time series. We find that searchers using our degraded systems are as successful as those using the standard system, but that, in achieving this success, they alter their behavior in ways that could be measured, in real time, by a suitably instrumented system. Our findings suggest, quite generally, that some aspects of behavioral dynamics may provide unobtrusive indicators of system performance.\n',
      citations:
        ' ""10.1177/20501579221080333/,  ""10.1007/978-3-030-66501-2_6/,  ""10.1016/j.ipm.2021.102601/,  ""10.1002ra2.15/,  ""10.1108/JD-02-2014-0031/,  ""10.1109/HRI.2013.6483558/,  ""10.1007/978-3-642-41145-8_3/,  ""10.1002/meet.14505001044/,  ""10.1007/978-3-642-32281-5_44/,  ""10.1007/s13222-011-0069-z/,  ""10.1007/978-3-642-19231-9_6/,  ""10.2200/S00368ED1V01Y201105ICR019/,  ""10.1002/meet.2011.14504801077/,  ""10.1002/aris.2011.1440450111/,  ""10.1002/meet.2008.1450450381/,  ""10.1002/asi.24451/,  ""10.1108/JD-01-2021-0019/',
      group:
        "SIGIR '08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrievalJuly 2008  Pages   147–154https://doi.org/10.1145/1390334.1390362",
      year: "",
      authors: "Catherine L. Smith",
      doi: "10.1145/1390334.1390362",
    },
    {
      FIELD1: 118,
      id: "78EC631B",
      name: "Domain-independent text segmentation using anisotropic diffusion and dynamic programming",
      url: "https://dl.acm.org/doi/abs/10.1145/860435.860494",
      abstract:
        "\nThis paper presents a novel domain-independent text segmentation method, which identifies the boundaries of topic changes in long text documents and/or text streams. The method consists of three components: As a preprocessing step, we eliminate the document-dependent stop words as well as the generic stop words before the sentence similarity is computed. This step assists in the discrimination of the sentence semantic information. Then the cohesion information of sentences in a document or a text stream is captured with a sentence-distance matrix with each entry corresponding to the similarity between a sentence pair. The distance matrix can be represented with a gray-scale image. Thus, a text segmentation problem is converted into an image segmentation problem. We apply the anisotropic diffusion technique to the image representation of the distance matrix to enhance the semantic cohesion of sentence topical groups as well as sharpen topical boundaries. At last, the dynamic programming technique is adapted to find the optimal topical boundaries and provide a zoom-in and zoom-out mechanism for topics access by segmenting text in variable numbers of sentence topical groups. Our approach involves no domain-specific training, and it can be applied to texts in a variety of domains. The experimental results show that our approach is effective in text segmentation and outperforms several state-of-the-art methods.\n",
      citations:
        ' ""10.1109/TKDE.2020.2983360/,  ""10.1109/TVCG.2018.2834341/,  ""10.1109/SNPD.2018.8441085/,  ""10.1109/ICDMW.2018.00053/,  ""10.1109/ICMETE.2016.33/,  ""10.1109/SAI.2014.6918196/,  ""10.1109/CIS.2011.240/,  ""10.1007/978-3-642-19400-9_24/,  ""10.1007/978-3-642-15760-8_27/,  ""10.1007/978-3-540-68636-1_14/,  ""10.1007/978-3-540-74628-7_21/,  ""10.1109/TFUZZ.2006.889911/,  ""10.1109/ICIA.2005.1635156/',
      group:
        "SIGIR '03: Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrievalJuly 2003  Pages   322–329https://doi.org/10.1145/860435.860494",
      year: "",
      authors: "Xiang Ji",
      doi: "10.1145/860435.860494",
    },
    {
      FIELD1: 119,
      id: "7F6C8F0D",
      name: "Document clustering with prior knowledge",
      url: "https://dl.acm.org/doi/abs/10.1145/1148170.1148241",
      abstract:
        "\nDocument clustering is an important tool for text analysis and is used in many different applications. We propose to incorporate prior knowledge of cluster membership for document cluster analysis and develop a novel semi-supervised document clustering model. The method models a set of documents with weighted graph in which each document is represented as a vertex, and each edge connecting a pair of vertices is weighted with the similarity value of the two corresponding documents. The prior knowledge indicates pairs of documents that known to belong to the same cluster. Then, the prior knowledge is transformed into a set of constraints. The document clustering task is accomplished by finding the best cuts of the graph under the constraints. We apply the model to the Normalized Cut method to demonstrate the idea and concept. Our experimental evaluations show that the proposed document clustering model reveals remarkable performance improvements with very limited training samples, and hence is a very effective semi-supervised classification tool.\n",
      citations:
        ' ""10.1007/978-981-13-0344-9_11/,  ""10.1007/978-3-030-02985-2_2/,  ""10.1109/TKDE.2018.2843342/,  ""10.4018/978-1-5225-5191-1.ch003/,  ""10.1109/SCC.2018.00008/,  ""10.4018/978-1-5225-0536-5.ch013/,  ""10.1109/ICIEAM.2017.8076407/,  ""10.1109/ICDM.2017.162/,  ""10.1109/TCYB.2015.2403573/,  ""10.1007/s11390-015-1565-7/,  ""10.1109/TKDE.2014.2356471/,  ""10.1109/WI-IAT.2015.90/,  ""10.1109/ICRTIT.2014.6996138/,  ""10.1109/IJCNN.2014.6889914/,  ""10.4018/978-1-4666-4062-7.ch005/,  ""10.1109/TSMCB.2012.2227998/,  ""10.1109/ICSMC.2012.6378284/,  ""10.1109/ICSMC.2012.6377788/,  ""10.1007/978-3-642-23241-1_6/,  ""10.4018/ijirr.2012070105/,  ""10.1007/978-3-642-19437-5_24/,  ""10.1587/transinf.E94.D.1227/,  ""10.3745/KIPSTB.2010.17B.2.177/,  ""10.1007/978-3-642-15251-1_32/,  ""10.1007/978-3-642-12035-0_17/,  ""10.1007/978-3-642-04180-8_31/,  ""10.1109/ICNIDC.2009.5360803/,  ""10.1007/978-3-642-04174-7_24/,  ""10.1007/s10115-008-0134-6/,  ""10.1007/s13042-018-0790-0/,  ""10.1007/s10586-018-2023-4/',
      group:
        "SIGIR '06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2006  Pages   405–412https://doi.org/10.1145/1148170.1148241",
      year: "",
      authors: "Xiang Ji",
      doi: "10.1145/1148170.1148241",
    },
    {
      FIELD1: 120,
      id: "7996EB5E",
      name: "Effective document presentation with a locality-based similarity heuristic",
      url: "https://dl.acm.org/doi/pdf/10.1145/312624.312664",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 121,
      id: "8130637C",
      name: "A regression framework for learning ranking functions using relative relevance judgments",
      url: "https://dl.acm.org/doi/abs/10.1145/1277741.1277792",
      abstract:
        "\nEffective ranking functions are an essential part of commercial search engines. We focus on developing a regression framework for learning ranking functions for improving relevance of search engines serving diverse streams of user queries. We explore supervised learning methodology from machine learning, and we distinguish two types of relevance judgments used as the training data: 1) absolute relevance judgments arising from explicit labeling of search results; and 2) relative relevance judgments extracted from user click throughs of search results or converted from the absolute relevance judgments. We propose a novel optimization framework emphasizing the use of relative relevance judgments. The main contribution is the development of an algorithm based on regression that can be applied to objective functions involving preference data, i.e., data indicating that a document is more relevant than another with respect to a query. Experimental results are carried out using data sets obtained from a commercial search engine. Our results show significant improvements of our proposed methods over some existing methods.\n",
      citations:
        ' ""10.1007/s10994-021-06122-3/,  ""10.1109/ACCESS.2021.3130369/,  ""10.1109/ACCESS.2019.2902640/,  ""10.1109/TCSS.2019.2907563/,  ""10.1142/S0218001419510078/,  ""10.1007/978-981-10-8657-1_35/,  ""10.1109/BigData.2017.8258078/,  ""10.1007/978-3-319-59147-6_45/,  ""10.1016/j.jksuci.2017.12.006/,  ""10.1016/j.is.2016.10.002/,  ""10.4018/978-1-4666-9562-7.ch063/,  ""10.1109/IJCNN.2016.7727464/,  ""10.4018/978-1-4666-8833-9.ch003/,  ""10.1109/DSAA.2015.7344890/,  ""10.2200/S00607ED2V01Y201410HLT026/,  ""10.1109/ICDM.2013.54/,  ""10.1007/s10115-011-0390-8/,  ""10.1007/978-3-642-24469-8_33/,  ""10.1007/978-3-642-14267-3_19/,  ""10.1007/978-3-642-14267-3_1/,  ""10.1007/978-3-642-14267-3_3/,  ""10.2200/S00348ED1V01Y201104HLT012/,  ""10.1109/ALLERTON.2008.4797684/,  ""10.1007/s10791-021-09398-0/',
      group:
        "SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2007  Pages   287–294https://doi.org/10.1145/1277741.1277792",
      year: "",
      authors: "Zhaohui Zheng",
      doi: "10.1145/1277741.1277792",
    },
    {
      FIELD1: 122,
      id: "7EADEC8F",
      name: "Learning from labeled features using generalized expectation criteria",
      url: "https://dl.acm.org/doi/abs/10.1145/1390334.1390436",
      abstract:
        "\nIt is difficult to apply machine learning to new domains because often we lack labeled problem instances. In this paper, we provide a solution to this problem that leverages domain knowledge in the form of affinities between input features and classes. For example, in a baseball vs. hockey text classification problem, even without any labeled data, we know that the presence of the word puck is a strong indicator of hockey. We refer to this type of domain knowledge as a labeled feature. In this paper, we propose a method for training discriminative probabilistic models with labeled features and unlabeled instances. Unlike previous approaches that use labeled features to create labeled pseudo-instances, we use labeled features directly to constrain the model's predictions on unlabeled instances. We express these soft constraints using generalized expectation (GE) criteria --- terms in a parameter estimation objective function that express preferences on values of a model expectation. In this paper we train multinomial logistic regression models using GE criteria, but the method we develop is applicable to other discriminative probabilistic models. The complete objective function also includes a Gaussian prior on parameters, which encourages generalization by spreading parameter weight to unlabeled features. Experimental results on text classification data sets show that this method outperforms heuristic approaches to training classifiers with labeled features. Experiments with human annotators show that it is more beneficial to spend limited annotation time labeling features rather than labeling instances. For example, after only one minute of labeling features, we can achieve 80% accuracy on the ibm vs. mac text classification problem using GE-FL, whereas ten minutes labeling documents results in an accuracy of only 77%\n",
      citations:
        ' ""10.1109/TNNLS.2020.3011671/,  ""10.1007/978-3-030-74296-6_21/,  ""10.1007/s10458-019-09425-x/,  ""10.1007/978-3-030-66187-8_5/,  ""10.1145/3419972/,  ""10.1109/TENCON.2019.8929663/,  ""10.1007/978-3-030-11051-2_119/,  ""10.2478/dim-2019-0011/,  ""10.1007/978-3-319-75487-1_35/,  ""10.1109/MESA.2018.8449150/,  ""10.1093/jamia/ocy013/,  ""10.1109/IJCNN.2016.7727788/,  ""10.1109/INTECH.2016.7845096/,  ""10.1007/978-3-319-50137-6_2/,  ""10.1007/978-3-319-46227-1_19/,  ""10.1007/978-3-319-25485-2_1/,  ""10.1007/s11390-015-1569-3/,  ""10.1287/ijoc.2013.0578/,  ""10.1109/IC3e.2013.6735980/,  ""10.1109/SOCPAR.2013.7054141/,  ""10.1007/978-3-642-33460-3_11/,  ""10.2200/S00429ED1V01Y201207AIM018/,  ""10.1007/978-3-642-24477-3_24/,  ""10.1109/ICMLC.2011.6016953/,  ""10.1007/978-3-642-24434-6_2/,  ""10.1007/s00521-019-04681-0/,  ""10.1007/s10115-018-1280-0/,  ""10.1088/1361-6560/aac712/,  ""10.1017/S1351324920000340/,  ""10.1007/s11192-021-04186-5/',
      group:
        "SIGIR '08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrievalJuly 2008  Pages   595–602https://doi.org/10.1145/1390334.1390436",
      year: "",
      authors: "Gregory Druck",
      doi: "10.1145/1390334.1390436",
    },
    {
      FIELD1: 123,
      id: "7EB0740B",
      name: "Text classification with kernels on the multinomial manifold",
      url: "https://dl.acm.org/doi/abs/10.1145/1076034.1076081",
      abstract:
        "\nSupport Vector Machines (SVMs) have been very successful in text classification. However, the intrinsic geometric structure of text data has been ignored by standard kernels commonly used in SVMs. It is natural to assume that the documents are on the multinomial manifold, which is the simplex of multinomial models furnished with the Riemannian structure induced by the Fisher information metric. We prove that the Negative Geodesic Distance (NGD) on the multinomial manifold is conditionally positive definite (cpd), thus can be used as a kernel in SVMs. Experiments show the NGD kernel on the multinomial manifold to be effective for text classification, significantly outperforming standard kernels on the ambient Euclidean space.\n",
      citations:
        ' ""10.1109/TMM.2019.2944241/,  ""10.1007/978-3-030-50146-4_51/,  ""10.1109/ICBK.2018.00066/,  ""10.1109/LRA.2017.2677469/,  ""10.1109/IGARSS.2016.7729119/,  ""10.1109/TNNLS.2015.2399102/,  ""10.1109/CVPR.2015.7298916/,  ""10.1109/WI-IAT.2015.90/,  ""10.1109/ECC.2015.7330969/,  ""10.1109/CVPR.2015.7298736/,  ""10.1109/ICDMW.2014.144/,  ""10.1007/978-3-319-01595-8_21/,  ""10.1007/s10791-006-9019-z/,  ""10.1109/ICSMC.2006.384735/',
      group:
        "SIGIR '05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2005  Pages   266–273https://doi.org/10.1145/1076034.1076081",
      year: "",
      authors: "Dell Zhang",
      doi: "10.1145/1076034.1076081",
    },
    {
      FIELD1: 124,
      id: "7CBBFBF4",
      name: "Social media recommendation based on people and tags",
      url: "https://dl.acm.org/doi/abs/10.1145/1835449.1835484",
      abstract:
        "\nWe study personalized item recommendation within an enterprise social media application suite that includes blogs, bookmarks, communities, wikis, and shared files. Recommendations are based on two of the core elements of social media - people and tags. Relationship information among people, tags, and items, is collected and aggregated across different sources within the enterprise. Based on these aggregated relationships, the system recommends items related to people and tags that are related to the user. Each recommended item is accompanied by an explanation that includes the people and tags that led to its recommendation, as well as their relationships with the user and the item. We evaluated our recommender system through an extensive user study. Results show a significantly better interest ratio for the tag-based recommender than for the people-based recommender, and an even better performance for a combined recommender. Tags applied on the user by other people are found to be highly effective in representing that user's topics of interest.\n",
      citations:
        ' ""10.1109/ICOEI53556.2022.9777131/,  ""10.4018/IJIRR.289574/,  ""10.1007/978-3-030-73200-4_17/,  ""10.1109/ICSTW52544.2021.00035/,  ""10.4018/978-1-7998-9020-1.ch027/,  ""10.1007/s13278-021-00785-5/,  ""10.1214/21-EJS1884/,  ""10.1007/978-3-030-19562-5_29/,  ""10.1007/s13278-019-0621-7/,  ""10.4018/IJCINI.2020070101/,  ""10.2478/manment-2019-0047/,  ""10.1109/IALP48816.2019.9037682/,  ""10.1109/TKDE.2019.2932406/,  ""10.1007/978-3-030-19063-7_54/,  ""10.1109/TPC.2018.2867168/,  ""10.1109/ICOSC.2019.8665624/,  ""10.1109/HCC46620.2019.00025/,  ""10.1109/BigData47090.2019.9006062/,  ""10.1007/s12525-018-0314-5/,  ""10.1007/978-3-030-01762-0_19/,  ""10.2139/ssrn.3262386/,  ""10.1007/s11390-017-1766-3/,  ""10.1007/978-3-319-90092-6_14/,  ""10.1007/978-3-319-93647-5_8/,  ""10.1007/978-3-319-90092-6_12/,  ""10.1007/978-981-10-7200-0_2/,  ""10.1007/978-3-319-93843-1_14/,  ""10.1007/978-3-658-20765-6_2/,  ""10.1007/978-3-319-90092-6_11/,  ""10.1109/I-SMAC.2018.8653769/,  ""10.1109/ICACCCN.2018.8748865/,  ""10.1109/TETCI.2018.2804335/,  ""10.1007/978-3-319-91485-5_12/,  ""10.1109/ICACCS.2017.8014631/,  ""10.1057/978-1-137-57475-6_5/,  ""10.1109/ICACCS.2017.8014653/,  ""10.1109/TMC.2017.2694830/,  ""10.1007/978-3-319-53676-7_3/,  ""10.1287/deca.2017.0354/,  ""10.1007/s11432-015-0900-x/,  ""10.1109/GLOCOM.2016.7842229/,  ""10.1109/IJCNN.2016.7727500/,  ""10.4018/978-1-4666-9787-4.ch138/,  ""10.1109/GLOCOM.2016.7841666/,  ""10.1007/978-3-319-24369-6_3/,  ""10.1007/978-1-4899-7637-6_20/,  ""10.1109/TMM.2015.2460192/,  ""10.1109/ICECCO.2015.7416895/,  ""10.1631/FITEE.1400368/,  ""10.1007/978-3-319-08786-3_40/,  ""10.1016/j.ins.2014.03.121/,  ""10.1007/s12652-012-0119-x/,  ""10.1007/978-3-319-05401-8_3/,  ""10.1109/ISTEL.2014.7000749/,  ""10.1109/RCIS.2014.6861066/,  ""10.4018/ijmdem.2014010103/,  ""10.1007/978-3-642-37453-1_28/,  ""10.1007/978-3-642-38366-3_15/,  ""10.1007/978-3-642-41154-0_7/,  ""10.1007/978-1-4614-8806-4_52/,  ""10.1007/978-3-642-37450-0_16/,  ""10.1109/SII.2013.6776691/,  ""10.1109/HPCC.and.EUC.2013.316/,  ""10.1109/ICAwST.2013.6765443/,  ""10.1007/978-3-642-25694-3_6/,  ""10.1007/978-1-4614-1894-8_4/,  ""10.1109/WICT.2012.6409252/,  ""10.1109/ICDIM.2012.6360114/,  ""10.1109/ICE.2012.6297690/,  ""10.1109/WI-IAT.2012.124/,  ""10.1109/WoWMoM.2012.6263692/,  ""10.1007/978-3-642-23014-1_18/,  ""10.1007/978-3-642-24396-7_31/,  ""10.1002/asi.24118/,  ""10.1108/EJM-11-2017-0896/,  ""10.3390/ijgi7020071/,  ""10.1080/17544750.2021.2009890/',
      group:
        "SIGIR '10: Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrievalJuly 2010  Pages   194–201https://doi.org/10.1145/1835449.1835484",
      year: "",
      authors: "Ido Guy",
      doi: "10.1145/1835449.1835484",
    },
    {
      FIELD1: 125,
      id: "7BDE0134",
      name: "Computation of term associations by a neural network",
      url: "https://dl.acm.org/doi/pdf/10.1145/160688.160703",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 126,
      id: "768042B4",
      name: "Learning to rank query reformulations",
      url: "https://dl.acm.org/doi/abs/10.1145/1835449.1835626",
      abstract:
        "\nQuery reformulation techniques based on query logs have recently proven to be effective for web queries. However, when initial queries have reasonably good quality, these techniques are often not reliable enough to identify the helpful reformulations among the suggested queries. In this paper, we show that we can use as few as two features to rerank a list of reformulated queries, or expanded queries to be specific, generated by a log-based query reformulation technique. Our results across five TREC collections suggest that there are consistently more useful reformulations in the first two positions in the new ranked list than there were initially, which leads to statistically significant improvements in retrieval effectiveness.\n",
      citations: ' ""10.1007/978-3-319-30671-1_23/,  ""10.3390/app11199075/',
      group:
        "SIGIR '10: Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrievalJuly 2010  Pages   807–808https://doi.org/10.1145/1835449.1835626",
      year: "",
      authors: "Van Dang",
      doi: "10.1145/1835449.1835626",
    },
    {
      FIELD1: 127,
      id: "788FA378",
      name: "Towards language independent automated learning of text categorization models",
      url: "https://link.springer.com/chapter/10.1007/978-1-4471-2099-5_3",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 128,
      id: "7ECA2159",
      name: "A support vector method for optimizing average precision",
      url: "https://dl.acm.org/doi/abs/10.1145/1277741.1277790",
      abstract:
        "\nMachine learning is commonly used to improve ranked retrieval systems. Due to computational difficulties, few learning techniques have been developed to directly optimize for mean average precision (MAP), despite its widespread use in evaluating such systems. Existing approaches optimizing MAP either do not find a globally optimal solution, or are computationally expensive. In contrast, we present a general SVM learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of MAP. We evaluate our approach using the TREC 9 and TREC 10 Web Track corpora (WT10g), comparing against SVMs optimized for accuracy and ROCArea. In most cases we show our method to produce statistically significant improvements in MAP scores.\n",
      citations:
        ' ""10.1007/s11704-020-0192-9/,  ""10.1109/ACCESS.2022.3159646/,  ""10.1007/s10664-021-10066-6/,  ""10.1007/978-3-030-96623-2_9/,  ""10.1109/TGRS.2022.3170316/,  ""10.2298/CSIS201220042Y/,  ""10.1016/j.apacoust.2020.107559/,  ""10.1007/978-3-030-72113-8_43/,  ""10.1007/978-3-030-75768-7_21/,  ""10.1109/IJCNN52387.2021.9533320/,  ""10.1109/TPAMI.2020.2991457/,  ""10.1109/FiCloud49777.2021.00037/,  ""10.1007/978-3-030-93420-0_19/,  ""10.1111/tgis.12798/,  ""10.1117/12.2606720/,  ""10.1016/j.trpro.2020.02.069/,  ""10.1109/MCI.2020.2976187/,  ""10.1007/978-3-030-06170-8_5/,  ""10.1016/B978-0-12-819764-6.00008-9/,  ""10.1109/CVPR42600.2020.00764/,  ""10.1007/978-3-030-58545-7_39/,  ""10.1109/SSCI47803.2020.9308223/,  ""10.1088/1742-6596/1682/1/012044/,  ""10.1109/TNNLS.2019.2936876/,  ""10.1007/s12046-019-1073-5/,  ""10.1109/TVCG.2018.2842734/,  ""10.1142/S021819401930001X/,  ""10.1007/978-3-030-34223-4_12/,  ""10.1109/SMC.2019.8913932/,  ""10.1109/CVPR.2019.00196/,  ""10.1109/CVPR.2019.00526/,  ""10.1109/ICCV.2019.00521/,  ""10.1109/CVPR.2019.01105/,  ""10.1109/TPAMI.2019.2914897/,  ""10.1109/ICME.2019.00311/,  ""10.1109/INFOCOM.2019.8737619/,  ""10.1007/978-981-13-1951-8_68/,  ""10.1109/TNNLS.2019.2945133/,  ""10.1109/TCYB.2017.2670608/,  ""10.1007/s10791-018-9330-5/,  ""10.1109/TPAMI.2017.2751607/,  ""10.1016/j.neunet.2017.11.006/,  ""10.1108/LHT-05-2017-0090/,  ""10.1007/978-3-319-73531-3_9/,  ""10.1109/ICASSP.2018.8462599/,  ""10.1109/ICOA.2018.8370597/,  ""10.1109/ICWS.2018.00022/,  ""10.1109/ACCESS.2018.2817497/,  ""10.1109/TMM.2018.2791803/,  ""10.1109/CVPR.2018.00389/,  ""10.1109/CVPR.2018.00423/,  ""10.1109/TNNLS.2017.2757504/,  ""10.1109/SCC.2017.21/,  ""10.1016/B978-0-12-812013-2.00007-1/,  ""10.1109/ICCV.2017.55/,  ""10.1109/BigData.2017.8258135/,  ""10.1109/TIP.2017.2708503/,  ""10.1109/TKDE.2017.2654250/,  ""10.1109/ISPAN-FCST-ISCC.2017.61/,  ""10.1007/978-3-319-54193-8_13/,  ""10.1109/ICWS.2017.124/,  ""10.1007/978-3-319-71249-9_2/,  ""10.1109/ICKEA.2016.7803020/,  ""10.4018/978-1-4666-8833-9.ch003/,  ""10.1109/GLOCOM.2016.7842335/,  ""10.1007/978-3-319-49055-7_31/,  ""10.1109/TIP.2015.2503700/,  ""10.1109/BigData.2016.7840827/,  ""10.1007/978-3-319-50835-1_22/,  ""10.1109/ICDM.2016.0062/,  ""10.1109/IJCNN.2016.7727188/,  ""10.1109/CVPR.2016.513/,  ""10.4018/978-1-4666-9562-7.ch063/,  ""10.1109/LSP.2015.2502271/,  ""10.1109/GLOCOM.2016.7841562/,  ""10.1140/epjds/s13688-016-0095-z/,  ""10.1007/978-3-319-18032-8_58/,  ""10.1007/978-3-319-20248-8_7/,  ""10.1007/978-3-319-26555-1_55/,  ""10.1186/s13321-015-0052-z/,  ""10.1109/INFOCOM.2015.7218593/,  ""10.1109/CVPR.2015.7299037/,  ""10.1109/TIP.2015.2421309/,  ""10.1109/RIOS.2015.7270735/,  ""10.1109/TAAI.2015.7407063/,  ""10.1109/TIP.2015.2403240/,  ""10.1109/ICASSP.2015.7178969/,  ""10.1109/ICASSP.2015.7178307/,  ""10.1109/LSP.2015.2410134/,  ""10.1109/TSC.2014.2381496/,  ""10.1007/978-3-319-10593-2_40/,  ""10.1201/b16812-58/,  ""10.1007/s11042-012-1192-z/,  ""10.1007/978-3-319-10578-9_40/,  ""10.2200/S00607ED2V01Y201410HLT026/,  ""10.1109/TNNLS.2013.2286696/,  ""10.1109/CIDM.2014.7008150/,  ""10.1007/978-3-642-37450-0_27/,  ""10.1007/978-3-642-41491-6_8/,  ""10.1016/j.eswa.2013.04.001/,  ""10.1109/ICDM.2013.54/,  ""10.1109/SOLI.2013.6611452/,  ""10.1109/TNNLS.2013.2247628/,  ""10.1527/tjsai.28.22/,  ""10.1186/1471-2105-14-286/,  ""10.1002/9781118562796.ch2/,  ""10.1007/978-3-642-35326-0_38/,  ""10.1007/978-3-642-33460-3_14/,  ""10.1109/CVPR.2012.6248090/,  ""10.1109/CVPR.2012.6247941/,  ""10.1109/MLSP.2012.6349807/,  ""10.1007/978-3-642-14267-3_4/,  ""10.1587/transinf.E94.D.1854/,  ""10.2200/S00348ED1V01Y201104HLT012/,  ""10.1007/978-3-642-22898-8_6/,  ""10.1007/978-0-85729-525-5_9/,  ""10.1007/978-3-642-14267-3_5/,  ""10.1007/978-3-642-14267-3_1/,  ""10.1007/978-3-642-14267-3_19/,  ""10.1007/978-3-642-14267-3_11/,  ""10.1007/978-3-642-23577-1_4/,  ""10.1109/ISI.2011.5984123/,  ""10.1007/978-3-642-24769-9_32/,  ""10.1109/CIDM.2011.5949420/,  ""10.1007/978-3-642-14556-8_9/,  ""10.1007/978-3-642-14556-8_7/,  ""10.1109/YCICT.2010.5713050/,  ""10.1109/ICASSP.2010.5494981/,  ""10.1109/CVPR.2010.5540003/,  ""10.1109/CSCWD.2010.5472010/,  ""10.4218/etrij.10.0109.0425/,  ""10.1109/ICMLC.2010.5580775/,  ""10.1109/YCICT.2010.5713094/,  ""10.1109/NLPKE.2010.5587824/,  ""10.1021/ci9003865/,  ""10.1109/ALLERTON.2008.4797684/,  ""10.1109/ICPR.2008.4761471/,  ""10.1007/s11633-019-1207-6/,  ""10.1007/s11263-020-01308-z/,  ""10.1002/cpe.4464/,  ""10.1371/journal.pone.0129947/,  ""10.1007/s11704-012-1170-7/,  ""10.1007/s13042-017-0730-4/,  ""10.1371/journal.pone.0061567/,  ""10.1080/01621459.2019.1691562/,  ""10.1111/coin.12413/,  ""10.1007/s11280-020-00846-3/,  ""10.1007/s00500-021-05694-5/,  ""10.1007/s40747-021-00327-8/',
      group:
        "SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2007  Pages   271–278https://doi.org/10.1145/1277741.1277790",
      year: "",
      authors: "Yisong Yue",
      doi: "10.1145/1277741.1277790",
    },
    {
      FIELD1: 129,
      id: "7E6BF6D8",
      name: "A database centric view of semantic image annotation and retrieval",
      url: "https://dl.acm.org/doi/abs/10.1145/1076034.1076129",
      abstract:
        "\nWe introduce a new model for semantic annotation and retrieval from image databases. The new model is based on a probabilistic formulation that poses annotation and retrieval as classification problems, and produces solutions that are optimal in the minimum probability of error sense. It is also database centric, by establishing a one-to-one mapping between semantic classes and the groups of database images that share the associated semantic labels. In this work we show that, under the database centric probabilistic model, optimal annotation and retrieval can be implemented with algorithms that are conceptually simple, computationally efficient, and do not require prior semantic segmentation of training images. Due to its simplicity, the annotation and retrieval architecture is also amenable to sophisticated parameter tuning, a property that is exploited to investigate the role of feature selection in the design of optimal annotation and retrieval systems. Finally, we demonstrate the benefits of simply establishing a one-to-one mapping between keywords and the states of the semantic classification problem over the more complex, and currently popular, joint modeling of keyword and visual feature distributions. The database centric probabilistic retrieval model is compared to existing semantic labeling and retrieval methods, and shown to achieve higher accuracy than the previously best published results, at a fraction of their computational cost.\n",
      citations:
        ' ""10.1002/9781119286462.refs/,  ""10.1109/KBEI.2015.7436151/,  ""10.1007/978-3-642-37835-5_20/,  ""10.4018/978-1-61350-126-9.ch004/,  ""10.4018/978-1-60960-818-7.ch417/,  ""10.1007/978-3-642-27278-3_40/,  ""10.1007/978-3-642-35286-7_18/,  ""10.4018/978-1-60960-553-7.ch017/,  ""10.1007/978-3-642-17829-0_43/,  ""10.1007/978-3-642-15907-7_35/,  ""10.1109/CCDC.2009.5192005/,  ""10.1007/978-3-540-92219-3_29/,  ""10.1109/LSP.2009.2028114/,  ""10.1109/ICPR.2008.4761646/,  ""10.1109/ICPR.2008.4761476/,  ""10.1109/CVPR.2007.383221/,  ""10.1109/CVPR.2007.383106/,  ""10.1109/CVPR.2007.383079/,  ""10.1007/0-387-34224-9_66/,  ""10.4028/www.scientific.net/AMM.48-49.366/',
      group:
        "SIGIR '05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2005  Pages   559–566https://doi.org/10.1145/1076034.1076129",
      year: "",
      authors: "Gustavo Carneiro",
      doi: "10.1145/1076034.1076129",
    },
    {
      FIELD1: 130,
      id: "7C9B715B",
      name: "Probabilistic latent query analysis for combining multiple retrieval sources",
      url: "https://dl.acm.org/doi/abs/10.1145/1148170.1148228",
      abstract:
        "\nCombining the output from multiple retrieval sources over the same document collection is of great importance to a number of retrieval tasks such as multimedia retrieval, web retrieval and meta-search. To merge retrieval sources adaptively according to query topics, we propose a series of new approaches called probabilistic latent query analysis (pLQA), which can associate non-identical combination weights with latent classes underlying the query space. Compared with previous query independent and query-class based combination methods, the proposed approaches have the advantage of being able to discover latent query classes automatically without using prior human knowledge, to assign one query to a mixture of query classes, and to determine the number of query classes under a model selection principle. Experimental results on two retrieval tasks, i.e., multimedia retrieval and meta-search, demonstrate that the proposed methods can uncover sensible latent classes from training data, and can achieve considerable performance gains.\n",
      citations:
        ' ""10.4018/978-1-60566-010-3.ch186/,  ""10.1109/JPROC.2008.916345/,  ""10.1109/CIDM.2007.368896/,  ""10.1109/ICME.2007.4284946/',
      group:
        "SIGIR '06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2006  Pages   324–331https://doi.org/10.1145/1148170.1148228",
      year: "",
      authors: "Rong Yan",
      doi: "10.1145/1148170.1148228",
    },
    {
      FIELD1: 131,
      id: "7D43B6D6",
      name: "Ranking with multiple hyperplanes",
      url: "https://dl.acm.org/doi/abs/10.1145/1277741.1277791",
      abstract:
        '\nThe central problem for many applications in Information Retrieval is ranking and learning to rank is considered as a promising approach for addressing the issue. Ranking SVM, for example, is a state-of-the-art method for learning to rank and has been empirically demonstrated to be effective. In this paper, we study the issue of learning to rank, particularly the approach of using SVM techniques to perform the task. We point out that although Ranking SVM is advantageous, it still has shortcomings. Ranking SVM employs a single hyperplane in the feature space as the model for ranking, which is too simple to tackle complex ranking problems. Furthermore, the training of Ranking SVM is also computationally costly. In this paper, we look at an alternative approach to Ranking SVM, which we call "Multiple Hyperplane Ranker" (MHR), and make comparisons between the two approaches. MHR takes the divide-and-conquer strategy. It employs multiple hyperplanes to rank instances and finally aggregates the ranking results given by the hyperplanes. MHR contains Ranking SVM as a special case, and MHR can overcome the shortcomings which Ranking SVM suffers from. Experimental results on two information retrieval datasets show that MHR can outperform Ranking SVM in ranking.\n',
      citations:
        ' ""10.1007/s10994-021-06122-3/,  ""10.1109/ACCESS.2021.3085971/,  ""10.1109/TETCI.2018.2864554/,  ""10.1109/TIP.2016.2580939/,  ""10.1109/TIFS.2015.2462732/,  ""10.1109/NICS.2015.7302178/,  ""10.1109/TIP.2014.2387379/,  ""10.1109/ICoCS.2014.7060911/,  ""10.2200/S00607ED2V01Y201410HLT026/,  ""10.1007/978-3-319-05813-9_10/,  ""10.1007/s13369-014-1463-2/,  ""10.1109/FG.2013.6553772/,  ""10.1007/978-3-642-37450-0_27/,  ""10.1007/978-3-642-40501-3_27/,  ""10.1109/TMI.2010.2062197/,  ""10.1109/CIDM.2011.5949420/,  ""10.1002/int.20455/,  ""10.1007/978-3-642-20841-6_30/,  ""10.1007/978-3-642-21557-5_4/,  ""10.1007/978-3-642-24469-8_33/,  ""10.1007/978-3-642-14267-3_10/,  ""10.1007/978-3-642-14267-3_1/,  ""10.1007/978-3-642-14267-3_3/,  ""10.2200/S00348ED1V01Y201104HLT012/,  ""10.1007/978-3-642-14267-3_19/,  ""10.1109/ICMLC.2009.5212411/,  ""10.1007/978-3-642-00958-7_67/,  ""10.1109/ISKE.2008.4730996/',
      group:
        "SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2007  Pages   279–286https://doi.org/10.1145/1277741.1277791",
      year: "",
      authors: "Tao Qin",
      doi: "10.1145/1277741.1277791",
    },
    {
      FIELD1: 132,
      id: "7A323EFE",
      name: "Exploiting ontologies for automatic image annotation",
      url: "https://dl.acm.org/doi/abs/10.1145/1076034.1076128",
      abstract:
        "\nAutomatic image annotation is the task of automatically assigning words to an image that describe the content of the image. Machine learning approaches have been explored to model the association between words and images from an annotated set of images and generate annotations for a test image. The paper proposes methods to use a hierarchy defined on the annotation words derived from a text ontology to improve automatic image annotation and retrieval. Specifically, the hierarchy is used in the context of generating a visual vocabulary for representing images and as a framework for the proposed hierarchical classification approach for automatic image annotation. The effect of using the hierarchy in generating the visual vocabulary is demonstrated by improvements in the annotation performance of translation models. In addition to performance improvements, hierarchical classification approaches yield well to constructing multimedia ontologies.\n",
      citations:
        ' ""10.46300/91017.2022.9.8/,  ""10.1186/s12859-021-04008-8/,  ""10.1109/iV.2017.27/,  ""10.1007/s13735-015-0082-3/,  ""10.1201/b16768-17/,  ""10.1016/j.isprsjprs.2013.05.003/,  ""10.1109/JPROC.2012.2201909/,  ""10.1587/transfun.E95.A.927/,  ""10.1007/978-3-642-19315-6_17/,  ""10.1109/EUVIP.2010.5699133/,  ""10.1007/978-3-642-05179-1_18/,  ""10.1109/ICSIPA.2009.5478621/,  ""10.1109/EM-COM.2009.5402975/,  ""10.1109/ITI.2009.5196076/,  ""10.1109/JPROC.2008.916355/,  ""10.1007/978-1-84800-076-6_10/,  ""10.3156/jsoft.20.720/,  ""10.1109/CBMI.2007.385419/,  ""10.1109/CVPR.2007.383272/,  ""10.1007/978-3-540-77051-0_3/,  ""10.1007/0-387-34224-9_66/,  ""10.1007/s00607-020-00859-w/',
      group:
        "SIGIR '05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2005  Pages   552–558https://doi.org/10.1145/1076034.1076128",
      year: "",
      authors: "Munirathnam Srikanth",
      doi: "10.1145/1076034.1076128",
    },
    {
      FIELD1: 133,
      id: "7AF59493",
      name: "Automatic essay grading using text categorization techniques",
      url: "https://dl.acm.org/doi/pdf/10.1145/290941.290965",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 134,
      id: "7CFD178A",
      name: "A unified and discriminative model for query refinement",
      url: "https://dl.acm.org/doi/abs/10.1145/1390334.1390400",
      abstract:
        "\nThis paper addresses the issue of query refinement, which involves reformulating ill-formed search queries in order to enhance relevance of search results. Query refinement typically includes a number of tasks such as spelling error correction, word splitting, word merging, phrase segmentation, word stemming, and acronym expansion. In previous research, such tasks were addressed separately or through employing generative models. This paper proposes employing a unified and discriminative model for query refinement. Specifically, it proposes a Conditional Random Field (CRF) model suitable for the problem, referred to as Conditional Random Field for Query Refinement (CRF-QR). Given a sequence of query words, CRF-QR predicts a sequence of refined query words as well as corresponding refinement operations. In that sense, CRF-QR differs greatly from conventional CRF models. Two types of CRF-QR models, namely a basic model and an extended model are introduced. One merit of employing CRF-QR is that different refinement tasks can be performed simultaneously and thus the accuracy of refinement can be enhanced. Furthermore, the advantages of discriminative models over generative models can be fully leveraged. Experimental results demonstrate that CRF-QR can significantly outperform baseline methods. Furthermore, when CRF-QR is used in web search, a significant improvement of relevance can be obtained.\n",
      citations:
        ' ""10.1007/978-3-030-45439-5_42/,  ""10.1007/978-3-319-93935-3_7/,  ""10.1109/ICCONS.2017.8250714/,  ""10.1109/ICCSP.2017.8286823/,  ""10.1002ra2.2016.14505301086/,  ""10.1109/ISSCS.2015.7203984/,  ""10.1109/ICACCI.2013.6637329/,  ""10.1109/ICACCI.2013.6637406/,  ""10.2200/S00508ED1V01Y201305HLT022/,  ""10.1007/978-3-642-34555-5_7/,  ""10.1007/978-3-642-45068-6_34/,  ""10.1002/meet.14505001062/,  ""10.1109/SCOReD.2012.6518611/,  ""10.1007/978-3-642-27323-0_54/,  ""10.1002/meet.2009.14504603117/,  ""10.1109/ICDIM.2009.5356786/',
      group:
        "SIGIR '08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrievalJuly 2008  Pages   379–386https://doi.org/10.1145/1390334.1390400",
      year: "",
      authors: "Jiafeng Guo",
      doi: "10.1145/1390334.1390400",
    },
    {
      FIELD1: 135,
      id: "7D272163",
      name: "Reading time, scrolling and interaction: exploring implicit sources of user preferences for relevance feedback",
      url: "https://dl.acm.org/doi/pdf/10.1145/383952.384045",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 136,
      id: "7AB8447A",
      name: "Evaluating evaluation metrics based on the bootstrap",
      url: "https://dl.acm.org/doi/abs/10.1145/1148170.1148261",
      abstract:
        '\nThis paper describes how the Bootstrap approach to statistics can be applied to the evaluation of IR effectiveness metrics. First, we argue that Bootstrap Hypothesis Tests deserve more attention from the IR community, as they are based on fewer assumptions than traditional statistical significance tests. We then describe straightforward methods for comparing the sensitivity of IR metrics based on Bootstrap Hypothesis Tests. Unlike the heuristics-based "swap" method proposed by Voorhees and Buckley, our method estimates the performance difference required to achieve a given significance level directly from Bootstrap Hypothesis Test results. In addition, we describe a simple way of examining the accuracy of rank correlation between two metrics based on the Bootstrap Estimate of Standard Error. We demonstrate the usefulness of our methods using test collections and runs from the NTCIR CLIR track for comparing seven IR metrics, including those that can handle graded relevance and those based on the Geometric Mean.\n',
      citations:
        ' ""10.1109/ACCESS.2022.3159646/,  ""10.1007/978-3-030-99736-6_13/,  ""10.1007/s10791-022-09407-w/,  ""10.1007/978-3-030-72113-8_38/,  ""10.1109/ACCESS.2021.3116857/,  ""10.1007/978-3-030-22948-1_1/,  ""10.1007/978-3-030-22948-1_2/,  ""10.1007/978-3-030-36805-0_6/,  ""10.1109/TKDE.2017.2729559/,  ""10.1007/978-981-13-1199-4_4/,  ""10.1007/978-981-13-1199-4_2/,  ""10.1007/978-981-13-1199-4_6/,  ""10.1007/978-3-319-93713-7_41/,  ""10.1109/CLEI.2016.7833349/,  ""10.1109/ICITEED.2015.7409020/,  ""10.1108/AJIM-12-2014-0171/,  ""10.1007/978-3-642-54798-0_6/,  ""10.1109/ICIP.2014.7025187/,  ""10.1007/978-3-642-45068-6_4/,  ""10.1007/978-3-642-35341-3_4/,  ""10.1007/978-3-642-24577-0_9/,  ""10.1109/ICRTIT.2011.5972453/,  ""10.1007/978-3-642-17187-1_9/,  ""10.1007/s10791-019-09356-x/,  ""10.1007/s10791-020-09377-x/',
      group:
        "SIGIR '06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2006  Pages   525–532https://doi.org/10.1145/1148170.1148261",
      year: "",
      authors: "Tetsuya Sakai",
      doi: "10.1145/1148170.1148261",
    },
    {
      FIELD1: 137,
      id: "7B20680E",
      name: "Simplified similarity scoring using term ranks",
      url: "https://dl.acm.org/doi/abs/10.1145/1076034.1076075",
      abstract:
        "\nWe propose a method for document ranking that combines a simple document-centric view of text, and fast evaluation strategies that have been developed in connection with the vector space model. The new method defines the importance of a term within a document qualitatively rather than quantitatively, and in doing so reduces the need for tuning parameters. In addition, the method supports very fast query processing, with most of the computation carried out on small integers, and dynamic pruning an effective option. Experiments on a wide range of TREC data show that the new method provides retrieval effectiveness as good as or better than the Okapi BM25 formulation, and variants of language models.\n",
      citations:
        ' ""10.1109/ACCESS.2020.2986943/,  ""10.1007/978-1-4899-7993-3_945-2/,  ""10.1007/978-1-4614-8265-9_945/,  ""10.1002/asi.22665/,  ""10.1007/978-3-642-22898-8_3/,  ""10.1007/978-3-642-15470-6_29/,  ""10.1007/978-0-387-39940-9_945/,  ""10.1007/978-3-540-78646-7_18/,  ""10.1007/s00778-007-0071-0/,  ""10.1007/978-3-540-71496-5_12/,  ""10.1007/978-3-540-77094-7_33/,  ""10.1109/CCE.2006.350884/',
      group:
        "SIGIR '05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2005  Pages   226–233https://doi.org/10.1145/1076034.1076075",
      year: "",
      authors: "Vo Ngoc Anh",
      doi: "10.1145/1076034.1076075",
    },
    {
      FIELD1: 138,
      id: "7C8994A9",
      name: "Multi-document summarization via sentence-level semantic analysis and symmetric matrix factorization",
      url: "https://dl.acm.org/doi/abs/10.1145/1390334.1390387",
      abstract:
        "\nMulti-document summarization aims to create a compressed summary while retaining the main characteristics of the original set of documents. Many approaches use statistics and machine learning techniques to extract sentences from documents. In this paper, we propose a new multi-document summarization framework based on sentence-level semantic analysis and symmetric non-negative matrix factorization. We first calculate sentence-sentence similarities using semantic analysis and construct the similarity matrix. Then symmetric matrix factorization, which has been shown to be equivalent to normalized spectral clustering, is used to group sentences into clusters. Finally, the most informative sentences are selected from each group to form the summary. Experimental results on DUC2005 and DUC2006 data sets demonstrate the improvement of our proposed framework over the implemented existing summarization systems. A further study on the factors that benefit the high performance is also conducted.\n",
      citations:
        ' ""10.1109/TNNLS.2020.3041360/,  ""10.1109/TCSS.2020.3033810/,  ""10.1007/s11704-020-9203-0/,  ""10.1109/TNSE.2020.3040407/,  ""10.1109/I2CT51068.2021.9418197/,  ""10.1016/j.eswa.2020.114555/,  ""10.1109/ICTAI52525.2021.00026/,  ""10.1109/SMC52423.2021.9658687/,  ""10.1109/TII.2019.2908958/,  ""10.3233/IDA-184432/,  ""10.1109/TKDE.2019.2892430/,  ""10.1109/ACCESS.2020.2985222/,  ""10.1002/9781119544487.ch13/,  ""10.1007/978-981-15-5043-0_6/,  ""10.1016/j.procs.2020.03.192/,  ""10.4018/IJITWE.2020010105/,  ""10.1109/ICCNC.2019.8685549/,  ""10.1109/TVCG.2018.2834341/,  ""10.3233/IDA-183947/,  ""10.23919/ChiCC.2019.8865968/,  ""10.1109/INFOCOMTECH.2018.8722419/,  ""10.1007/978-3-030-00847-5_41/,  ""10.26634/jcom.6.1.14710/,  ""10.5772/intechopen.75433/,  ""10.1007/978-981-10-8198-9_17/,  ""10.1017/S1351324918000323/,  ""10.1007/978-3-030-02840-4_7/,  ""10.1109/ICNSC.2018.8361350/,  ""10.1109/WI.2018.00-14/,  ""10.1109/TNNLS.2018.2830761/,  ""10.1109/KSE.2018.8573420/,  ""10.1109/KSE.2018.8573336/,  ""10.1007/s11432-016-9333-4/,  ""10.1038/srep45380/,  ""10.1109/ICCTEC.2017.00141/,  ""10.1007/978-3-319-63579-8_46/,  ""10.1109/ICCCNT.2017.8204049/,  ""10.1109/TII.2017.2724769/,  ""10.1007/s10955-016-1681-y/,  ""10.1109/IALP.2017.8300593/,  ""10.1061/9780784480823.011/,  ""10.1007/s11518-017-5329-5/,  ""10.1007/978-3-662-48331-2_3/,  ""10.1016/j.procs.2016.06.080/,  ""10.1109/APSIPA.2016.7820883/,  ""10.1007/978-3-319-49685-6_32/,  ""10.1007/978-3-319-48740-3_8/,  ""10.1007/978-3-319-45814-4_17/,  ""10.1016/j.procs.2016.06.088/,  ""10.1109/TMM.2015.2510329/,  ""10.1109/APSIPA.2016.7820839/,  ""10.1109/APSIPA.2016.7820694/,  ""10.1007/978-3-319-13728-5_21/,  ""10.1109/TCYB.2014.2377154/,  ""10.1016/j.procs.2015.07.406/,  ""10.1016/j.neucom.2014.07.046/,  ""10.1109/TMM.2014.2384912/,  ""10.1038/srep09039/,  ""10.1007/978-981-10-0080-5_8/,  ""10.1109/RIOS.2015.7270733/,  ""10.1109/EICT.2015.7392016/,  ""10.1109/ICTSD.2015.7095851/,  ""10.1109/ISCID.2015.83/,  ""10.1080/08839514.2015.983014/,  ""10.1007/978-3-319-13647-9_14/,  ""10.1109/IRI.2014.7051942/,  ""10.1109/IRI.2014.7051943/,  ""10.4018/978-1-4666-5019-0.ch001/,  ""10.1007/s11571-014-9292-2/,  ""10.1109/TSMCC.2013.2258335/,  ""10.1109/BIGCOMP.2014.6741396/,  ""10.4018/978-1-4666-5019-0.ch004/,  ""10.1109/ICCIC.2014.7238566/,  ""10.1007/978-3-642-37450-0_24/,  ""10.1038/srep02993/,  ""10.1111/j.1467-8640.2012.00435.x/,  ""10.4018/ijirr.2013100102/,  ""10.1109/ICCITechn.2012.6509764/,  ""10.1007/s10115-011-0437-x/,  ""10.1007/978-3-642-30157-5_66/,  ""10.1016/j.ins.2011.04.052/,  ""10.1016/j.swevo.2011.06.006/,  ""10.1007/978-3-642-19896-0_5/,  ""10.1111/j.1467-8640.2010.00365.x/,  ""10.1002/asi.21299/,  ""10.1109/ICME.2009.5202747/,  ""10.1109/ISCIS.2009.5291878/,  ""10.1007/s13042-019-00980-z/,  ""10.1007/s12083-019-00780-w/,  ""10.1007/s00354-020-00099-8/,  ""10.1007/s10115-021-01557-5/,  ""10.1371/journal.pone.0167781/,  ""10.1088/1742-5468/2013/09/P09013/,  ""10.1007/s13369-018-3619-y/,  ""10.1007/s10844-018-0521-8/,  ""10.1111/exsy.13110/',
      group:
        "SIGIR '08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrievalJuly 2008  Pages   307–314https://doi.org/10.1145/1390334.1390387",
      year: "",
      authors: "Dingding Wang",
      doi: "10.1145/1390334.1390387",
    },
    {
      FIELD1: 139,
      id: "7EA5DD49",
      name: "A case-based approach to intelligent information retrieval",
      url: "https://dl.acm.org/doi/pdf/10.1145/215206.215364",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 140,
      id: "76A69BB9",
      name: "Jester 2.0 (poster abstract): evaluation of an new linear time collaborative filtering algorithm",
      url: "https://dl.acm.org/doi/pdf/10.1145/312624.312718",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 141,
      id: "7DCAC7DD",
      name: "Learning to cluster web search results",
      url: "https://dl.acm.org/doi/abs/10.1145/1008992.1009030",
      abstract:
        "\nOrganizing Web search results into clusters facilitates users' quick browsing through search results. Traditional clustering techniques are inadequate since they don't generate clusters with highly readable names. In this paper, we reformalize the clustering problem as a salient phrase ranking problem. Given a query and the ranked list of documents (typically a list of titles and snippets) returned by a certain Web search engine, our method first extracts and ranks salient phrases as candidate cluster names, based on a regression model learned from human labeled training data. The documents are assigned to relevant salient phrases to form candidate clusters, and the final clusters are generated by merging these candidate clusters. Experimental results verify our method's feasibility and effectiveness.\n",
      citations:
        ' ""10.1177/0165551520961035/,  ""10.1109/ComSDS52473.2021.9422848/,  ""10.1109/ICKG52313.2021.00060/,  ""10.1007/978-981-15-0077-0_12/,  ""10.1007/978-3-030-33695-0_38/,  ""10.1007/978-3-030-58334-7_4/,  ""10.1109/InCIT50588.2020.9310951/,  ""10.1007/s42979-020-00311-y/,  ""10.1109/ACCESS.2019.2962059/,  ""10.1109/ICCWAMTIP51612.2020.9317356/,  ""10.1007/978-3-030-15712-8_28/,  ""10.1007/978-3-030-01054-6_51/,  ""10.1007/978-3-319-70581-1_27/,  ""10.1007/978-3-319-69835-9_57/,  ""10.1109/ICIRCA.2018.8596765/,  ""10.1109/ICIOTA.2017.8073628/,  ""10.1007/978-3-319-66468-2_5/,  ""10.1109/CSCloud.2017.38/,  ""10.1527/tjsai.WII-G/,  ""10.1109/ICTER.2016.7829915/,  ""10.1007/978-3-319-30671-1_62/,  ""10.1007/978-3-319-46140-3_15/,  ""10.1109/ICEEOT.2016.7755581/,  ""10.1109/DSAA.2016.50/,  ""10.1109/STARTUP.2016.7583941/,  ""10.1109/ICCSNT.2015.7490802/,  ""10.1109/CISP.2015.7407866/,  ""10.1007/978-3-319-14343-9_8/,  ""10.1109/INFOP.2015.7489490/,  ""10.4018/IJITSA.2015070103/,  ""10.1109/TBDATA.2015.2451635/,  ""10.1109/EESCO.2015.7253949/,  ""10.1109/KSE.2015.47/,  ""10.1007/978-3-319-26138-6_52/,  ""10.1007/978-3-319-11933-5_4/,  ""10.1007/978-3-319-21404-7_35/,  ""10.1007/978-3-319-22047-5_35/,  ""10.1007/978-3-319-28940-3_38/,  ""10.1109/ICICES.2014.7033811/,  ""10.1109/WICT.2014.7077325/,  ""10.1109/ICASTECH.2014.7068150/,  ""10.1007/978-3-319-12580-0_18/,  ""10.1007/978-3-319-05813-9_23/,  ""10.1007/978-3-319-08156-4_6/,  ""10.1007/978-3-319-10599-4_34/,  ""10.1007/978-3-319-10554-3_26/,  ""10.1080/17517575.2013.857793/,  ""10.4018/978-1-4666-2494-8.ch013/,  ""10.4018/978-1-4666-3898-3.ch003/,  ""10.1109/ICAT.2013.6684048/,  ""10.1007/978-3-642-41360-5_24/,  ""10.1007/978-3-642-45068-6_3/,  ""10.1162/COLI_a_00148/,  ""10.1016/j.procs.2013.06.058/,  ""10.4018/978-1-4666-0330-1.ch012/,  ""10.1109/JPROC.2012.2193109/,  ""10.1109/ICSMC.2012.6378045/,  ""10.1109/ECTICon.2012.6254293/,  ""10.1007/978-3-642-32281-5_18/,  ""10.1007/978-3-642-35341-3_6/,  ""10.1007/s10115-011-0388-2/,  ""10.4018/978-1-60960-818-7.ch417/,  ""10.1016/j.proeng.2012.01.654/,  ""10.1016/j.phpro.2012.05.066/,  ""10.1109/ICCIAutom.2011.6183985/,  ""10.1109/ICSCCN.2011.6024622/,  ""10.1109/DMO.2011.5976519/,  ""10.1109/NGNS.2011.6142534/,  ""10.1109/TIE.2010.2045315/,  ""10.1109/CCIS.2011.6045023/,  ""10.1109/VCIP.2011.6115976/,  ""10.1109/ICCIAutom.2011.6183893/,  ""10.1109/FUZZY.2011.6007567/,  ""10.4018/978-1-60960-475-2.ch002/,  ""10.1016/S1876-6102(14)00454-8/,  ""10.1007/978-3-642-18440-6_12/,  ""10.1109/ICoAC.2011.6165203/,  ""10.4018/978-1-60960-475-2.ch001/,  ""10.1007/978-3-642-19460-3_4/,  ""10.1007/978-3-642-25661-5_30/,  ""10.1007/978-3-642-23765-2_13/,  ""10.1016/j.phpro.2011.11.053/,  ""10.1109/VCIP.2011.6116010/,  ""10.1108/14684521111113560/,  ""10.4018/ijirr.2011010103/,  ""10.1109/FSKD.2010.5569335/,  ""10.1109/CVPR.2010.5540046/,  ""10.1109/FSKD.2010.5569863/,  ""10.1109/JPROC.2010.2050410/,  ""10.3745/KIPSTB.2010.17B.2.177/,  ""10.1109/ICPCA.2010.5704085/,  ""10.1007/s10115-009-0227-x/,  ""10.1109/ICMLC.2009.5212332/,  ""10.1109/ICSMC.2009.5346882/,  ""10.1109/CYBERC.2009.5342183/,  ""10.1007/978-3-540-89985-3_147/,  ""10.1109/ICSMC.2009.5346100/,  ""10.1007/978-3-642-04346-8_12/,  ""10.1109/ICADIWT.2009.5273966/,  ""10.1109/ECRIME.2009.5342614/,  ""10.1109/ICME.2009.5202634/,  ""10.1109/ICME.2009.5202782/,  ""10.1007/s10115-009-0216-0/,  ""10.1007/978-3-540-85644-3_6/,  ""10.1007/978-81-8489-203-1_33/,  ""10.1109/ICSMC.2008.4811495/,  ""10.1109/ICSMC.2008.4811875/,  ""10.1109/INNOVATIONS.2008.4781642/,  ""10.1109/HSI.2008.4581524/,  ""10.1109/ICMLC.2008.4620444/,  ""10.1007/978-3-540-68125-0_35/,  ""10.1007/978-3-540-68636-1_81/,  ""10.1007/978-3-540-78646-7_56/,  ""10.1007/978-3-540-78159-2_2/,  ""10.1007/978-3-540-88192-6_69/,  ""10.1109/ICME.2007.4284635/,  ""10.1109/ICDE.2007.369029/,  ""10.1109/ICASSP.2007.366069/,  ""10.1109/ISDA.2007.126/,  ""10.1109/WI-IATW.2007.83/,  ""10.1007/s11576-007-0033-6/,  ""10.1007/978-1-4020-6268-1_40/,  ""10.1007/978-3-540-72524-4_70/,  ""10.1007/978-3-540-71701-0_48/,  ""10.1007/978-3-540-77094-7_13/,  ""10.1007/978-3-540-77094-7_19/,  ""10.1007/978-3-540-72079-9_6/,  ""10.1007/978-0-387-73742-3_12/,  ""10.1007/978-1-4020-6264-3_31/,  ""10.1007/978-1-84628-663-6_30/,  ""10.1007/978-0-387-44641-7_21/,  ""10.1080/10447310701362900/,  ""10.1108/14684520710731056/,  ""10.1109/ICCIS.2006.252315/,  ""10.1109/ICME.2006.262895/,  ""10.1109/ICCIAS.2006.295296/,  ""10.1109/ASRU.2005.1566499/,  ""10.1109/NLPKE.2005.1598800/,  ""10.1109/APSITT.2005.203656/,  ""10.1109/ICDM.2004.10027/,  ""10.1007/978-3-540-30116-5_60/,  ""10.1007/978-3-540-30116-5_48/,  ""10.29252/jsdp.14.3.65/,  ""10.1002/asi.24071/,  ""10.1007/s00530-019-00638-4/,  ""10.1007/s10115-021-01650-9/',
      group:
        "SIGIR '04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2004  Pages   210–217https://doi.org/10.1145/1008992.1009030",
      year: "",
      authors: "Hua-Jun Zeng",
      doi: "10.1145/1008992.1009030",
    },
    {
      FIELD1: 142,
      id: "76645F38",
      name: "Predicting the performance of linearly combined IR systems",
      url: "https://dl.acm.org/doi/pdf/10.1145/290941.290991",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 143,
      id: "7722ED46",
      name: "Vertical selection in the presence of unlabeled verticals",
      url: "https://dl.acm.org/doi/abs/10.1145/1835449.1835564",
      abstract:
        "\nVertical aggregation is the task of incorporating results from specialized search engines or verticals (e.g., images, video, news) into Web search results. Vertical selection is the subtask of deciding, given a query, which verticals, if any, are relevant. State of the art approaches use machine learned models to predict which verticals are relevant to a query. When trained using a large set of labeled data, a machine learned vertical selection model outperforms baselines which require no training data. Unfortunately, whenever a new vertical is introduced, a costly new set of editorial data must be gathered. In this paper, we propose methods for reusing training data from a set of existing (source) verticals to learn a predictive model for a new (target) vertical. We study methods for learning robust, portable, and adaptive cross-vertical models. Experiments show the need to focus on different types of features when maximizing portability (the ability for a single model to make accurate predictions across multiple verticals) than when maximizing adaptability (the ability for a single model to make accurate predictions for a specific vertical). We demonstrate the efficacy of our methods through extensive experimentation for 11 verticals\n",
      citations:
        ' ""10.1109/IRASET52964.2022.9737888/,  ""10.7232/JKIIE.2022.48.2.138/,  ""10.1007/978-3-030-58334-7_4/,  ""10.1016/j.procs.2019.01.021/,  ""10.1109/IJCNN.2019.8851716/,  ""10.1109/IJCNN.2019.8852468/,  ""10.1109/IJCNN.2019.8851959/,  ""10.1109/TKDE.2017.2739151/,  ""10.1007/978-3-319-06028-6_17/,  ""10.7763/IJIET.2012.V2.163/',
      group:
        "SIGIR '10: Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrievalJuly 2010  Pages   691–698https://doi.org/10.1145/1835449.1835564",
      year: "",
      authors: "Jaime Arguello",
      doi: "10.1145/1835449.1835564",
    },
    {
      FIELD1: 144,
      id: "7DBE5DB3",
      name: "Beyond independent relevance: methods and evaluation metrics for subtopic retrieval",
      url: "https://dl.acm.org/doi/abs/10.1145/2795403.2795405",
      abstract:
        "We present a non-traditional retrieval problem we call subtopic retrieval. The subtopic retrieval problem is concerned with finding documents that cover many different subtopics of a query topic. In such a problem, the utility of a document in a ranking is dependent on other documents in the ranking, violating the assumption of independent relevance which is assumed in most traditional retrieval methods. Subtopic retrieval poses challenges for evaluating performance, as well as for developing effective algorithms. We propose a framework for evaluating subtopic retrieval which generalizes the traditional precision and recall metrics by accounting for intrinsic topic difficulty as well as redundancy in documents. We propose and systematically evaluate several methods for performing subtopic retrieval using statistical language models and a maximal marginal relevance (MMR) ranking strategy. A mixture model combined with query likelihood relevance ranking is shown to modestly outperform a baseline relevance ranking on a data set used in the TREC interactive track.",
      citations:
        ' ""10.4018/IJIRR.289609/,  ""10.1007/s10915-021-01472-5/,  ""10.1109/ITCE48509.2020.9047776/,  ""10.1109/FOCS46700.2020.00059/,  ""10.1016/j.ipm.2019.01.006/,  ""10.1007/978-981-13-2354-6_1/,  ""10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00175/,  ""10.2200/S00718ED1V01Y201605ICR049/,  ""10.1007/s10791-019-09353-0/,  ""10.1007/s10706-019-01140-4/,  ""10.1007/s41060-020-00232-2/,  ""10.1007/s10618-022-00833-4/',
      group:
        "ACM SIGIR ForumVolume 49Issue 1June 2015  pp   2–9https://doi.org/10.1145/2795403.2795405",
      year: "",
      authors: "ChengXiang Zhai",
      doi: "10.1145/2795403.2795405",
    },
    {
      FIELD1: 145,
      id: "7C47E47F",
      name: "Evaluating a probabilistic model for cross-lingual information retrieval",
      url: "https://dl.acm.org/doi/abs/10.1145/383952.383968",
      abstract:
        "\nThis work proposes and evaluates a probabilistic cross-lingual retrieval system.  The system uses a generative model to estimate the probability that a document in one language is relevant, given a query in another language.  An important component of the model is translation probabilities from terms in documents to terms in a query.  Our approach is evaluated when 1) the only resource is a manually generated bilingual word list, 2) the only resource is a parallel corpus, and 3) both resources are combined in a mixture model.  The combined resources produce about 90% of monolingual performance in retrieving Chinese documents.  For Spanish the system achieves 85% of monolingual performance using only a pseudo-parallel Spanish-English corpus. Retrieval results are comparable with those of the structural query translation technique (Pirkola, 1998) when bilingual lexicons are used for query translation.  When parallel texts in addition to conventional lexicons are used, it achieves better retrieval results but requires more computation than the structural query translation technique.  It also produces slightly better results than using a machine translation system for CLIR, but the improvement over the MT system is not significant.\n",
      citations:
        ' ""10.1007/978-981-15-5554-1_2/,  ""10.1162/COLI_a_00249/,  ""10.1108/EL-08-2011-0126/,  ""10.1007/978-3-642-33486-3_19/,  ""10.1007/978-3-642-22543-7_73/,  ""10.1007/978-3-642-17187-1_17/,  ""10.1007/978-1-84800-330-9_16/,  ""10.1109/ICICISYS.2009.5358121/,  ""10.1109/ISCIS.2009.5291896/,  ""10.1109/ICMLC.2008.4620845/,  ""10.1109/ICMLC.2007.4370744/,  ""10.1016/j.iilr.2005.05.002/,  ""10.1080/10572317.2005.10762671/,  ""10.7202/1029496ar/,  ""10.1007/978-3-540-27859-7_33/,  ""10.1109/ICDE.2003.1260777/,  ""10.1007/978-3-540-45237-9_8/,  ""10.1007/978-94-017-0171-6_2/,  ""10.1007/s10791-020-09372-2/,  ""10.1007/s11042-020-10305-w/',
      group:
        "SIGIR '01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrievalSeptember 2001  Pages   105–110https://doi.org/10.1145/383952.383968",
      year: "",
      authors: "Jinxi Xu",
      doi: "10.1145/383952.383968",
    },
    {
      FIELD1: 146,
      id: "8051956C",
      name: "User modeling for full-text federated search in peer-to-peer networks",
      url: "https://dl.acm.org/doi/abs/10.1145/1148170.1148229",
      abstract:
        "\nUser modeling for information retrieval has mostly been studied to improve the effectiveness of information access in centralized repositories. In this paper we explore user modeling in the context of full-text federated search in peer-to-peer networks. Our approach models a user's persistent, long-term interests based on past queries, and uses the model to improve search efficiency for future queries that represent interests similar to past queries. Our approach also enables queries representing a user's transient, ad-hoc interests to be automatically recognized so that search for these queries can rely on a relatively large search radius to avoid sacrificing effectiveness for efficiency. Experimental results demonstrate that our approach can significantly improve the efficiency of full-text federated search without degrading its accuracy. Furthermore, the proposed approach does not require a large amount of training data, and is robust to a range of parameter values.\n",
      citations:
        ' ""10.1080/1206212X.2020.1859245/,  ""10.1109/ICCSN.2018.8488222/,  ""10.1109/CONTROLO.2018.8439791/,  ""10.1109/RCIS.2015.7128883/,  ""10.1007/978-3-642-40173-2_29/,  ""10.1007/978-3-642-38844-6_21/,  ""10.1002/asi.22904/,  ""10.4018/978-1-4666-0330-1.ch002/,  ""10.1145/2180868.2180871/,  ""10.1527/tjsai.26.97/,  ""10.1007/978-3-642-21353-3_11/,  ""10.1109/ICME.2010.5582934/,  ""10.1007/978-0-387-77672-9_12/,  ""10.1109/IPDPS.2007.370269/,  ""10.1109/P2P.2007.22/,  ""10.1109/ISI.2007.379547/',
      group:
        "SIGIR '06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2006  Pages   332–339https://doi.org/10.1145/1148170.1148229",
      year: "",
      authors: "Jie Lu",
      doi: "10.1145/1148170.1148229",
    },
    {
      FIELD1: 147,
      id: "7ABA248D",
      name: "Hierarchical neural networks for text categorization (poster abstract)",
      url: "https://dl.acm.org/doi/pdf/10.1145/312624.312700",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 148,
      id: "7F8DBD08",
      name: "Generic soft pattern models for definitional question answering",
      url: "https://dl.acm.org/doi/abs/10.1145/1076034.1076101",
      abstract:
        "\nThis paper explores probabilistic lexico-syntactic pattern matching, also known as soft pattern matching. While previous methods in soft pattern matching are ad hoc in computing the degree of match, we propose two formal matching models: one based on bigrams and the other on the Profile Hidden Markov Model (PHMM). Both models provide a theoretically sound method to model pattern matching as a probabilistic process that generates token sequences. We demonstrate the effectiveness of these models on definition sentence retrieval for definitional question answering. We show that both models significantly outperform state-of-the-art manually constructed patterns. A critical difference between the two models is that the PHMM technique handles language variations more effectively but requires more training data to converge. We believe that both models can be extended to other areas where lexico-syntactic pattern matching can be applied.\n",
      citations:
        ' ""10.1007/978-981-15-1097-7_10/,  ""10.1007/978-3-319-25816-4_26/,  ""10.1016/j.ipm.2015.04.005/,  ""10.1007/978-3-319-07983-7_10/,  ""10.1007/978-3-642-45358-8_11/,  ""10.1007/978-3-642-28569-1_7/,  ""10.1007/978-3-642-34456-5_24/,  ""10.1007/978-3-642-23708-9_10/,  ""10.1108/14684521111161927/,  ""10.1108/00220411011038485/,  ""10.1111/j.1471-1842.2010.00896.x/,  ""10.1109/CCPR.2009.5344021/,  ""10.1109/CCPR.2009.5344145/,  ""10.1109/ICME.2007.4284776/,  ""10.1007/978-3-540-74999-8_47/,  ""10.1007/978-3-540-71496-5_23/,  ""10.4028/www.scientific.net/KEM.460-461.130/',
      group:
        "SIGIR '05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2005  Pages   384–391https://doi.org/10.1145/1076034.1076101",
      year: "",
      authors: "Hang Cui",
      doi: "10.1145/1076034.1076101",
    },
    {
      FIELD1: 149,
      id: "7ACC689A",
      name: "Training algorithms for linear text classifiers",
      url: "https://dl.acm.org/doi/pdf/10.1145/243199.243277",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 150,
      id: "7B9A7E21",
      name: "Evaluating evaluation measure stability",
      url: "https://dl.acm.org/doi/abs/10.1145/3130348.3130373",
      abstract:
        "This paper presents a novel way of examining the accuracy of the evaluation measures commonly used in information retrieval experiments. It validates several of the rules-of-thumb experimenters use, such as the number of queries needed for a good experiment is at least 25 and 50 is better, while challenging other beliefs, such as the common evaluation measures are equally reliable. As an example, we show that Precision at 30 documents has about twice the average error rate as Average Precision has. These results can help information retrieval researchers design experiments that provide a desired level of confidence in their results. In particular, we suggest researchers using Web measures such as Precision at 10 documents will need to use many more than 50 queries or will have to require two methods to have a very large difference in evaluation scores before concluding that the two methods are actually different.",
      citations:
        ' ""10.1007/s12046-021-01731-z/,  ""10.1016/j.inpa.2022.03.004/,  ""10.3934/mbe.2022273/,  ""10.1007/978-3-031-16474-3_64/,  ""10.1007/s11263-021-01443-1/,  ""10.1109/I-SMAC.2018.8653683/,  ""10.4000/questionsdecommunication.672/',
      group:
        "ACM SIGIR ForumVolume 51Issue 2July 2017  pp   235–242https://doi.org/10.1145/3130348.3130373",
      year: "",
      authors: "Chris Buckley",
      doi: "10.1145/3130348.3130373",
    },
    {
      FIELD1: 151,
      id: "7868D94E",
      name: "Dynamicity vs. effectiveness: studying online clustering for scatter/gather",
      url: "https://dl.acm.org/doi/abs/10.1145/1571941.1571947",
      abstract:
        "\nWe proposed and implemented a novel clustering algorithm called LAIR2, which has constant running time average for on-the-fly Scatter/Gather browsing [4]. Our experiments showed that when running on a single processor, the LAIR2 on-line clustering algorithm was several hundred times faster than a parallel Buckshot algorithm running on multiple processors [11]. This paper reports on a study that examined the effectiveness of the LAIR2 algorithm in terms of clustering quality and its impact on retrieval performance. We conducted a user study on 24 subjects to evaluate on-the-fly LAIR2 clustering in Scatter/Gather search tasks by comparing its performance to the Buckshot algorithm, a classic method for Scatter/Gather browsing [4]. Results showed significant differences in terms of subjective perceptions of clustering quality. Subjects perceived that the LAIR2 algorithm produced significantly better quality clusters than the Buckshot method did. Subjects felt that it took less effort to complete the tasks with the LAIR2 system, which was more effective in helping them in the tasks. Interesting patterns also emerged from subjects' comments in the final open-ended questionnaire. We discuss implications and future research.\n",
      citations:
        ' ""10.1109/BIBM47256.2019.8983328/,  ""10.4018/978-1-5225-5191-1.ch003/,  ""10.1109/TBDATA.2016.2641460/,  ""10.4018/978-1-5225-0536-5.ch013/,  ""10.1162/COLI_a_00148/,  ""10.4018/978-1-4666-0330-1.ch002/,  ""10.1007/978-1-4614-3223-4_4/,  ""10.1002/meet.14504901139/,  ""10.1002/meet.14504901328/,  ""10.1109/DBTA.2010.5659018/,  ""10.1109/NAFIPS.2010.5548181/',
      group:
        "SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrievalJuly 2009  Pages   19–26https://doi.org/10.1145/1571941.1571947",
      year: "",
      authors: "Weimao Ke",
      doi: "10.1145/1571941.1571947",
    },
    {
      FIELD1: 152,
      id: "7B31E378",
      name: "Evaluating high accuracy retrieval techniques",
      url: "https://dl.acm.org/doi/abs/10.1145/1008992.1008996",
      abstract:
        "\nAlthough information retrieval research has always been concerned with improving the effectiveness of search, in some applications, such as information analysis, a more specific requirement exists for high accuracy retrieval. This means that achieving high precision in the top document ranks is paramount. In this paper we present work aimed at achieving high accuracy in ad-hoc document retrieval by incorporating approaches from question answering(QA). We focus on getting the first relevant result as high as possible in the ranked list and argue that traditional precision and recall are not appropriate measures for evaluatin this task. We instead use the mean reciprocal rank(MRR) of the first relevant result. We evaluate three different methods for modifying queries to achieve high accuracy. The experiments done on TREC data provide support for the approach of using MRR and incorporating QA techniques for getting high accuracy in ad-hoc retrieval task.\n",
      citations:
        ' ""10.1007/s11704-018-7283-x/,  ""10.1108/EL-12-2019-0296/,  ""10.1109/TVCG.2018.2834341/,  ""10.1002/asi.23072/,  ""10.1002/meet.14505001052/,  ""10.1109/CISE.2009.5362743/,  ""10.1109/ICICISYS.2009.5358088/,  ""10.1109/CISE.2009.5366092/,  ""10.1109/CISE.2009.5362586/,  ""10.1007/s11704-007-0007-2/,  ""10.4304/jmm.9.5.652-659/',
      group:
        "SIGIR '04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2004  Pages   2–9https://doi.org/10.1145/1008992.1008996",
      year: "",
      authors: "Chirag Shah",
      doi: "10.1145/1008992.1008996",
    },
    {
      FIELD1: 153,
      id: "7FA844BE",
      name: "Text categorization by boosting automatically extracted concepts",
      url: "https://dl.acm.org/doi/abs/10.1145/860435.860470",
      abstract:
        "\nTerm-based representations of documents have found wide-spread use in information retrieval. However, one of the main shortcomings of such methods is that they largely disregard lexical semantics and, as a consequence, are not sufficiently robust with respect to variations in word usage.In this paper we investigate the use of concept-based document representations to supplement word- or phrase-based features. The utilized concepts are automatically extracted from documents via probabilistic latent semantic analysis. We propose to use AdaBoost to optimally combine weak hypotheses based on both types of features. Experimental results on standard benchmarks confirm the validity of our approach, showing that AdaBoost achieves consistent improvements by including additional semantic features in the learned ensemble.\n",
      citations:
        ' ""10.1002/int.22508/,  ""10.4018/IJIIT.2020040104/,  ""10.1109/ACCESS.2019.2921976/,  ""10.1007/978-3-030-11027-7_12/,  ""10.1109/ICNIDC.2018.8525817/,  ""10.1109/ACCESS.2018.2882878/,  ""10.1109/ICACCI.2017.8125868/,  ""10.1109/WISA.2017.44/,  ""10.1109/ISCMI.2016.31/,  ""10.1007/978-3-319-46298-1_8/,  ""10.4236/jdaip.2015.34014/,  ""10.1016/j.eswa.2014.09.031/,  ""10.1109/TNNLS.2014.2299806/,  ""10.1109/ICInfA.2013.6720444/,  ""10.1007/978-3-642-31552-7_32/,  ""10.1007/s10115-011-0403-7/,  ""10.1007/978-3-642-18452-9_17/,  ""10.1201/EBK1439822876-b1/,  ""10.1109/ICIEA.2010.5514692/,  ""10.1109/DEST.2009.5276756/,  ""10.4018/978-1-60566-010-3.ch271/,  ""10.1109/IJCNN.2008.4633926/,  ""10.1007/978-3-540-71233-6_33/,  ""10.1007/978-3-540-75696-5_9/,  ""10.1007/3-540-31314-1_40/,  ""10.1108/00220410610666501/,  ""10.3182/20060517-3-FR-2903.00339/,  ""10.1109/ICDM.2004.10077/,  ""10.2139/ssrn.3199170/,  ""10.1007/s11277-021-08331-4/',
      group:
        "SIGIR '03: Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrievalJuly 2003  Pages   182–189https://doi.org/10.1145/860435.860470",
      year: "",
      authors: "Lijuan Cai",
      doi: "10.1145/860435.860470",
    },
    {
      FIELD1: 154,
      id: "7EF01968",
      name: "Hidden Markov models for automatic annotation and content-based retrieval of images and video",
      url: "https://dl.acm.org/doi/abs/10.1145/1076034.1076127",
      abstract:
        "\nThis paper introduces a novel method for automatic annotation of images with keywords from a generic vocabulary of concepts or objects for the purpose of content-based image retrieval. An image, represented as sequence of feature-vectors characterizing low-level visual features such as color, texture or oriented-edges, is modeled as having been stochastically generated by a hidden Markov model, whose states represent concepts. The parameters of the model are estimated from a set of manually annotated (training) images. Each image in a large test collection is then automatically annotated with the a posteriori probability of concepts present in it. This annotation supports content-based search of the image-collection via keywords. Various aspects of model parameterization, parameter estimation, and image annotation are discussed. Empirical retrieval results are presented on two image-collections | COREL and key-frames from TRECVID. Comparisons are made with two other recently developed techniques on the same datasets.\n",
      citations:
        ' ""10.1007/978-3-658-03765-9_21/,  ""10.1016/B978-0-12-802045-6.00021-1/,  ""10.1109/ICCSE.2014.6926631/,  ""10.1109/ICCWAMTIP.2014.7073412/,  ""10.1109/ICCSE.2014.6926548/,  ""10.1201/b17080-21/,  ""10.1007/978-3-319-07773-4_37/,  ""10.1007/978-3-658-03895-3_21-1/,  ""10.4018/978-1-60960-818-7.ch417/,  ""10.1109/ICCSE.2012.6295027/,  ""10.4018/978-1-61350-126-9.ch005/,  ""10.4018/978-1-4666-0900-6.ch011/,  ""10.1007/978-3-642-19282-1_10/,  ""10.1007/s00138-009-0217-8/,  ""10.1007/978-3-642-13467-8_14/,  ""10.1109/ICIP.2009.5419128/,  ""10.1109/ICIINFS.2009.5429827/,  ""10.4018/978-1-60566-026-4.ch385/,  ""10.1007/978-3-540-75171-7_9/,  ""10.1007/978-3-540-78646-7_66/,  ""10.1109/TMM.2008.2007290/,  ""10.1109/ICME.2007.4284733/,  ""10.1109/ICASSP.2006.1660297/,  ""10.1007/11957959_14/,  ""10.1007/0-387-34224-9_66/,  ""10.1007/s00521-019-04114-y/,  ""10.1007/s11042-020-08862-1/',
      group:
        "SIGIR '05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2005  Pages   544–551https://doi.org/10.1145/1076034.1076127",
      year: "",
      authors: "Arnab Ghoshal",
      doi: "10.1145/1076034.1076127",
    },
    {
      FIELD1: 155,
      id: "7DD1A5C9",
      name: "Using bayesian priors to combine classifiers for adaptive filtering",
      url: "https://dl.acm.org/doi/abs/10.1145/1008992.1009052",
      abstract:
        "\nAn adaptive information filtering system monitors a document stream to identify the documents that match information needs specified by user profiles. As the system filters, it also refines its knowledge about the user's information needs based on long-term observations of the document stream and periodic feedback(training data) from the user. Low variance profile learning algorithms, such as Rocchio, work well at the early stage of filtering when the system has very few training data. Low bias profile learning algorithms, such as Logistic Regression, work well at the later stage of filtering when the system has accumulated enough training data.However, an empirical system needs to works well consistently at all stages of filtering process. This paper addresses this problem by proposing a new technique to combine different text classification algorithms via a constrained maximum likelihood Bayesian prior. This technique provides a trade off between bias and variance, and the combined classifier may achieve a consistent good performance at different stages of filtering. We implemented the proposed technique to combine two complementary classification algorithms: Rocchio and logistic regression. The new algorithm is shown to compare favorably with Rocchio, Logistic Regression, and the best methods in the TREC-9 and TREC-11 adaptive filtering tracks.\n",
      citations:
        ' ""10.3233/IDA-200006/,  ""10.1007/978-3-030-33904-3_8/,  ""10.3233/JIFS-169486/,  ""10.2200/S00718ED1V01Y201605ICR049/,  ""10.1007/978-3-319-28940-3_24/,  ""10.1007/978-3-642-25658-5_15/,  ""10.1007/s11721-010-0044-6/',
      group:
        "SIGIR '04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2004  Pages   345–352https://doi.org/10.1145/1008992.1009052",
      year: "",
      authors: "Yi Zhang",
      doi: "10.1145/1008992.1009052",
    },
    {
      FIELD1: 156,
      id: "79CA2BA6",
      name: "A parallel derivation of probabilistic information retrieval models",
      url: "https://dl.acm.org/doi/abs/10.1145/1148170.1148192",
      abstract:
        "\nThis paper investigates in a stringent athematical formalism the parallel derivation of three grand probabilistic retrieval models: binary independent retrieval (BIR), Poisson model (PM), and language modelling (LM).The investigation has been motivated by a number of questions. Firstly, though sharing the same origin, namely the probability of relevance, the models differ with respect to event spaces. How can this be captured in a consistent notation, and can we relate the event spaces? Secondly, BIR and PM are closely related, but how does LM fit in? Thirdly, how are tf-idf and probabilistic models related? .The parallel investigation of the models leads to a number of formalised results: BIR and PM assume the collection to be a set of non-relevant documents, whereas LM assumes the collection to be a set of terms from relevant documents.PM can be viewed as a bridge connecting BIR and LM.A BIR-LM equivalence explains BIR as a special LM case.PM explains tf-idf, and both, BIR and LM probabilities express tf-idf in a dual way..\n",
      citations:
        ' ""10.31168/2305-6754.2020.9.1.2/,  ""10.1007/978-1-4899-7993-3_919-2/,  ""10.1093/comjnl/bxv031/,  ""10.2200/S00494ED1V01Y201304ICR027/,  ""10.1002/asi.21158/,  ""10.1007/978-0-387-39940-9_919/,  ""10.1007/978-3-540-78646-7_79/',
      group:
        "SIGIR '06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2006  Pages   107–114https://doi.org/10.1145/1148170.1148192",
      year: "",
      authors: "Thomas Roelleke",
      doi: "10.1145/1148170.1148192",
    },
    {
      FIELD1: 157,
      id: "7DC501D5",
      name: "On scaling latent semantic indexing for large peer-to-peer systems",
      url: "https://dl.acm.org/doi/abs/10.1145/1008992.1009014",
      abstract:
        "\nThe exponential growth of data demands scalable infrastructures capable of indexing and searching rich content such as text, music, and images. A promising direction is to combine information re-trieval with peer-to-peer technology for scalability, fault-tolerance, and low administration cost. One pioneering work along this di-rection is pSearch [32, 33]. pSearch places documents onto a peer-to- peer overlay network according to semantic vectors produced using Latent Semantic Indexing (LSI). The search cost for a query is reduced since documents related to the query are likely to be co-located on a small number of nodes. Unfortunately, because of its reliance on LSI, pSearch also inherits the limitations of LSI. (1) When the corpus is large and heterogeneous, LSI's retrieval quality is inferior to methods such as Okapi. (2) The Singular Value Decomposition (SVD) used in LSI is unscalable in terms of both memory consumption and computation time.This paper addresses the above limitations of LSI and makes the following contributions. (1) To reduce the cost of SVD, we reduce the size of its input matrix through document clustering and term selection. Our method retains the retrieval quality of LSI but is several orders of magnitude more efficient. (2) Through extensive experimentation, we found that proper normalization of semantic vectors for terms and documents improves recall by 76%. (3) To further improve retrieval quality, we use low-dimensional subvectors of semantic vectors to cluster documents in the overlay and then use Okapi to guide the search and document selection.\n",
      citations:
        ' ""10.1007/978-981-13-2721-6_8/,  ""10.1007/978-981-10-0534-3_31/,  ""10.1109/ICOSC.2015.7050813/,  ""10.1109/TC.2013.110/,  ""10.1007/978-3-642-32891-6_25/,  ""10.1109/ICMSS.2011.5999091/,  ""10.1109/NOTERE.2011.5957990/,  ""10.1109/ITSIM.2010.5561613/,  ""10.1109/ICDIM.2008.4746764/,  ""10.1109/ICDE.2007.368969/,  ""10.1016/j.is.2006.09.004/,  ""10.1109/ICC.2006.254700/,  ""10.1007/978-3-540-31842-2_15/',
      group:
        "SIGIR '04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2004  Pages   112–121https://doi.org/10.1145/1008992.1009014",
      year: "",
      authors: "Chunqiang Tang",
      doi: "10.1145/1008992.1009014",
    },
    {
      FIELD1: 158,
      id: "799D1559",
      name: "Inferring probability of relevance using the method of logistic regression",
      url: "https://link.springer.com/chapter/10.1007/978-1-4471-2099-5_23",
      abstract: "",
      citations: "",
      group: "",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 159,
      id: "758CBA13",
      name: "A collaborative filtering algorithm and evaluation metric that accurately model the user experience",
      url: "https://dl.acm.org/doi/abs/10.1145/1008992.1009050",
      abstract:
        "\nCollaborative Filtering (CF) systems have been researched for over a decade as a tool to deal with information overload. At the heart of these systems are the algorithms which generate the predictions and recommendations.In this article we empirically demonstrate that two of the most acclaimed CF recommendation algorithms have flaws that result in a dramatically unacceptable user experience.In response, we introduce a new Belief Distribution Algorithm that overcomes these flaws and provides substantially richer user modeling. The Belief Distribution Algorithm retains the qualities of nearest-neighbor algorithms which have performed well in the past, yet produces predictions of belief distributions across rating values rather than a point rating value.In addition, we illustrate how the exclusive use of the mean absolute error metric has concealed these flaws for so long, and we propose the use of a modified Precision metric for more accurately evaluating the user experience.\n",
      citations:
        ' ""10.1109/TSC.2020.2977018/,  ""10.1007/978-1-0716-2197-4_15/,  ""10.1142/S0218126622300070/,  ""10.1016/j.eswa.2021.115482/,  ""10.1109/SACI51354.2021.9465626/,  ""10.1109/ACCESS.2021.3124939/,  ""10.1016/j.ins.2020.06.067/,  ""10.1007/978-981-13-6504-1_78/,  ""10.1109/TKDE.2018.2879658/,  ""10.1109/ACCESS.2020.2979777/,  ""10.1109/ICCSEA49143.2020.9132845/,  ""10.1002/9781119711582.ch1/,  ""10.1631/FITEE.1900382/,  ""10.1007/978-3-030-11928-7_30/,  ""10.1109/COMPSAC.2019.00036/,  ""10.1186/s13638-019-1525-y/,  ""10.1007/978-3-030-34223-4_13/,  ""10.23919/SOFTCOM.2019.8903913/,  ""10.1007/978-1-4939-7131-2_110158/,  ""10.1007/s00170-017-0662-x/,  ""10.1007/978-1-4939-7131-2_110162/,  ""10.4018/978-1-5225-4191-2.ch010/,  ""10.1007/978-3-319-74521-3_15/,  ""10.1109/TSC.2016.2589244/,  ""10.1109/ICACCCN.2018.8748693/,  ""10.1109/ICIS.2017.7960088/,  ""10.1007/978-1-4614-7163-9_110158-1/,  ""10.1007/978-3-319-41163-7_6/,  ""10.1007/978-1-4614-7163-9_110162-1/,  ""10.1016/j.jpdc.2017.09.014/,  ""10.1109/IISA.2017.8316436/,  ""10.1007/978-3-319-42092-9_35/,  ""10.1109/ACIT-CSII-BCD.2016.075/,  ""10.1007/978-3-319-30671-1_44/,  ""10.1007/978-3-319-42297-8_75/,  ""10.1587/transinf.2015EDP7380/,  ""10.1109/TSC.2015.2433251/,  ""10.1109/ICWS.2016.34/,  ""10.1109/ISCIT.2016.7751627/,  ""10.1108/K-09-2015-0236/,  ""10.1109/MDM.2016.16/,  ""10.1007/978-3-319-41357-0_4/,  ""10.1109/BESC.2015.7365976/,  ""10.1007/978-3-319-25840-9_6/,  ""10.1109/TICST.2015.7369388/,  ""10.1109/ICMTMA.2015.338/,  ""10.1109/ISCID.2015.154/,  ""10.1007/978-1-4899-7637-6_11/,  ""10.1007/978-1-4899-7637-6_8/,  ""10.1007/978-1-4899-7637-6_7/,  ""10.1007/978-3-319-26555-1_41/,  ""10.1007/s13278-014-0207-3/,  ""10.1109/ICDMW.2014.27/,  ""10.1109/MPRV.2014.80/,  ""10.1007/978-1-4614-7518-7_22/,  ""10.1007/s11390-014-1412-2/,  ""10.1109/TSMCB.2012.2231411/,  ""10.1007/s11257-012-9129-9/,  ""10.4018/japuc.2013040106/,  ""10.1109/ISTEL.2012.6483164/,  ""10.1109/GLOCOM.2012.6503973/,  ""10.1007/978-3-642-34752-8_32/,  ""10.2200/S00414ED1V01Y201204DTM025/,  ""10.4018/japuc.2012070103/,  ""10.1109/SafeConfig.2011.6111675/,  ""10.1109/ISDA.2011.6121638/,  ""10.1109/INFCOM.2011.5935222/,  ""10.1109/ICCRD.2011.5764131/,  ""10.1007/978-0-387-85820-3_2/,  ""10.1109/FSKD.2010.5569294/,  ""10.1007/978-3-642-17537-4_49/,  ""10.1109/IJCNN.2009.5178967/,  ""10.1109/ICDIM.2007.4444225/,  ""10.1007/978-3-540-72079-9_9/,  ""10.1007/978-3-540-77226-2_67/,  ""10.1007/978-3-540-77485-3_3/,  ""10.1007/1-84628-290-X_6/,  ""10.1080/10106049.2018.1493155/,  ""10.1007/s10845-018-1409-8/,  ""10.1007/s13369-019-04180-3/,  ""10.31590/ejosat.822968/,  ""10.1371/journal.pone.0248695/,  ""10.1007/s41019-020-00138-w/',
      group:
        "SIGIR '04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrievalJuly 2004  Pages   329–336https://doi.org/10.1145/1008992.1009050",
      year: "",
      authors: "Matthew R. McLaughlin",
      doi: "10.1145/1008992.1009050",
    },
    {
      FIELD1: 160,
      id: "75349D25",
      name: "Building a test collection for complex document information processing",
      url: "https://dl.acm.org/doi/abs/10.1145/1148170.1148307",
      abstract:
        "\nResearch and development of information access technology for scanned paper documents has been hampered by the lack of public test collections of realistic scope and complexity. As part of a project to create a prototype system for search and mining of masses of document images, we are assembling a 1.5 terabyte dataset to support evaluation of both end-to-end complex document information processing (CDIP) tasks (e.g., text retrieval and data mining) as well as component technologies such as optical character recognition (OCR), document structure analysis, signature matching, and authorship attribution.\n",
      citations:
        ' ""10.1007/978-3-031-06430-2_21/,  ""10.1007/978-3-031-06555-2_8/,  ""10.1109/CVPRW56347.2022.00320/,  ""10.1109/CVPRW56347.2022.00564/,  ""10.1007/978-3-031-13643-6_8/,  ""10.18287/2412-6179-CO-1020/,  ""10.1007/978-3-030-86159-9_30/,  ""10.1007/978-3-030-86159-9_33/,  ""10.1007/978-3-030-86337-1_42/,  ""10.1007/978-3-030-86549-8_34/,  ""10.1007/978-3-030-85713-4_19/,  ""10.1109/CVPR46437.2021.00560/,  ""10.1109/ICCV48922.2021.00103/,  ""10.1109/TPAMI.2021.3055337/,  ""10.1007/978-3-030-50417-5_29/,  ""10.1007/978-3-030-51935-3_35/,  ""10.1109/CVPRW50498.2020.00412/,  ""10.1109/CVPR42600.2020.01435/,  ""10.1109/ICIEVicIVPR48672.2020.9306532/,  ""10.1109/TIP.2019.2946979/,  ""10.1109/TPDS.2019.2934683/,  ""10.1007/978-3-030-23987-9_7/,  ""10.1007/978-3-030-29888-3_4/,  ""10.1007/978-3-030-30645-8_14/,  ""10.1007/978-3-030-30645-8_25/,  ""10.1109/IJCNN.2019.8852197/,  ""10.1109/ICDARW.2019.40079/,  ""10.1109/CBMI.2018.8516532/,  ""10.1007/s13369-018-3365-1/,  ""10.1016/j.aej.2017.06.010/,  ""10.1007/978-981-10-7898-9_1/,  ""10.1109/ACCESS.2018.2795104/,  ""10.1109/ICPR.2018.8546235/,  ""10.1109/SIU.2017.7960562/,  ""10.1109/ICCSP.2017.8286476/,  ""10.1007/978-3-319-68548-9_5/,  ""10.1007/978-3-319-48680-2_38/,  ""10.1109/ICPR.2016.7900112/,  ""10.1109/ICPR.2016.7899812/,  ""10.1109/TIP.2015.2465145/,  ""10.1109/RIVF.2015.7049880/,  ""10.1007/978-3-642-19231-9_8/,  ""10.1007/978-3-642-17934-1_3/,  ""10.1109/CVPR.2007.383200/,  ""10.1109/ICDAR.2007.4377038/,  ""10.1109/CVPR.2007.383255/,  ""10.1007/s10579-019-09476-2/,  ""10.1007/s11554-018-0756-1/,  ""10.1007/s10032-021-00370-8/,  ""10.3390/app12031457/,  ""10.1007/s10032-022-00406-7/',
      group:
        "SIGIR '06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2006  Pages   665–666https://doi.org/10.1145/1148170.1148307",
      year: "",
      authors: "D. Lewis",
      doi: "10.1145/1148170.1148307",
    },
    {
      FIELD1: 161,
      id: "78118BFA",
      name: "Some simple effective approximations to the 2-Poisson model for probabilistic weighted retrieval",
      url: "https://link.springer.com/chapter/10.1007/978-1-4471-2099-5_24",
      abstract: "",
      citations: "",
      group:
        "SIGIR '02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2002  Pages   199–206https://doi.org/10.1145/564376.564412",
      year: "",
      authors: "",
      doi: "",
    },
    {
      FIELD1: 162,
      id: "76A00DCE",
      name: "Properties of extended Boolean models in information retrieval",
      url: "https://link.springer.com/chapter/10.1007/978-1-4471-2099-5_19",
      abstract: "",
      citations: "",
      group:
        "SIGIR '02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrievalAugust 2002  Pages   199–206https://doi.org/10.1145/564376.564412",
      year: "",
      authors: "",
      doi: "",
    },
  ],
  links: [
    { source: 1, target: 0, value: 1 },
    { source: 2, target: 0, value: 8 },
    { source: 3, target: 0, value: 10 },
    { source: 3, target: 2, value: 6 },
    { source: 4, target: 0, value: 1 },
    { source: 5, target: 0, value: 1 },
    { source: 6, target: 0, value: 1 },
    { source: 7, target: 0, value: 1 },
    { source: 8, target: 0, value: 2 },
    { source: 9, target: 0, value: 1 },
    { source: 11, target: 10, value: 1 },
    { source: 11, target: 3, value: 3 },
    { source: 11, target: 2, value: 3 },
    { source: 11, target: 0, value: 5 },
    { source: 12, target: 11, value: 1 },
    { source: 13, target: 11, value: 1 },
    { source: 14, target: 11, value: 1 },
    { source: 15, target: 11, value: 1 },
    { source: 17, target: 16, value: 4 },
    { source: 18, target: 16, value: 4 },
    { source: 18, target: 17, value: 4 },
    { source: 19, target: 16, value: 4 },
    { source: 19, target: 17, value: 4 },
    { source: 19, target: 18, value: 4 },
    { source: 20, target: 16, value: 3 },
    { source: 20, target: 17, value: 3 },
    { source: 20, target: 18, value: 3 },
    { source: 20, target: 19, value: 4 },
    { source: 21, target: 16, value: 3 },
    { source: 21, target: 17, value: 3 },
    { source: 21, target: 18, value: 3 },
    { source: 21, target: 19, value: 3 },
    { source: 21, target: 20, value: 5 },
    { source: 22, target: 16, value: 3 },
    { source: 22, target: 17, value: 3 },
    { source: 22, target: 18, value: 3 },
    { source: 22, target: 19, value: 3 },
    { source: 22, target: 20, value: 4 },
    { source: 22, target: 21, value: 4 },
    { source: 23, target: 16, value: 3 },
    { source: 23, target: 17, value: 3 },
    { source: 23, target: 18, value: 3 },
    { source: 23, target: 19, value: 3 },
    { source: 23, target: 20, value: 4 },
    { source: 23, target: 21, value: 4 },
    { source: 23, target: 22, value: 4 },
    { source: 23, target: 12, value: 2 },
    { source: 23, target: 11, value: 9 },
    { source: 24, target: 23, value: 2 },
    { source: 24, target: 11, value: 7 },
    { source: 25, target: 24, value: 13 },
    { source: 25, target: 23, value: 1 },
    { source: 25, target: 11, value: 12 },
    { source: 26, target: 24, value: 4 },
    { source: 26, target: 11, value: 31 },
    { source: 26, target: 16, value: 1 },
    { source: 26, target: 25, value: 1 },
    { source: 27, target: 11, value: 17 },
    { source: 27, target: 23, value: 5 },
    { source: 27, target: 25, value: 5 },
    { source: 27, target: 24, value: 1 },
    { source: 27, target: 26, value: 1 },
    { source: 28, target: 11, value: 8 },
    { source: 28, target: 27, value: 1 },
    { source: 29, target: 23, value: 1 },
    { source: 29, target: 27, value: 1 },
    { source: 29, target: 11, value: 2 },
    { source: 30, target: 23, value: 1 },
    { source: 31, target: 30, value: 2 },
    { source: 31, target: 11, value: 3 },
    { source: 31, target: 23, value: 2 },
    { source: 31, target: 27, value: 1 },
    { source: 32, target: 11, value: 1 },
    { source: 33, target: 11, value: 2 },
    { source: 33, target: 27, value: 1 },
    { source: 34, target: 11, value: 3 },
    { source: 34, target: 29, value: 2 },
    { source: 35, target: 11, value: 3 },
    { source: 35, target: 34, value: 3 },
    { source: 35, target: 29, value: 2 },
    { source: 36, target: 34, value: 2 },
    { source: 36, target: 35, value: 2 },
    { source: 36, target: 11, value: 2 },
    { source: 36, target: 29, value: 1 },
    { source: 37, target: 34, value: 2 },
    { source: 37, target: 123, value: 2 },
    { source: 37, target: 36, value: 2 },
    { source: 37, target: 11, value: 2 },
    { source: 37, target: 29, value: 1 },
    { source: 38, target: 34, value: 2 },
    { source: 38, target: 35, value: 2 },
    { source: 38, target: 36, value: 2 },
    { source: 38, target: 37, value: 2 },
    { source: 38, target: 11, value: 2 },
    { source: 38, target: 29, value: 1 },
    { source: 39, target: 25, value: 1 },
    { source: 40, target: 25, value: 1 },
    { source: 41, target: 24, value: 2 },
    { source: 41, target: 25, value: 3 },
    { source: 42, target: 41, value: 2 },
    { source: 42, target: 25, value: 2 },
    { source: 42, target: 24, value: 1 },
    { source: 43, target: 11, value: 3 },
    { source: 43, target: 26, value: 1 },
    { source: 43, target: 27, value: 1 },
    { source: 44, target: 28, value: 3 },
    { source: 44, target: 11, value: 1 },
    { source: 45, target: 28, value: 2 },
    { source: 47, target: 46, value: 1 },
    { source: 48, target: 47, value: 2 },
    { source: 48, target: 25, value: 1 },
    { source: 48, target: 27, value: 1 },
    { source: 48, target: 11, value: 1 },
    { source: 49, target: 26, value: 3 },
    { source: 49, target: 11, value: 2 },
    { source: 50, target: 49, value: 1 },
    { source: 50, target: 24, value: 1 },
    { source: 51, target: 49, value: 9 },
    { source: 51, target: 26, value: 2 },
    { source: 51, target: 11, value: 2 },
    { source: 52, target: 51, value: 1 },
    { source: 52, target: 39, value: 1 },
    { source: 53, target: 51, value: 1 },
    { source: 54, target: 51, value: 2 },
    { source: 54, target: 49, value: 1 },
    { source: 54, target: 26, value: 1 },
    { source: 55, target: 51, value: 6 },
    { source: 55, target: 49, value: 12 },
    { source: 55, target: 39, value: 1 },
    { source: 55, target: 54, value: 1 },
    { source: 55, target: 26, value: 21 },
    { source: 55, target: 11, value: 19 },
    { source: 55, target: 16, value: 1 },
    { source: 55, target: 25, value: 2 },
    { source: 55, target: 41, value: 5 },
    { source: 55, target: 48, value: 4 },
    { source: 56, target: 49, value: 1 },
    { source: 56, target: 55, value: 1 },
    { source: 57, target: 55, value: 1 },
    { source: 57, target: 41, value: 1 },
    { source: 57, target: 48, value: 1 },
    { source: 58, target: 55, value: 7 },
    { source: 58, target: 48, value: 7 },
    { source: 58, target: 27, value: 6 },
    { source: 58, target: 57, value: 1 },
    { source: 58, target: 11, value: 4 },
    { source: 59, target: 58, value: 15 },
    { source: 59, target: 55, value: 5 },
    { source: 59, target: 48, value: 6 },
    { source: 59, target: 57, value: 2 },
    { source: 60, target: 48, value: 1 },
    { source: 60, target: 58, value: 4 },
    { source: 60, target: 59, value: 2 },
    { source: 61, target: 48, value: 2 },
    { source: 61, target: 58, value: 6 },
    { source: 61, target: 60, value: 2 },
    { source: 61, target: 59, value: 5 },
    { source: 61, target: 57, value: 1 },
    { source: 61, target: 55, value: 1 },
    { source: 62, target: 55, value: 9 },
    { source: 62, target: 58, value: 17 },
    { source: 62, target: 59, value: 13 },
    { source: 62, target: 48, value: 7 },
    { source: 62, target: 57, value: 2 },
    { source: 62, target: 41, value: 1 },
    { source: 62, target: 61, value: 6 },
    { source: 62, target: 60, value: 3 },
    { source: 63, target: 59, value: 5 },
    { source: 63, target: 48, value: 5 },
    { source: 63, target: 62, value: 6 },
    { source: 63, target: 57, value: 2 },
    { source: 63, target: 58, value: 4 },
    { source: 63, target: 61, value: 3 },
    { source: 63, target: 60, value: 2 },
    { source: 63, target: 55, value: 1 },
    { source: 64, target: 55, value: 5 },
    { source: 64, target: 62, value: 12 },
    { source: 64, target: 48, value: 5 },
    { source: 64, target: 63, value: 4 },
    { source: 64, target: 58, value: 10 },
    { source: 64, target: 61, value: 6 },
    { source: 64, target: 60, value: 2 },
    { source: 64, target: 59, value: 9 },
    { source: 64, target: 57, value: 1 },
    { source: 64, target: 11, value: 1 },
    { source: 65, target: 63, value: 5 },
    { source: 65, target: 64, value: 7 },
    { source: 65, target: 48, value: 3 },
    { source: 65, target: 62, value: 5 },
    { source: 65, target: 58, value: 5 },
    { source: 65, target: 61, value: 5 },
    { source: 65, target: 60, value: 2 },
    { source: 65, target: 59, value: 5 },
    { source: 65, target: 57, value: 1 },
    { source: 65, target: 55, value: 2 },
    { source: 66, target: 64, value: 3 },
    { source: 66, target: 58, value: 3 },
    { source: 66, target: 59, value: 1 },
    { source: 66, target: 62, value: 2 },
    { source: 66, target: 65, value: 2 },
    { source: 66, target: 48, value: 1 },
    { source: 66, target: 63, value: 1 },
    { source: 66, target: 61, value: 1 },
    { source: 66, target: 60, value: 1 },
    { source: 67, target: 57, value: 3 },
    { source: 68, target: 25, value: 5 },
    { source: 68, target: 11, value: 1 },
    { source: 68, target: 24, value: 1 },
    { source: 68, target: 27, value: 1 },
    { source: 68, target: 48, value: 1 },
    { source: 68, target: 41, value: 1 },
    { source: 69, target: 25, value: 6 },
    { source: 69, target: 68, value: 6 },
    { source: 69, target: 11, value: 1 },
    { source: 69, target: 24, value: 1 },
    { source: 69, target: 27, value: 2 },
    { source: 69, target: 48, value: 1 },
    { source: 69, target: 41, value: 1 },
    { source: 70, target: 25, value: 4 },
    { source: 70, target: 69, value: 4 },
    { source: 70, target: 68, value: 4 },
    { source: 70, target: 11, value: 1 },
    { source: 70, target: 24, value: 1 },
    { source: 70, target: 27, value: 1 },
    { source: 70, target: 41, value: 1 },
    { source: 70, target: 58, value: 1 },
    { source: 71, target: 27, value: 1 },
    { source: 71, target: 69, value: 2 },
    { source: 71, target: 68, value: 2 },
    { source: 71, target: 70, value: 2 },
    { source: 71, target: 11, value: 1 },
    { source: 71, target: 48, value: 1 },
    { source: 71, target: 41, value: 1 },
    { source: 71, target: 25, value: 1 },
    { source: 72, target: 26, value: 2 },
    { source: 72, target: 27, value: 1 },
    { source: 72, target: 11, value: 1 },
    { source: 73, target: 48, value: 2 },
    { source: 74, target: 48, value: 2 },
    { source: 74, target: 73, value: 3 },
    { source: 75, target: 69, value: 3 },
    { source: 75, target: 68, value: 3 },
    { source: 75, target: 25, value: 3 },
    { source: 75, target: 48, value: 1 },
    { source: 75, target: 41, value: 1 },
    { source: 75, target: 70, value: 1 },
    { source: 75, target: 71, value: 1 },
    { source: 76, target: 64, value: 1 },
    { source: 76, target: 65, value: 1 },
    { source: 76, target: 66, value: 1 },
    { source: 76, target: 63, value: 1 },
    { source: 76, target: 62, value: 1 },
    { source: 76, target: 48, value: 1 },
    { source: 76, target: 58, value: 1 },
    { source: 77, target: 0, value: 1 },
    { source: 78, target: 0, value: 8 },
    { source: 79, target: 0, value: 10 },
    { source: 79, target: 2, value: 6 },
    { source: 80, target: 0, value: 1 },
    { source: 81, target: 0, value: 1 },
    { source: 82, target: 2, value: 1 },
    { source: 83, target: 0, value: 1 },
    { source: 83, target: 49, value: 2 },
    { source: 84, target: 39, value: 1 },
    { source: 84, target: 10, value: 1 },
    { source: 85, target: 3, value: 3 },
    { source: 86, target: 2, value: 3 },
    { source: 86, target: 0, value: 5 },
    { source: 86, target: 88, value: 1 },
    { source: 86, target: 88, value: 1 },
    { source: 87, target: 88, value: 1 },
    { source: 87, target: 101, value: 1 },
    { source: 87, target: 101, value: 4 },
    { source: 88, target: 115, value: 4 },
    { source: 88, target: 117, value: 4 },
    { source: 88, target: 116, value: 4 },
    { source: 89, target: 117, value: 4 },
    { source: 90, target: 18, value: 4 },
    { source: 90, target: 116, value: 3 },
    { source: 90, target: 117, value: 3 },
    { source: 91, target: 118, value: 3 },
    { source: 91, target: 119, value: 4 },
    { source: 91, target: 36, value: 3 },
    { source: 92, target: 147, value: 3 },
    { source: 92, target: 118, value: 3 },
    { source: 92, target: 119, value: 3 },
    { source: 92, target: 120, value: 5 },
    { source: 92, target: 116, value: 3 },
    { source: 93, target: 117, value: 3 },
    { source: 93, target: 118, value: 3 },
    { source: 93, target: 119, value: 3 },
    { source: 93, target: 20, value: 4 },
    { source: 94, target: 21, value: 4 },
    { source: 95, target: 126, value: 3 },
    { source: 96, target: 147, value: 3 },
    { source: 97, target: 138, value: 3 },
    { source: 97, target: 159, value: 3 },
    { source: 97, target: 120, value: 4 },
    { source: 98, target: 121, value: 4 },
    { source: 98, target: 122, value: 4 },
    { source: 99, target: 12, value: 2 },
    { source: 99, target: 11, value: 9 },
    { source: 100, target: 23, value: 2 },
    { source: 100, target: 11, value: 7 },
    { source: 100, target: 24, value: 13 },
    { source: 101, target: 23, value: 1 },
    { source: 101, target: 11, value: 12 },
    { source: 102, target: 24, value: 4 },
    { source: 102, target: 11, value: 31 },
    { source: 102, target: 16, value: 1 },
    { source: 102, target: 25, value: 1 },
    { source: 105, target: 11, value: 17 },
    { source: 105, target: 23, value: 5 },
    { source: 105, target: 25, value: 5 },
    { source: 106, target: 24, value: 1 },
    { source: 106, target: 26, value: 1 },
    { source: 106, target: 11, value: 8 },
    { source: 107, target: 27, value: 1 },
    { source: 107, target: 23, value: 1 },
    { source: 107, target: 27, value: 1 },
    { source: 107, target: 11, value: 2 },
    { source: 108, target: 23, value: 1 },
    { source: 109, target: 30, value: 2 },
    { source: 109, target: 11, value: 3 },
    { source: 110, target: 23, value: 2 },
    { source: 110, target: 27, value: 1 },
    { source: 110, target: 11, value: 1 },
    { source: 111, target: 11, value: 2 },
    { source: 111, target: 27, value: 1 },
    { source: 112, target: 11, value: 3 },
    { source: 112, target: 29, value: 2 },
    { source: 113, target: 11, value: 3 },
    { source: 113, target: 34, value: 3 },
    { source: 114, target: 29, value: 2 },
    { source: 114, target: 34, value: 2 },
    { source: 115, target: 35, value: 2 },
    { source: 115, target: 11, value: 2 },
    { source: 115, target: 29, value: 1 },
    { source: 116, target: 34, value: 2 },
    { source: 116, target: 35, value: 2 },
    { source: 116, target: 36, value: 2 },
    { source: 116, target: 11, value: 2 },
    { source: 116, target: 29, value: 1 },
    { source: 117, target: 34, value: 2 },
    { source: 117, target: 35, value: 2 },
    { source: 117, target: 36, value: 2 },
    { source: 117, target: 37, value: 2 },
    { source: 118, target: 11, value: 2 },
    { source: 118, target: 29, value: 1 },
    { source: 118, target: 25, value: 1 },
    { source: 119, target: 25, value: 1 },
    { source: 119, target: 24, value: 2 },
    { source: 120, target: 25, value: 3 },
    { source: 120, target: 41, value: 2 },
    { source: 120, target: 25, value: 2 },
    { source: 120, target: 24, value: 1 },
    { source: 121, target: 11, value: 3 },
    { source: 121, target: 26, value: 1 },
    { source: 122, target: 27, value: 1 },
    { source: 122, target: 28, value: 3 },
    { source: 122, target: 11, value: 1 },
    { source: 123, target: 28, value: 2 },
    { source: 123, target: 46, value: 1 },
    { source: 123, target: 47, value: 2 },
    { source: 124, target: 25, value: 1 },
    { source: 124, target: 27, value: 1 },
    { source: 124, target: 11, value: 1 },
    { source: 125, target: 26, value: 3 },
    { source: 125, target: 11, value: 2 },
    { source: 125, target: 49, value: 1 },
    { source: 125, target: 24, value: 1 },
    { source: 126, target: 49, value: 9 },
    { source: 126, target: 26, value: 2 },
    { source: 126, target: 11, value: 2 },
    { source: 126, target: 51, value: 1 },
    { source: 127, target: 39, value: 1 },
    { source: 127, target: 51, value: 1 },
    { source: 127, target: 51, value: 2 },
    { source: 128, target: 49, value: 1 },
    { source: 128, target: 26, value: 1 },
    { source: 128, target: 51, value: 6 },
    { source: 129, target: 49, value: 12 },
    { source: 129, target: 39, value: 1 },
    { source: 129, target: 54, value: 1 },
    { source: 129, target: 26, value: 21 },
    { source: 129, target: 11, value: 19 },
    { source: 129, target: 16, value: 1 },
    { source: 129, target: 25, value: 2 },
    { source: 129, target: 41, value: 5 },
    { source: 129, target: 48, value: 4 },
    { source: 130, target: 49, value: 1 },
    { source: 130, target: 113, value: 1 },
    { source: 131, target: 113, value: 1 },
    { source: 131, target: 114, value: 1 },
    { source: 131, target: 114, value: 1 },
    { source: 132, target: 113, value: 7 },
    { source: 132, target: 48, value: 7 },
    { source: 132, target: 27, value: 6 },
    { source: 133, target: 57, value: 1 },
    { source: 133, target: 113, value: 4 },
    { source: 133, target: 58, value: 15 },
    { source: 134, target: 114, value: 5 },
    { source: 134, target: 48, value: 6 },
    { source: 135, target: 113, value: 2 },
    { source: 135, target: 48, value: 1 },
    { source: 136, target: 58, value: 4 },
    { source: 136, target: 57, value: 2 },
    { source: 137, target: 48, value: 2 },
    { source: 137, target: 58, value: 6 },
    { source: 137, target: 60, value: 2 },
    { source: 137, target: 59, value: 5 },
    { source: 61, target: 57, value: 1 },
    { source: 138, target: 55, value: 1 },
    { source: 138, target: 55, value: 9 },
    { source: 138, target: 117, value: 17 },
    { source: 138, target: 59, value: 13 },
    { source: 139, target: 48, value: 7 },
    { source: 139, target: 114, value: 2 },
    { source: 139, target: 41, value: 1 },
    { source: 139, target: 61, value: 6 },
    { source: 140, target: 114, value: 3 },
    { source: 140, target: 114, value: 5 },
    { source: 140, target: 48, value: 5 },
    { source: 141, target: 117, value: 6 },
    { source: 141, target: 117, value: 2 },
    { source: 141, target: 117, value: 4 },
    { source: 141, target: 62, value: 3 },
    { source: 141, target: 114, value: 2 },
    { source: 142, target: 55, value: 1 },
    { source: 142, target: 55, value: 5 },
    { source: 142, target: 62, value: 12 },
    { source: 142, target: 48, value: 5 },
    { source: 143, target: 63, value: 4 },
    { source: 143, target: 58, value: 10 },
    { source: 143, target: 61, value: 6 },
    { source: 143, target: 60, value: 2 },
    { source: 143, target: 59, value: 9 },
    { source: 144, target: 113, value: 1 },
    { source: 144, target: 113, value: 1 },
    { source: 145, target: 123, value: 5 },
    { source: 145, target: 123, value: 7 },
    { source: 146, target: 123, value: 3 },
    { source: 146, target: 123, value: 5 },
    { source: 146, target: 58, value: 5 },
    { source: 146, target: 61, value: 5 },
    { source: 146, target: 117, value: 2 },
    { source: 147, target: 117, value: 5 },
    { source: 147, target: 117, value: 1 },
    { source: 147, target: 55, value: 2 },
    { source: 147, target: 64, value: 3 },
    { source: 147, target: 58, value: 3 },
    { source: 148, target: 59, value: 1 },
    { source: 148, target: 123, value: 2 },
    { source: 148, target: 65, value: 2 },
    { source: 148, target: 48, value: 1 },
    { source: 148, target: 63, value: 1 },
    { source: 149, target: 61, value: 1 },
    { source: 149, target: 60, value: 1 },
    { source: 150, target: 57, value: 3 },
    { source: 150, target: 25, value: 5 },
    { source: 150, target: 11, value: 1 },
    { source: 150, target: 24, value: 1 },
    { source: 150, target: 27, value: 1 },
    { source: 150, target: 48, value: 1 },
    { source: 150, target: 41, value: 1 },
    { source: 151, target: 89, value: 6 },
    { source: 151, target: 118, value: 6 },
    { source: 151, target: 111, value: 1 },
    { source: 151, target: 136, value: 1 },
    { source: 152, target: 136, value: 2 },
    { source: 152, target: 48, value: 1 },
    { source: 152, target: 123, value: 1 },
    { source: 152, target: 25, value: 4 },
    { source: 153, target: 69, value: 4 },
    { source: 153, target: 68, value: 4 },
    { source: 153, target: 11, value: 1 },
    { source: 154, target: 123, value: 1 },
    { source: 154, target: 125, value: 1 },
    { source: 154, target: 89, value: 1 },
    { source: 155, target: 58, value: 1 },
    { source: 155, target: 27, value: 1 },
    { source: 155, target: 69, value: 2 },
    { source: 156, target: 89, value: 2 },
    { source: 156, target: 70, value: 2 },
    { source: 156, target: 125, value: 1 },
    { source: 157, target: 123, value: 1 },
    { source: 157, target: 41, value: 1 },
    { source: 157, target: 25, value: 1 },
    { source: 157, target: 26, value: 2 },
    { source: 158, target: 27, value: 1 },
    { source: 158, target: 11, value: 1 },
    { source: 158, target: 89, value: 2 },
    { source: 158, target: 48, value: 2 },
    { source: 159, target: 73, value: 3 },
    { source: 159, target: 69, value: 3 },
    { source: 159, target: 123, value: 3 },
    { source: 159, target: 125, value: 3 },
    { source: 159, target: 48, value: 1 },
    { source: 159, target: 118, value: 1 },
    { source: 159, target: 89, value: 1 },
    { source: 159, target: 71, value: 1 },
    { source: 160, target: 64, value: 1 },
    { source: 160, target: 65, value: 1 },
    { source: 160, target: 125, value: 1 },
    { source: 161, target: 63, value: 1 },
    { source: 161, target: 62, value: 1 },
    { source: 162, target: 48, value: 1 },
    { source: 162, target: 58, value: 1 }
  ],
};
